[{"authors":["admin"],"categories":null,"content":"2013年岐阜大学工学部 電気電子・情報工学科に入学．情報分野を専門領域として学ぶ． その中で，人工知能・コンピュータビジョンに興味を持ち，2015年より加藤研究室に所属する． 学部・修士課程を通して，ニューラルネットワーク・画像処理・異常検知の研究に従事．特に工業製品や食品における外観検査の自動化をテーマとして研究を行った． また2018年度より応用生物科学部と協同しニューラルネットワークを用いた野生動物検知の研究にも着手．\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://salty-vanilla.github.io/portfolio/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/portfolio/author/admin/","section":"author","summary":"2013年岐阜大学工学部 電気電子・情報工学科に入学．情報分野を専門領域として学ぶ． その中で，人工知能・コンピュータビジョンに興味を持ち，2015年より加藤研究室に所属する． 学部・修士課程を通して，ニューラルネットワーク・画像処理・異常検知の研究に従事．特に工業製品や食品における外観検査の自動化をテーマとして研究を行った． また2018年度より応用生物科学部と協同しニューラルネットワークを用いた野生動物検知の研究にも着手．","tags":null,"title":"Nakatsuka Shunsuke ","type":"author"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う Deep SVDDベースのDeep SADを提案  Deep SVDD + 少量の教師つきデータ + mutual info    2. 先行研究と比べてどこがすごい？  Deep SVDD (Unsupervised: 正常データのみ)にSemi-Supervised: 正常データ + 少量の教師つきデータ の枠組みを追加 最近この問題設定流行り？  より実利用に近い感じがしてgood   classification と one-class learning のいいとこどり   3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Deep SVDD + 少量の教師つきデータ + mutual info  Mutual Information  Information Bottleneck (classification)では，入力$x$と潜在変数$z$，ラベル$y$それぞれのmutual info $\\mathbb{I}$を最大化 $$ min_{p(z|x)} {\\mathbb{I}(X; Z) - \\alpha\\mathbb{I}(Z; Y)} $$ Unsupervisedなら，正則化項$R$を使って $$ max_{p(z|x)} {\\mathbb{I}(X; Z) + \\beta R(Z)} $$ autoencoderはInfomaxの枠組みとも考えられる  Deep SVDD  以前まとめた https://salty-vanilla.github.io/portfolio/post/deep_svdd/ を参照 $$ \\min _ {w} \\frac{1}{n} \\sum_{i=1}^{n}\\left|\\phi\\left(\\boldsymbol{x} _ {i} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2}+\\frac{\\lambda}{2} \\sum_{\\ell=1}^{L}\\left|\\boldsymbol{W}^{\\ell}\\right|_{F}^{2}, \\quad \\lambda\u0026gt;0 $$ Deep SVDDはemprical varianceを最小化している $s(x) = \\left|\\phi\\left(\\boldsymbol{x} _ {i} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2} $ はlatent gaussian のentropyの上界とみなせて，それの最小化をしている  AutoencoderでNNを初期化していることが前提    Deep SAD (Semi-supervised Anomaly Dection) 変数の定義  $x_1, \\cdots, x_n$ : unlabeled samples $(\\tilde{x_1}, \\tilde{y_1}), \\cdots, (\\tilde{x_m}, \\tilde{y_m})$ : labeled samples  normalなら $\\tilde{y} = +1$ anomalyなら $\\tilde{y} = -1$    目的関数   Unsupervised のInfomaxを適用して $$ max_{p(z|x)} {\\mathbb{I}(X; Z) + \\beta (\\mathbb{H}(Z^{-}) - \\mathbb{H}(Z^{+}))} $$\n $\\mathbb{H}$ : entropy $Z^{-}$ : $\\tilde{y} = -1$ の$x$に対する潜在変数 $Z^{+}$ : $\\tilde{y} = +1$ の$x$に対する潜在変数    これにDeep SVDDの枠組みを適用すると $$ \\min _ {\\boldsymbol{w}} \\frac{1}{n+m} \\sum_{i=1}^{n}\\left|\\phi\\left(\\boldsymbol{x} _ {i} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2}+\\frac{\\eta}{n+m} \\sum_{j=1}^{m}\\left(\\left|\\phi\\left(\\tilde{\\boldsymbol{x}} _ {j} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2}\\right)^{\\tilde{y} _ {j}}+\\frac{\\lambda}{2} \\sum_{\\ell=1}^{L}\\left|\\boldsymbol{W}^{\\ell}\\right|_{F}^{2} $$\n 1, 3項目はDeepSVDD 2項目が↑式の正則化項にあたる  normalなら$c$に近く anomalyなら$c$から遠く      4. どうやって有効だと検証した？  MNIST, Fashion-MNIST, Cifar10で実験 labelつきデータの異常データを増やすほどAUC上昇  labelなしデータの中に異常データが混入しても他手法よりも精度が落ちない   5. 議論はあるか？  Deep SVDD + Semisupervisedは自分も考えていただけに先越された感 今年はこの問題設定流行りそう  6. 次に読むべき論文はある？ ","date":1582729200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582729200,"objectID":"d853b2f9089fc65f3dd48a9e92b1662f","permalink":"https://salty-vanilla.github.io/portfolio/post/deep_sad/","publishdate":"2020-02-27T00:00:00+09:00","relpermalink":"/portfolio/post/deep_sad/","section":"post","summary":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う Deep SVDDベースのDeep SADを提案  Deep SVDD + 少量の教師つきデータ + mutual info    2. 先行研究と比べてどこがすごい？  Deep SVDD (Unsupervised: 正常データのみ)にSemi-Supervised: 正常データ + 少量の教師つきデータ の枠組みを追加 最近この問題設定流行り？  より実利用に近い感じがしてgood   classification と one-class learning のいいとこどり   3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Deep SVDD + 少量の教師つきデータ + mutual info  Mutual Information  Information Bottleneck (classification)では，入力$x$と潜在変数$z$，ラベル$y$それぞれのmutual info $\\mathbb{I}$を最大化 $$ min_{p(z|x)} {\\mathbb{I}(X; Z) - \\alpha\\mathbb{I}(Z; Y)} $$ Unsupervisedなら，正則化項$R$を使って $$ max_{p(z|x)} {\\mathbb{I}(X; Z) + \\beta R(Z)} $$ autoencoderはInfomaxの枠組みとも考えられる  Deep SVDD  以前まとめた https://salty-vanilla.","tags":null,"title":"Deep Semi-Supervised Anomaly Detection","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う 入力は2入力でWeight SharingされたNNから得られた特徴ベクトル同士を結合して異常度回帰  2. 先行研究と比べてどこがすごい？  正常データからAnomaly Detectionモデルを作れるのは当たり前 実利用においては，少量の異常データを如何にうまく使うかが求められる DevNetの異常度のreference scoreがデータに一切依存していないことを改善？  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Pairwise Relation を学習 大量の正常データと少量の異常データからAnomaly Detectionを行う テスト時には正常データと異常データと比較することで異常度算出  変数の定義  $\\mathcal{U} = \\{ u_1, u_2, \\cdots, u_N \\}$ : unlabeled samples (正常データとごく少量の異常データ) $\\mathcal{A} = \\{ a_1, a_2, \\cdots, a_K \\}$ : labeled samples (少量の異常データ) その他の変数は下を参照   Loss関数 $$ \\underset{\\Theta}{\\arg \\min } \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} _ {i}, \\mathbf{x} _ {j}, y_{i j} \\in \\mathcal{B}}\\left|y_{i j}-\\phi\\left(\\left(\\mathbf{x} _ {i}, \\mathbf{x}_{j}\\right) ; \\Theta\\right)\\right|+\\lambda R(\\Theta) $$\n $\\mathcal{B}$ は$\\mathcal{U}$(正常)と$\\mathcal{A}$(異常)からサンプリングされたサンプルで構成 $c_1 \u0026lt; c_2 \u0026lt; c_3$ 異常/異常の組み合わせ : $y=c_1$ (めちゃめちゃ遠くに) 異常/正常の組み合わせ : $y=c_2$ (遠くに) 正常/正常の組み合わせ : $y=c_3$ (近くに)  異常度の算出 $$ s_{\\mathbf{x}_{k}}=\\frac{1}{2 E}\\left[\\sum_{i=1}^{E} \\phi\\left(\\left(\\mathbf{a}_{i}, \\mathbf{x}_{k}\\right) ; \\Theta^{*}\\right)+\\sum_{j=1}^{E} \\phi\\left(\\left(\\mathbf{x}_{k}, \\mathbf{u}_{j}\\right) ; \\Theta^{*}\\right)\\right] $$\n $x_k$が異常なら$s_{x_k}$が大（理論値 : $c_1 + c_2$） $x_k$が正常なら$s_{x_k}$が小（理論値 : $c_2 + c_3$）  4. どうやって有効だと検証した？  様々なAD datasetでSoTA  Deep SVDD: AD．タスクに合わせてenhanceしたモデルを実装したとのこと prototypical networks (FSNet) : few-shot classification iForest: AD DevNet: 筆者のmethod     5. 議論はあるか？  $c_1$, $c_2$, $c_3$のチューニングは必要？ サンプリング方法を同じにしたSiamse Networkとの比較は？ Deep SVDDをどうenhanceしたか？  6. 次に読むべき論文はある？ ","date":1582642800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582642800,"objectID":"31ad7af78894e8b3a0620c8b53cf6b74","permalink":"https://salty-vanilla.github.io/portfolio/post/prenet/","publishdate":"2020-02-26T00:00:00+09:00","relpermalink":"/portfolio/post/prenet/","section":"post","summary":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う 入力は2入力でWeight SharingされたNNから得られた特徴ベクトル同士を結合して異常度回帰  2. 先行研究と比べてどこがすごい？  正常データからAnomaly Detectionモデルを作れるのは当たり前 実利用においては，少量の異常データを如何にうまく使うかが求められる DevNetの異常度のreference scoreがデータに一切依存していないことを改善？  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Pairwise Relation を学習 大量の正常データと少量の異常データからAnomaly Detectionを行う テスト時には正常データと異常データと比較することで異常度算出  変数の定義  $\\mathcal{U} = \\{ u_1, u_2, \\cdots, u_N \\}$ : unlabeled samples (正常データとごく少量の異常データ) $\\mathcal{A} = \\{ a_1, a_2, \\cdots, a_K \\}$ : labeled samples (少量の異常データ) その他の変数は下を参照   Loss関数 $$ \\underset{\\Theta}{\\arg \\min } \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} _ {i}, \\mathbf{x} _ {j}, y_{i j} \\in \\mathcal{B}}\\left|y_{i j}-\\phi\\left(\\left(\\mathbf{x} _ {i}, \\mathbf{x}_{j}\\right) ; \\Theta\\right)\\right|+\\lambda R(\\Theta) $$","tags":null,"title":"Deep Weakly-supervised Anomaly Detection","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う 枠組みとしてはDeep SVDDに近い  2. 先行研究と比べてどこがすごい？  正常データからAnomaly Detectionモデルを作れるのは当たり前 実利用においては，少量の異常データを如何にうまく使うかが求められる end2end  AnoGANなどはnot end2end    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  大量の正常データと少量の異常データからAnomaly Detectionを行う  変数の定義  $ \\mathcal{X} = \\{ x_1, x_2, \\cdots, x_N, x_{N+1}, \\cdots, x_{N+K} \\} $ : training samples $\\mathcal{U} = \\{ x_1, x_2, \\cdots, x_N \\}$ : unlabeled samples (正常データとごく少量の異常データ) $\\mathcal{K} = \\{ x_{N+1}, x_{N+2}, \\cdots, x_{N+K} \\}$ : labeled samples (少量の異常データ) $K \u0026laquo; N$ : 異常データは少量 $\\phi(x, \\theta)$ : Scoring Network  Framework   Scoring NetworkからScoreを算出\n  Reference Scoreを算出\n 確率分布$F$から$l$個の乱数を生成 $l$個の乱数から平均$\\mu_R$と分散$\\sigma_R$を算出 なにかNNとかあるわけではないので注意 $F$は$\\mathcal{N}(\\mu=0, \\sigma=1)$，$l=5000$くらいで十分らしい    Deviation Lossを算出\n $x \\sim \\mathcal{U}$ なら $y=0$ (正常) deviationを$0$に $x \\sim \\mathcal{K}$ なら $y=1$ (異常) deviationを$a$に $$ \\operatorname{dev}(\\mathbf{x})=\\frac{\\phi(\\mathbf{x} ; \\Theta)-\\mu_{\\Re}}{\\sigma_{\\mathcal{R}}} $$ $$ L\\left(\\phi(\\mathbf{x} ; \\Theta), \\mu_{\\mathcal{R}}, \\sigma_{\\mathcal{R}}\\right)=(1-y)|dev(\\mathbf{x})|+y \\max (0, a-\\operatorname{dev}(\\mathbf{x})) $$     4. どうやって有効だと検証した？  様々なAD datasetでSoTA  REPEN: limited labeld dataのAD Deep SVDD: AD．タスクに合わせてenhanceしたモデルを実装したとのこと prototypical networks (FSNet) : few-shot classification iForest: AD     5. 議論はあるか？  $F$が標準正規分布なら，$\\mu_R=0$，$\\sigma=0$となってデータに全く依存しないReference Scoreになってるけどいいのか？  この筆者の次の論文では解決されるらしい[1]   結局ミニバッチのサンプリングを$\\mathcal{U}$から半分，$\\mathcal{K}$から半分とってきてるのが大きそう  6. 次に読むべき論文はある？  Pang, G., Shen, C., Jin, H., \u0026amp; Hengel, A. van den. (2019). Deep Weakly-supervised Anomaly Detection. Retrieved from https://arxiv.org/abs/1910.13601  ","date":1581778800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581778800,"objectID":"69d5f6c2d457b02ecb25867109ffc731","permalink":"https://salty-vanilla.github.io/portfolio/post/devnet/","publishdate":"2020-02-16T00:00:00+09:00","relpermalink":"/portfolio/post/devnet/","section":"post","summary":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う 枠組みとしてはDeep SVDDに近い  2. 先行研究と比べてどこがすごい？  正常データからAnomaly Detectionモデルを作れるのは当たり前 実利用においては，少量の異常データを如何にうまく使うかが求められる end2end  AnoGANなどはnot end2end    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  大量の正常データと少量の異常データからAnomaly Detectionを行う  変数の定義  $ \\mathcal{X} = \\{ x_1, x_2, \\cdots, x_N, x_{N+1}, \\cdots, x_{N+K} \\} $ : training samples $\\mathcal{U} = \\{ x_1, x_2, \\cdots, x_N \\}$ : unlabeled samples (正常データとごく少量の異常データ) $\\mathcal{K} = \\{ x_{N+1}, x_{N+2}, \\cdots, x_{N+K} \\}$ : labeled samples (少量の異常データ) $K \u0026laquo; N$ : 異常データは少量 $\\phi(x, \\theta)$ : Scoring Network  Framework   Scoring NetworkからScoreを算出","tags":null,"title":"Deep Anomaly Detection with Deviation Networks","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  One-Class SVM (OCSVM)の非線形カーネルをNNで置き換えたモデル anomaly detectionの枠組みとして，soft-boundary と one-class Deep SVDDを提案  2. 先行研究と比べてどこがすごい？  OCSVMの非線形カーネルをNNで置き換えた  OSCVMより優れた表現力を持つ   SVDD (Support Vector Data Description) OCSVMのobjective  $x$ : sample $w$ : weights $\\phi$ : kernel function $\\rho$ : distance from the origin to hyperplane $w$ $\\xi$ : margin $$ \\min _ {\\boldsymbol{w}, \\rho, \\boldsymbol{\\xi}} \\frac{1}{2}|\\boldsymbol{w}|_{\\mathcal{F}_{k}}^{2}-\\rho+\\frac{1}{\\nu n} \\sum_{i=1}^{n} \\xi_{i} $$ $$ \\text { s.t. } \\quad\\left\\langle\\boldsymbol{w}, \\phi_{k}\\left(\\boldsymbol{x} _ {i}\\right)\\right\\rangle_{\\mathcal{F} _ {k}} \\geq \\rho-\\xi_{i}, \\quad \\xi_{i} \\geq 0, \\quad \\forall i $$    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  OCSVM + NN   soft boudary  objective $$ \\min _ {R, W} R^{2}+\\frac{1}{\\nu n} \\Sigma_{i=1}^n \\max ( 0, \\|\\phi(x_{i} ; \\mathcal{W})-c\\|^{2}-R^{2}) +\\frac{\\lambda}{2} \\sum_{\\ell=1}^{L}\\left|\\boldsymbol{W}^{\\ell}\\right|_{F}^{2} $$  $R$はミニバッチ内の0.9 quantile目のdistance : $\\|\\phi(x_{i} ; \\mathcal{W})-c\\|^{2}$ $R$より中心から離れたサンプルだけにペナルティを与える感じ    one-class  objective $$ \\min _ {w} \\frac{1}{n} \\sum_{i=1}^{n}\\left|\\phi\\left(\\boldsymbol{x}_ {i} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2}+\\frac{\\lambda}{2} \\sum_{\\ell=1}^{L}\\left|\\boldsymbol{W}^{\\ell}\\right|_{F}^{2} $$  異常度の算出 $$ s(\\boldsymbol{x})=\\left|\\phi\\left(\\boldsymbol{x} ; \\mathcal{W}^{*}\\right)-\\boldsymbol{c}\\right|^{2} $$\nProperties  weightを0初期化しない  $\\boldsymbol{c}$は初期化したNNの出力の平均ベクトルとする   biasを用いない bounded function （有界関数）を活性化関数に使わない  relu族を使おう   $nu$はoutlierの割合の上限とする  4. どうやって有効だと検証した？  Cifar10，MNISTで実験 OCSVMに勝るのはもちろん，DCAEやAnoGANより高精度  同クラス内でもnormal / anomalousなsampleが検出できている   5. 議論はあるか？  MNISTやCifarはNovelty Detectionの成分が強い気がする  外観検査とかで使えるかは検証しないとわからん 傷があるとか局所的に異常とか   ミニバッチの大きさはどのくらい精度に影響する？  6. 次に読むべき論文はある？  Chalapathy, R., Menon, A. K., \u0026amp; Chawla, S. (2018). Anomaly Detection using One-Class Neural Networks. Retrieved from http://arxiv.org/abs/1802.06360  ","date":1581778800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581778800,"objectID":"1138a5ea742f15cc14d17a6e61d94fc8","permalink":"https://salty-vanilla.github.io/portfolio/post/deep_svdd/","publishdate":"2020-02-16T00:00:00+09:00","relpermalink":"/portfolio/post/deep_svdd/","section":"post","summary":"1. どんなもの？  One-Class SVM (OCSVM)の非線形カーネルをNNで置き換えたモデル anomaly detectionの枠組みとして，soft-boundary と one-class Deep SVDDを提案  2. 先行研究と比べてどこがすごい？  OCSVMの非線形カーネルをNNで置き換えた  OSCVMより優れた表現力を持つ   SVDD (Support Vector Data Description) OCSVMのobjective  $x$ : sample $w$ : weights $\\phi$ : kernel function $\\rho$ : distance from the origin to hyperplane $w$ $\\xi$ : margin $$ \\min _ {\\boldsymbol{w}, \\rho, \\boldsymbol{\\xi}} \\frac{1}{2}|\\boldsymbol{w}|_{\\mathcal{F}_{k}}^{2}-\\rho+\\frac{1}{\\nu n} \\sum_{i=1}^{n} \\xi_{i} $$ $$ \\text { s.t. } \\quad\\left\\langle\\boldsymbol{w}, \\phi_{k}\\left(\\boldsymbol{x} _ {i}\\right)\\right\\rangle_{\\mathcal{F} _ {k}} \\geq \\rho-\\xi_{i}, \\quad \\xi_{i} \\geq 0, \\quad \\forall i $$    3.","tags":null,"title":"Deep One-Class Classification","type":"post"},{"authors":null,"categories":["Semi-supervised Learning"],"content":"1. どんなもの？  Pseudo labelとConsistency regularizationを組み合わせたSemi-supervised learning (SSL) 非常に単純な枠組みだが，Cifar10を40labels だけでerror率：11.39を達成  2. 先行研究と比べてどこがすごい？  Pseudo labelとConsistency regularizationの組み合わせでSSLのSOTA  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Pseudo labelとConsistency regularizationの組み合わせ 変数の定義  $x_b$ : labeled training exmaple $p_b$ : one-hot label $\\mathbb{X} = { (x_b, p_b): b \\in (1, \\cdots, B) }$ : labelありデータの集合 $u_b$: unlabeled training exmaple $\\mathbb{U} = {(u_b): b \\in (1, \\cdots, \\mu B)}$ : labelなしデータの集合 $H(p, q)$ : $p$, $q$のcrossentropy    Consistency regularization  loss関数は確率的なaugmentation $\\alpha$と$p_m$を用いて， $$ \\sum_{b=1}^{\\mu B}\\left|p_{\\mathrm{m}}\\left(y | \\alpha\\left(u_{b}\\right)\\right)-p_{\\mathrm{m}}\\left(y | \\alpha\\left(u_{b}\\right)\\right)\\right|_{2}^{2} $$ 確率的なので，↑は0にはならないことに注意  Pseudo label  $u_b$に対して，擬似的ラベル$q_b$を付与する $$ q_b = p_m(y|u_b) $$ unlabeld dataに対するloss関数は，指示関数 $\\mathbb{I}$，しきい値 $\\tau$を用いて $$ \\frac{1}{\\mu B} \\sum_{b=1}^{\\mu B} \\mathbb{I}\\left(\\max \\left(q_{b}\\right) \\geq \\tau\\right) \\mathrm{H}\\left(\\hat{q}_{b}, q_{b}\\right) $$ $$ \\hat{q}_{b} = argmax(q_b) $$  FixMatch  labeled exmapleに対してはConsistency regularization (図の上側) $\\alpha$は弱いaugmentation (e.g. filpとか軽微なshift) $$ \\ell_{s}=\\frac{1}{B} \\sum_{b=1}^{B} \\mathrm{H}\\left(p_{b}, p_{\\mathrm{m}}\\left(y | \\alpha\\left(x_{b}\\right)\\right)\\right) $$ unlabeld exampleに対してはPseudo label(図の下側) $\\mathcal{A}$は強いaugmentation (AutoAugmentベースの手法：RandAugment，CTAugment) $$ \\ell_{u}=\\frac{1}{\\mu B} \\sum_{b=1}^{\\mu B} \\mathbb{I}\\left(\\max \\left(q_{b}\\right) \\geq \\tau\\right) \\mathrm{H}\\left(\\hat{q}_{b}, p_{\\mathrm{m}}\\left(y | \\mathcal{A}\\left(u_{b}\\right)\\right)\\right) $$ $$ q_b = p_m(y | \\alpha(u_b)) $$   Additional important factors  weight decayが有効 AdamよりSGDが良い learning scheduleにはcosine learning rate decayを使う $$ \\eta \\cos (\\frac{7 \\pi K}{16K} ) $$  4. どうやって有効だと検証した？  Cifar10，Cifar100，SVHNで実験  Cifar100以外はSOTA    下の10枚（つまり1クラス1枚）だけを用いてCifar10学習しても78%のAccuracy   5. 議論はあるか？  Section 5は気が向いたら 単純な方法 + 少ラベルでこれほどの精度が出るのは驚き Goodfellow曰く革命 The quiet semisupervised revolution continues https://t.co/FAY4v9aHbe\n\u0026mdash; Ian Goodfellow (@goodfellow_ian) January 22, 2020    6. 次に読むべき論文はある？  David Berthelot, Nicholas Carlini, Ekin D. Cubuk, Alex Ku- rakin, Kihyuk Sohn, Han Zhang, and Colin Raffel. Remix- match: Semi-supervised learning with distribution matching and augmentation anchoring. In Eighth International Conference on Learning Representations, 2020. Ekin D. Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V. Le. Randaugment: Practical automated data augmen- tation with a reduced search space. arXiv preprint arXiv:1909.13719, 2019. David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raffel. Mixmatch: A holistic approach to semi-supervised learning. In Advances in Neural Information Processing Systems 32. 2019.  ","date":1580137200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580137200,"objectID":"9ade4b00c27babea930d01f9ec796248","permalink":"https://salty-vanilla.github.io/portfolio/post/fixmatch/","publishdate":"2020-01-28T00:00:00+09:00","relpermalink":"/portfolio/post/fixmatch/","section":"post","summary":"1. どんなもの？  Pseudo labelとConsistency regularizationを組み合わせたSemi-supervised learning (SSL) 非常に単純な枠組みだが，Cifar10を40labels だけでerror率：11.39を達成  2. 先行研究と比べてどこがすごい？  Pseudo labelとConsistency regularizationの組み合わせでSSLのSOTA  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Pseudo labelとConsistency regularizationの組み合わせ 変数の定義  $x_b$ : labeled training exmaple $p_b$ : one-hot label $\\mathbb{X} = { (x_b, p_b): b \\in (1, \\cdots, B) }$ : labelありデータの集合 $u_b$: unlabeled training exmaple $\\mathbb{U} = {(u_b): b \\in (1, \\cdots, \\mu B)}$ : labelなしデータの集合 $H(p, q)$ : $p$, $q$のcrossentropy    Consistency regularization  loss関数は確率的なaugmentation $\\alpha$と$p_m$を用いて， $$ \\sum_{b=1}^{\\mu B}\\left|p_{\\mathrm{m}}\\left(y | \\alpha\\left(u_{b}\\right)\\right)-p_{\\mathrm{m}}\\left(y | \\alpha\\left(u_{b}\\right)\\right)\\right|_{2}^{2} $$ 確率的なので，↑は0にはならないことに注意  Pseudo label  $u_b$に対して，擬似的ラベル$q_b$を付与する $$ q_b = p_m(y|u_b) $$ unlabeld dataに対するloss関数は，指示関数 $\\mathbb{I}$，しきい値 $\\tau$を用いて $$ \\frac{1}{\\mu B} \\sum_{b=1}^{\\mu B} \\mathbb{I}\\left(\\max \\left(q_{b}\\right) \\geq \\tau\\right) \\mathrm{H}\\left(\\hat{q}_{b}, q_{b}\\right) $$ $$ \\hat{q}_{b} = argmax(q_b) $$  FixMatch  labeled exmapleに対してはConsistency regularization (図の上側) $\\alpha$は弱いaugmentation (e.","tags":null,"title":"FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence","type":"post"},{"authors":null,"categories":["Anomaly Detection","Self-supervised Learning"],"content":"1. どんなもの？  Classification-BasedなSelf-supervised learningモデルを使った異常検知手法 幾何変換モデルを発展させた  2. 先行研究と比べてどこがすごい？  ベースはGeometric-transformation classification(GEOM) ↓2点の解決  GEOMでは，Anomalyに対しても正常度が高くなってしまうことがあった GEOMでは，画像しか対応できず1次元データに対しては適用不可だった    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  GEOMのSoftmax + Categorical Cross Entoropyをcenter vectorをanchorとしたtripletに 幾何変換ではなく，アフィン変換（幾何ではなく，$Wx+b$）に  GEOM   GEOMでは画像$x \\in X$を幾何変換$m \\in M$で変換することで$T(x, m)$を生成\n  $T(x, m)$を入力，$m$を教師ラベルとすることで幾何変換判別モデルを学習していた (Self-supervised)\n  正常データならこの変換の判別がうまくできるし，正常データでないなら判別がうまくできないという仮定を利用して異常検知\n  尤度としては $$ P\\left(m^{\\prime} | T(x, m)\\right)=\\frac{P\\left(T(x, m) \\in X_{m^{\\prime}}\\right) P\\left(m^{\\prime}\\right)}{\\sum_{\\tilde{m}} P\\left(T(x, m) \\in X_{\\tilde{m}}\\right) P(\\tilde{m})}=\\frac{P\\left(T(x, m) \\in X_{m^{\\prime}}\\right)}{\\sum_{\\tilde{m}} P\\left(T(x, m) \\in X_{\\tilde{m}}\\right)} $$\n  問題点\n 正常データに対して高い尤度を持つことは確認できるけど，異常データに対して低い尤度を持つとは言い難い Outlier Exposureみたいに異常も教えてあげればいいけど，異常データを実際に学習に使えない場合は多い    triplet lossの導入  ↑の問題解決のために，判別モデルではなくmetric learning（距離学習系）の採用 $T(x, m)$から特徴ベクトルを抽出するモデル$f$を学習 lossにはtriplet lossを採用．anchorはそれぞれの幾何変換$m$の特徴ベクトルのcenter vector $c_m$，$s$はmargin $$ c_m = \\frac{1}{N}\\Sigma_{x \\in X}f(T(x, m)) $$  $$ L=\\sum_{i} \\max \\left(\\left|f\\left(T\\left(x_{i}, m\\right)\\right)-c_{m}\\right|^{2}+s-\\min _{m^{\\prime} \\neq m}\\left|f\\left(T\\left(x_{i}, m\\right)\\right)-c_{m^{\\prime}}\\right|^{2}, 0\\right) $$\n 正常度は $$ \\tilde{P}\\left(m^{\\prime} | T(x, m)\\right)=\\frac{e^{-\\left|f(T(x, m))-c_{m^{\\prime}}\\right|^{2}+\\epsilon}}{\\sum_{\\tilde{m}} e^{-\\left|f(T(x, m))-c_{\\tilde{m}}\\right|^{2}+M \\cdot \\epsilon}} $$  $$ \\text {Score}(x)=-\\log P(x \\in X)=-\\sum_{m} \\log \\tilde{P}\\left(T(x, m) \\in X_{m}\\right)=-\\sum_{m} \\log \\tilde{P}(m | T(x, m)) $$\ntransformation  幾何変換は画像データにしか適用できない場合がある Affine transformの適用．$W_m$, $b_m$はrandom matrix, vector $$ T(x,m) = W_m x + b_m $$ 幾何変換は↑の特殊な形といえる．つまり一般化した形 無制限のvariationの獲得 adversarial examplesから守ることができる  4. どうやって有効だと検証した？  Cifar10で実験 transformの数は8  1次元データでも実験   5. 議論はあるか？  Dirichlet weightingとは？ ICLR2020 accept  6. 次に読むべき論文はある？  Izhak Golan and Ran El-Yaniv. Deep anomaly detection using geometric transformations. In NeurIPS, 2018 Dan Hendrycks, Mantas Mazeika, and Thomas G Dietterich. Deep anomaly detection with outlier exposure. arXiv preprint arXiv:1812.04606, 2018  ","date":1580050800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580050800,"objectID":"4429d3b3e440b96c07743e98fbd1b7ff","permalink":"https://salty-vanilla.github.io/portfolio/post/classification-based_anomaly_detection_for_general_data/","publishdate":"2020-01-27T00:00:00+09:00","relpermalink":"/portfolio/post/classification-based_anomaly_detection_for_general_data/","section":"post","summary":"1. どんなもの？  Classification-BasedなSelf-supervised learningモデルを使った異常検知手法 幾何変換モデルを発展させた  2. 先行研究と比べてどこがすごい？  ベースはGeometric-transformation classification(GEOM) ↓2点の解決  GEOMでは，Anomalyに対しても正常度が高くなってしまうことがあった GEOMでは，画像しか対応できず1次元データに対しては適用不可だった    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  GEOMのSoftmax + Categorical Cross Entoropyをcenter vectorをanchorとしたtripletに 幾何変換ではなく，アフィン変換（幾何ではなく，$Wx+b$）に  GEOM   GEOMでは画像$x \\in X$を幾何変換$m \\in M$で変換することで$T(x, m)$を生成\n  $T(x, m)$を入力，$m$を教師ラベルとすることで幾何変換判別モデルを学習していた (Self-supervised)\n  正常データならこの変換の判別がうまくできるし，正常データでないなら判別がうまくできないという仮定を利用して異常検知\n  尤度としては $$ P\\left(m^{\\prime} | T(x, m)\\right)=\\frac{P\\left(T(x, m) \\in X_{m^{\\prime}}\\right) P\\left(m^{\\prime}\\right)}{\\sum_{\\tilde{m}} P\\left(T(x, m) \\in X_{\\tilde{m}}\\right) P(\\tilde{m})}=\\frac{P\\left(T(x, m) \\in X_{m^{\\prime}}\\right)}{\\sum_{\\tilde{m}} P\\left(T(x, m) \\in X_{\\tilde{m}}\\right)} $$","tags":null,"title":"Classification-Based Anomaly Detection for General Data","type":"post"},{"authors":null,"categories":["Anomaly Detection","Novelty Detection","Out of Distribution Detection"],"content":"1. どんなもの？  OoD Detectionの枠組み 入力をSVD + 特異値0埋めでBlurして，low-rank projectorとなるようなNNを学習 ↑のようなNNを用いることで，target distribution specificな特徴を抽出  2. 先行研究と比べてどこがすごい？  従来のOoD Detectionの手法では，OoDなデータに対しても高い尤度を持つことが多々あった 幾何変換は使わないので，幾何的な意味を持たないDomainにも適用できそう  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  入力をSVD + 特異値0埋めでBlur low-rank projectorとなるようなNN  GENERATING BLURRED DATA  変数の定義  target distribution (training dataset): $D$ training data sample: $d \\in \\mathbb{R}^{H \\times W \\times i}$ $d$の$j$番目のチャネル画像$d_j$のnonzero singular values: $[ \\sigma_{j1}, \\sigma_{j2}, \\cdots, \\sigma_{jN_j} ]$ $d_j$のnonzero singular valuesの数: N_j   $d_j$をSVDすると $$ d_{j}=\\Sigma_{t=1}^{N_{j}} \\sigma_{j t} u_{j t} v_{j t}^{T} $$ $[ \\sigma_{j1}, \\sigma_{j2}, \\cdots, \\sigma_{jN_j} ]$ のbottom $K$個を0にして，復元するとBlurredなデータが生成される  rankが落ちるから    OOD DETECTION VIA SVD-RND  変数の定義  Predictor Network: $f$ $i$番目のbottom K: $K_i$ $i$番目のtarget network: $g_i$ (random networkで学習時に一切更新されない) $i$の個数: $b_{train}$   $b_{train} = 1$のときのモデル構造  Objective $$ f^{*}=\\arg \\min _ {f}\\left[\\Sigma_{x \\in D_{\\text {train }}}\\left|f(x)-g_{0}(x)\\right| _ {2}^{2}+\\Sigma_{i=1}^{b_{\\text {train }}} \\Sigma_{x \\in D_{K_{i}}}\\left|f(x)-g_{i}(x)\\right|_{2}^{2}\\right] $$ $f(x)$を$g_i(x)$に近づけることで，$f$がlow-rank projectorになることを期待 $f$がtarget distribution specificな特徴を獲得する 推論時にはscoreとして下を用いる $$ \\left|f(x)-g_{0}(x)\\right|_2^2 $$ VQ-VAEやRNDではtarget distribution specificな特徴を獲得できていないため，blurred dataでも高い尤度を持つ   4. どうやって有効だと検証した？  Cifar-10, TinyImageNet, LSUN, CelebAで実験 Cifar-10がtargetなら，他はOoDといったようにして実験  $fpr@tpr=0.95$で評価 (異常検知でいうところの5%見逃し許容したときの過検出率)  SVD-RNDは学習枚数が少なくても精度が優秀   5. 議論はあるか？  5章で更に検証してるけど，詳細は気が向いたら $K_1=28$とかは記述あるけど，$K_2$は29とかでいいんだろうか？ ICLR2020 accept  6. 次に読むべき論文はある？  Burda, Y., Edwards, H., Storkey, A., \u0026amp; Klimov, O. (2018). Exploration by Random Network Distillation. Retrieved from https://arxiv.org/abs/1810.12894  ","date":1579532400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579532400,"objectID":"7b615c098bfafac7df75b5f63005387c","permalink":"https://salty-vanilla.github.io/portfolio/post/svdrnd/","publishdate":"2020-01-21T00:00:00+09:00","relpermalink":"/portfolio/post/svdrnd/","section":"post","summary":"1. どんなもの？  OoD Detectionの枠組み 入力をSVD + 特異値0埋めでBlurして，low-rank projectorとなるようなNNを学習 ↑のようなNNを用いることで，target distribution specificな特徴を抽出  2. 先行研究と比べてどこがすごい？  従来のOoD Detectionの手法では，OoDなデータに対しても高い尤度を持つことが多々あった 幾何変換は使わないので，幾何的な意味を持たないDomainにも適用できそう  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  入力をSVD + 特異値0埋めでBlur low-rank projectorとなるようなNN  GENERATING BLURRED DATA  変数の定義  target distribution (training dataset): $D$ training data sample: $d \\in \\mathbb{R}^{H \\times W \\times i}$ $d$の$j$番目のチャネル画像$d_j$のnonzero singular values: $[ \\sigma_{j1}, \\sigma_{j2}, \\cdots, \\sigma_{jN_j} ]$ $d_j$のnonzero singular valuesの数: N_j   $d_j$をSVDすると $$ d_{j}=\\Sigma_{t=1}^{N_{j}} \\sigma_{j t} u_{j t} v_{j t}^{T} $$ $[ \\sigma_{j1}, \\sigma_{j2}, \\cdots, \\sigma_{jN_j} ]$ のbottom $K$個を0にして，復元するとBlurredなデータが生成される  rankが落ちるから    OOD DETECTION VIA SVD-RND  変数の定義  Predictor Network: $f$ $i$番目のbottom K: $K_i$ $i$番目のtarget network: $g_i$ (random networkで学習時に一切更新されない) $i$の個数: $b_{train}$   $b_{train} = 1$のときのモデル構造  Objective $$ f^{*}=\\arg \\min _ {f}\\left[\\Sigma_{x \\in D_{\\text {train }}}\\left|f(x)-g_{0}(x)\\right| _ {2}^{2}+\\Sigma_{i=1}^{b_{\\text {train }}} \\Sigma_{x \\in D_{K_{i}}}\\left|f(x)-g_{i}(x)\\right|_{2}^{2}\\right] $$ $f(x)$を$g_i(x)$に近づけることで，$f$がlow-rank projectorになることを期待 $f$がtarget distribution specificな特徴を獲得する 推論時にはscoreとして下を用いる $$ \\left|f(x)-g_{0}(x)\\right|_2^2 $$ VQ-VAEやRNDではtarget distribution specificな特徴を獲得できていないため，blurred dataでも高い尤度を持つ   4.","tags":null,"title":"Novelty Detection Via Blurring","type":"post"},{"authors":null,"categories":["Continual Learning","Flow Based"],"content":"1. どんなもの？  継続学習の枠組み 1クラスごとに，NICEを学習することで追加クラスに対応  2. 先行研究と比べてどこがすごい？  1クラスごとに学習するので，学習済みのデータは消しても良い クラス数の追加は好きなだけできる catastrophic forgetting を回避  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  クラスごとにNICEを学習することで，OoD問題に持っていく  NICE  invertibleな生成モデル 潜在変数を仮定し，尤度最大化  OvA-INN では標準正規分布を仮定 最大化する対数尤度は下式 $$ l_{i}(x)=\\sum_{d} \\log \\left( p_{d} \\left(f_{i, d}(x)\\right)\\right)=-\\sum_{d} \\frac{1}{2} f_{i, d}(x)^{2}+\\sum_{d} \\log \\left(\\frac{1}{\\sqrt{2 \\pi}}\\right)=-\\frac{1}{2}\\left|f_{i}(x)\\right|_{2}^{2}+\\beta $$    OvA-INN (One vs All - Invertible Neural Networks)  任意のクラス数分のNICEを用意して，それぞれ最適化 クラスそれぞれにNICEがあるので，forgetするわけはない クラス数が増えてもincremental に学習ができる $i$番目のクラスのNICE $f_i$のNLL $$ \\mathcal{L}(\\mathcal{X} _ i)= \\frac{1}{| \\mathcal{X} _ i |} \\sum_{x \\in \\mathcal{X} _ i} |f_{i}(x)|_{2}^{2} $$ OvA-INN の最終的な推論のラベルは $$ y^{*}=\\underset{y=1, \\ldots, t}{\\arg \\min }\\left|f_{y}(x)\\right|_{2}^{2} $$  4. どうやって有効だと検証した？ MNIST  MNISTをincremental に学習させて，Acc算出 従来手法よりも優秀   CIFAR100  クラス数が増えても，精度があまり落ちない   5. 議論はあるか？  クラス数分だけ，NICEがあるならforgetしないのは当たり前では？ Flow based model がOoD 検出には使えないかも？という問題には全く触れていない[1] ICLR2020 reject  6. 次に読むべき論文はある？  Choi, H., Jang, E., \u0026amp; Alemi, A. A. (2018). WAIC, but Why? Generative Ensembles for Robust Anomaly Detection. Retrieved from http://arxiv.org/abs/1810.01392  ","date":1579446000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579446000,"objectID":"723269bf2e51bdd83de01e46eaeed25b","permalink":"https://salty-vanilla.github.io/portfolio/post/ova-inn/","publishdate":"2020-01-20T00:00:00+09:00","relpermalink":"/portfolio/post/ova-inn/","section":"post","summary":"1. どんなもの？  継続学習の枠組み 1クラスごとに，NICEを学習することで追加クラスに対応  2. 先行研究と比べてどこがすごい？  1クラスごとに学習するので，学習済みのデータは消しても良い クラス数の追加は好きなだけできる catastrophic forgetting を回避  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  クラスごとにNICEを学習することで，OoD問題に持っていく  NICE  invertibleな生成モデル 潜在変数を仮定し，尤度最大化  OvA-INN では標準正規分布を仮定 最大化する対数尤度は下式 $$ l_{i}(x)=\\sum_{d} \\log \\left( p_{d} \\left(f_{i, d}(x)\\right)\\right)=-\\sum_{d} \\frac{1}{2} f_{i, d}(x)^{2}+\\sum_{d} \\log \\left(\\frac{1}{\\sqrt{2 \\pi}}\\right)=-\\frac{1}{2}\\left|f_{i}(x)\\right|_{2}^{2}+\\beta $$    OvA-INN (One vs All - Invertible Neural Networks)  任意のクラス数分のNICEを用意して，それぞれ最適化 クラスそれぞれにNICEがあるので，forgetするわけはない クラス数が増えてもincremental に学習ができる $i$番目のクラスのNICE $f_i$のNLL $$ \\mathcal{L}(\\mathcal{X} _ i)= \\frac{1}{| \\mathcal{X} _ i |} \\sum_{x \\in \\mathcal{X} _ i} |f_{i}(x)|_{2}^{2} $$ OvA-INN の最終的な推論のラベルは $$ y^{*}=\\underset{y=1, \\ldots, t}{\\arg \\min }\\left|f_{y}(x)\\right|_{2}^{2} $$  4.","tags":null,"title":"OvA-INN: Continual Learning with Invertible Neural Networks","type":"post"},{"authors":null,"categories":["Representation Learning"],"content":"1. どんなもの？  表現学習の枠組み Denoising Autoencoderをベースにより良い特徴表現を獲得 具体的には，入力データにノイズを付加するのではなくLaplacian Pyramidのrandom level目でノイズを付加する   2. 先行研究と比べてどこがすごい？  通常のDAEより優れた特徴表現の獲得 他の表現学習とは異なり，domain assumptionやpseudo labelを必要としない  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  入力データにノイズを付加するのではなく，Laplacian Pyramidのlevel $l$層目でノイズを付加する $l$層目のLaplacian Pyramid $x_l^L$ は，$l$層目のGaussian Pyramid $x_l^G$ を用いて下式 $$ x_l^L = x_l^G - upsample(x_{l+1}^G) $$ $x_0^G$ は元画像に等しい．上式の $l$ を 0 に向かって繰り返し計算すると元画像が求められる $$ x_l^G = x_l^L + upsample(x_{l+1}^G) $$ この繰り返しの途中でノイズを付加する   algorithmは以下  $c \\in C$ はどんなノイズを付加するかのセットと要素 objectiveは通常のMSE     4. どうやって有効だと検証した？ MNIST  通常のDAEと比較して，input space, laplacian spaceどちらのnoiseに対しても正確に復元できていることがわかる 再構成Lossも低い   CIFAR10  再構成，画像検索共に通常のDAEより高精度   Imagenet  Supervised learningと同じようなconv filterが学習できている  conv層後の特徴を線形分類したときの精度比較．  LapDAEとAET-project[1]を組み合わせた LapDAE + Transが最高精度    Pascal VOCに転移学習しても最高精度   5. 議論はあるか？  単純な方法でより良い特徴表現の獲得に成功している objectiveはMSEのままなのに，blurが軽減されているのはなぜ？ Gaussian pyramidを作る際にGaussian filterはかけてる？  6. 次に読むべき論文はある？  Zhang, L., Qi, G.-J., Wang, L., \u0026amp; Luo, J. (2019). AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data. Retrieved from http://arxiv.org/abs/1901.04596  ","date":1579273200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579273200,"objectID":"20e60eb245d5a34503e17b8a28d01577","permalink":"https://salty-vanilla.github.io/portfolio/post/lapdae/","publishdate":"2020-01-18T00:00:00+09:00","relpermalink":"/portfolio/post/lapdae/","section":"post","summary":"1. どんなもの？  表現学習の枠組み Denoising Autoencoderをベースにより良い特徴表現を獲得 具体的には，入力データにノイズを付加するのではなくLaplacian Pyramidのrandom level目でノイズを付加する   2. 先行研究と比べてどこがすごい？  通常のDAEより優れた特徴表現の獲得 他の表現学習とは異なり，domain assumptionやpseudo labelを必要としない  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  入力データにノイズを付加するのではなく，Laplacian Pyramidのlevel $l$層目でノイズを付加する $l$層目のLaplacian Pyramid $x_l^L$ は，$l$層目のGaussian Pyramid $x_l^G$ を用いて下式 $$ x_l^L = x_l^G - upsample(x_{l+1}^G) $$ $x_0^G$ は元画像に等しい．上式の $l$ を 0 に向かって繰り返し計算すると元画像が求められる $$ x_l^G = x_l^L + upsample(x_{l+1}^G) $$ この繰り返しの途中でノイズを付加する   algorithmは以下  $c \\in C$ はどんなノイズを付加するかのセットと要素 objectiveは通常のMSE     4. どうやって有効だと検証した？ MNIST  通常のDAEと比較して，input space, laplacian spaceどちらのnoiseに対しても正確に復元できていることがわかる 再構成Lossも低い   CIFAR10  再構成，画像検索共に通常のDAEより高精度   Imagenet  Supervised learningと同じようなconv filterが学習できている  conv層後の特徴を線形分類したときの精度比較．  LapDAEとAET-project[1]を組み合わせた LapDAE + Transが最高精度    Pascal VOCに転移学習しても最高精度   5.","tags":null,"title":"Laplacian Denoising Autoencoder","type":"post"},{"authors":null,"categories":["GAN"],"content":"1. どんなもの？  StyleGANのver2 StyleGANの問題の問題を改善 FIDの向上に加えて，PPL: Perceptual Path Lengthも向上  2. 先行研究と比べてどこがすごい？  StyleGANの問題であった水滴状のノイズ，潜在変数を走査しても顔のパーツが自然に変化しないなどの問題を改善 Instance Normの見直し，Progressive Growingの見直し，PPLの導入  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Revisit Instance Norm  StyleGANでは雨粒状のノイズ (artifact)が現れていた 原因はAdaINの演算    NVIDIAの動画がわかりやすい     この原因は Instance Norm にあり\n INは各feature mapの平均と分散で正規化 絶対値が小さくてもスパイク状の分布のfeature mapがあるとartifactが出てしまう INを無くせば，artifactが出ないらしい    a. StyleGAN\nb. StyleGANの詳細\nc. INのartifactを考慮した形\n A(mapping networkの出力$f(z)$)，conv後のstdのみを使うように変更 B(noise image)のaddはBlockの外に出した  d. (c)のoperationをweight demodulationで簡易化\n AのAdaINではAのstdで割り算していた これをfeature mapに対して割り算するのではなく，convのweightに対して割り算することで等価の演算に $s$はAをaffineして得られたスケールベクトル，$w \\in \\mathbb{R} ^{{ch_{in}} \\times {ch_{out}} \\times {hw}}$はconvのweight $$ w_{ijk}^{\\prime} = s_i \\cdot w_{ijk} $$ $$ w_{ijk}^{\\prime\\prime} = \\frac{w_{ijk}^{\\prime}}{\\sqrt{\\Sigma_{i,k}{{w_{ijk}^{\\prime}}^2 + \\epsilon}}} $$ 入力が標準偏差1のrandom variableであることを仮定している．これは$\\sigma$割っていることと同義 $$ \\sigma_j = \\sqrt{\\Sigma_{i,k}{{w_{ijk}^{\\prime}}^2}} $$  Image quality and generator smoothness While Perceptual Path Length  潜在空間のPerceptual Path Length: PPLが小さい ⇔ 生成のQuality高い PPLを正則化項として追加する $$ \\mathbb{E}_{w,y \\sim N(0,\\mathbf{I})} ( ||\\mathbf{J_w^T y}|| - a)^2 $$ $$ \\mathbf{J_w^T y} = \\nabla_w(g(w) \\cdot y) $$   Lazy Reguralization  loss関数は，logistic lossと$R_1$[1] $R_1$は毎ミニバッチごとに算出しなくても，16ミニバッチごとくらいでいいよということ それがlazy  Revisiting Progressive Growing   StyleGANでは，顔のパーツが潜在変数の変化に追従しないという問題あり\n 画像では，顔の向きが変わっているのに口が変わっていない     これは，StyleGANのProgressive Growing構造によるもの\n 各resolutionのGを段階的に学習することで，Gのレイヤは高周波成分を出力するように その結果，GがShift invarianceを失ってしまう    代替の構造として以下の(b),(c)を使う\n Generatorは(b) Discriminatorは(c)    4. どうやって有効だと検証した？   全工夫の有効性は   weight demodulationの有効性は以下\n artifactが消えたのがわかる     PPLの有効性は以下\n PPLが小さくなっている     PGに替わる構造の有効性は以下\n GとDにskipとresidualを選んだのはこの表から     生成は以下   5. 議論はあるか？  PG構造なくしたのはGood．非常に簡潔になった AdaINによるartifactへの対処としてのweight modulationも簡潔 しかし，依然として学習時間はDGX-1で13days  6. 次に読むべき論文はある？  Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for GANs do actually converge? CoRR, abs/1801.04406, 2018. 5, 10 Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proc. CVPR, 2018. 1, 2, 4, 10, 12, 16 Animesh Karnewar, Oliver Wang, and Raghu Sesha Iyengar. MSG-GAN: multi-scale gradient GAN for stable image syn- thesis. CoRR, abs/1903.06048, 2019. 6  ","date":1577631600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577631600,"objectID":"aae105df73d88d47c774b8b0e940e650","permalink":"https://salty-vanilla.github.io/portfolio/post/stylegan2/","publishdate":"2019-12-30T00:00:00+09:00","relpermalink":"/portfolio/post/stylegan2/","section":"post","summary":"1. どんなもの？  StyleGANのver2 StyleGANの問題の問題を改善 FIDの向上に加えて，PPL: Perceptual Path Lengthも向上  2. 先行研究と比べてどこがすごい？  StyleGANの問題であった水滴状のノイズ，潜在変数を走査しても顔のパーツが自然に変化しないなどの問題を改善 Instance Normの見直し，Progressive Growingの見直し，PPLの導入  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Revisit Instance Norm  StyleGANでは雨粒状のノイズ (artifact)が現れていた 原因はAdaINの演算    NVIDIAの動画がわかりやすい     この原因は Instance Norm にあり\n INは各feature mapの平均と分散で正規化 絶対値が小さくてもスパイク状の分布のfeature mapがあるとartifactが出てしまう INを無くせば，artifactが出ないらしい    a. StyleGAN\nb. StyleGANの詳細\nc. INのartifactを考慮した形\n A(mapping networkの出力$f(z)$)，conv後のstdのみを使うように変更 B(noise image)のaddはBlockの外に出した  d. (c)のoperationをweight demodulationで簡易化\n AのAdaINではAのstdで割り算していた これをfeature mapに対して割り算するのではなく，convのweightに対して割り算することで等価の演算に $s$はAをaffineして得られたスケールベクトル，$w \\in \\mathbb{R} ^{{ch_{in}} \\times {ch_{out}} \\times {hw}}$はconvのweight $$ w_{ijk}^{\\prime} = s_i \\cdot w_{ijk} $$ $$ w_{ijk}^{\\prime\\prime} = \\frac{w_{ijk}^{\\prime}}{\\sqrt{\\Sigma_{i,k}{{w_{ijk}^{\\prime}}^2 + \\epsilon}}} $$ 入力が標準偏差1のrandom variableであることを仮定している．これは$\\sigma$割っていることと同義 $$ \\sigma_j = \\sqrt{\\Sigma_{i,k}{{w_{ijk}^{\\prime}}^2}} $$  Image quality and generator smoothness While Perceptual Path Length  潜在空間のPerceptual Path Length: PPLが小さい ⇔ 生成のQuality高い PPLを正則化項として追加する $$ \\mathbb{E}_{w,y \\sim N(0,\\mathbf{I})} ( ||\\mathbf{J_w^T y}|| - a)^2 $$ $$ \\mathbf{J_w^T y} = \\nabla_w(g(w) \\cdot y) $$   Lazy Reguralization  loss関数は，logistic lossと$R_1$[1] $R_1$は毎ミニバッチごとに算出しなくても，16ミニバッチごとくらいでいいよということ それがlazy  Revisiting Progressive Growing   StyleGANでは，顔のパーツが潜在変数の変化に追従しないという問題あり","tags":null,"title":"Analyzing and Improving the Image Quality of StyleGAN","type":"post"},{"authors":null,"categories":["Time Series"],"content":"1. どんなもの？  音の生波形から，eventのclassificationを行う raw waveformを1D CNNで周波数解析し，得られたTransformed Imageを2D CNNで識別 training dataが少ない場合でも有効なMix-trainingを提案  2. 先行研究と比べてどこがすごい？  Audio ClassificationはGoogleのBottleneck featureを使った識別，Handcrafted featureを使った識別がBaselineだった Bottleneckは情報のlostが，Handcraftedは抽出の困難さが問題 end-to-endな周波数特徴の抽出，識別を可能に  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  キモは，周波数特徴を抽出する1D CNNとその特徴を識別する2D CNN  Raw-waveforms-based network 1D CNN  1D CNNで時間方向にdownsamplingをかけることで，周波数特徴を抽出 FFTをNNに任せてるイメージで，識別に適した周波数特徴を抽出してくれることを期待 最終的には，$C \\times 1 \\times T$ (channel, 1, time)のfeature mapをtransposeして，$1 \\times C \\times T$ (1, channel, time)の画像に  2D CNN  得られた周波数特徴画像を2D Convolution 勾配消失を防ぐため，multi-resolutionalなfeature mapからpredictionを出力 attentionつき（attentionは多分，以下の構造）   Avg Poolは多分GAP．．．？  Mix-training strategy  training dataが少ない場合に有効なMix-training．pretraining的な扱い 2つの入力を$\\alpha \\in (0, 1)$でblend  $$ \\tilde{x}_k = \\alpha x_i + (1-\\alpha) x_j $$\n $\\tilde{x}_k$に対応する教師ラベルは以下（$y_i$,$y_j$はmulti-hot label)  $$ \\tilde{y}_k = sign(y_i + y_j) $$\n loss関数は  $$ L=-\\frac{1}{K} \\sum_{k, n} \\left(1-\\tilde{y}_{k n}\\right) \\log \\left(1-t_{k n}\\right)+\\tilde{y}_{k n} \\log t_{k n} $$\n$$ \\mathbf{t_k} = f_\\theta (\\tilde{x}_k) = [ t_{k1}, t_{k2}, \u0026hellip;, t_{kN} ] $$\n Mix-trainingが終わった後にはmixしないデータでfine-tuning  4. どうやって有効だと検証した？  Audio SetでBaselineとの精度比較 精度的には負けてるが，pretrainingなしなのはgoodかも   mix-trainingの有効性確認も mix-upよりも高精度  5. 議論はあるか？  周波数特徴画像にFFTのような説明性はあるか？ mix-trainingの教師データの総和が1にならないが良いのか．．． stemのConv 1x7は妥当か？  6. 次に読むべき論文はある？  Yu, C., Barsim, K. S., Kong, Q., \u0026amp; Yang, B. (2018). Multi-level Attention Model for Weakly Supervised Audio Classification. Retrieved from http://arxiv.org/abs/1803.02353 Zhang, H., Cisse, M., Dauphin, Y. N., \u0026amp; Lopez-Paz, D. (2017). mixup: Beyond Empirical Risk Minimization. Retrieved from https://arxiv.org/abs/1710.09412  ","date":1577026800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577026800,"objectID":"06e15f630c9d2aa98227d3509e99fcb6","permalink":"https://salty-vanilla.github.io/portfolio/post/an_end-to-end_audio_classification_system_based_on_raw_waveforms_and_mix-training_strategy/","publishdate":"2019-12-23T00:00:00+09:00","relpermalink":"/portfolio/post/an_end-to-end_audio_classification_system_based_on_raw_waveforms_and_mix-training_strategy/","section":"post","summary":"1. どんなもの？  音の生波形から，eventのclassificationを行う raw waveformを1D CNNで周波数解析し，得られたTransformed Imageを2D CNNで識別 training dataが少ない場合でも有効なMix-trainingを提案  2. 先行研究と比べてどこがすごい？  Audio ClassificationはGoogleのBottleneck featureを使った識別，Handcrafted featureを使った識別がBaselineだった Bottleneckは情報のlostが，Handcraftedは抽出の困難さが問題 end-to-endな周波数特徴の抽出，識別を可能に  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  キモは，周波数特徴を抽出する1D CNNとその特徴を識別する2D CNN  Raw-waveforms-based network 1D CNN  1D CNNで時間方向にdownsamplingをかけることで，周波数特徴を抽出 FFTをNNに任せてるイメージで，識別に適した周波数特徴を抽出してくれることを期待 最終的には，$C \\times 1 \\times T$ (channel, 1, time)のfeature mapをtransposeして，$1 \\times C \\times T$ (1, channel, time)の画像に  2D CNN  得られた周波数特徴画像を2D Convolution 勾配消失を防ぐため，multi-resolutionalなfeature mapからpredictionを出力 attentionつき（attentionは多分，以下の構造）   Avg Poolは多分GAP．．．？  Mix-training strategy  training dataが少ない場合に有効なMix-training．pretraining的な扱い 2つの入力を$\\alpha \\in (0, 1)$でblend  $$ \\tilde{x}_k = \\alpha x_i + (1-\\alpha) x_j $$","tags":null,"title":"An End-to-End Audio Classification System based on Raw Waveforms and Mix-Training Strategy","type":"post"},{"authors":null,"categories":["Normalization"],"content":"1. どんなもの？  pixelごとにチャネル方向に串刺しにして正規化する系の正規化手法 Encoder-Decoder構造（Domain transferなど）に適用すると良い生成  2. 先行研究と比べてどこがすごい？  BN，LN，INなどとは違って，空間解像度を保った正規化なのでstructuralな情報が残せる もちろん収束は早くなるし，安定もする  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Positional Normalization  feature mapの各Pixel（position)ごとにチャネル方向にstaticsを求める つまり，staticsのshapeは（b, h, w)  $$ \\mu_{b, h, w}=\\frac{1}{C} \\sum_{c=1}^{C} X_{b, c, h, w}, \\quad \\sigma_{b, h, w}=\\sqrt{\\frac{1}{C} \\sum_{c=1}^{C}\\left(X_{b, c, h, w}^{2}-\\mu_{b, h, w}\\right)+\\epsilon} $$\n$$ X_{b, c, h, w}^{\\prime}=\\gamma\\left(\\frac{X_{b, c, h, w}-\\mu}{\\sigma}\\right)+\\beta $$\n VGGにponoを差し込んでみると，画像の構造をstaticsが捉えているように見える  ただDenseNetでは，map端に望まない反応が見られる   Moment Shortcut  Encoder-Decoder構造において，Encoderのponoで得られたstd $\\sigma$を$\\gamma$，mean $\\mu$を$\\beta$として $$ x\u0026rsquo; = \\gamma x + \\beta $$ CycleGANやPix2Pixで有効 $\\mu$,$\\sigma$に対して，convして，$\\beta,\\gamma \\in \\mathbb{R}^{B \\times H \\times W \\times C}$にしてからAffineするDynamic Moment Shortcutも提案  4. どうやって有効だと検証した？  Domain transfer (Map \u0026lt;-\u0026gt; Photo, Horse \u0026lt;-\u0026gt; Zebra)で実験 CycleGAN (baseline)を上回るのはもちろん，SPADEにも勝っている parameter数も少ない  5. 議論はあるか？  情報量的には軽量版Unetと感じた Unetはパラメータ数，計算量も格段に多くなるのでGood MUNITはlatent spaceにたどり着かないかもしれない情報がでるけど，大丈夫なのか  6. 次に読むべき論文はある？ ","date":1576508400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576508400,"objectID":"80400532f5ef19e07cb1962865a07008","permalink":"https://salty-vanilla.github.io/portfolio/post/pono/","publishdate":"2019-12-17T00:00:00+09:00","relpermalink":"/portfolio/post/pono/","section":"post","summary":"1. どんなもの？  pixelごとにチャネル方向に串刺しにして正規化する系の正規化手法 Encoder-Decoder構造（Domain transferなど）に適用すると良い生成  2. 先行研究と比べてどこがすごい？  BN，LN，INなどとは違って，空間解像度を保った正規化なのでstructuralな情報が残せる もちろん収束は早くなるし，安定もする  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Positional Normalization  feature mapの各Pixel（position)ごとにチャネル方向にstaticsを求める つまり，staticsのshapeは（b, h, w)  $$ \\mu_{b, h, w}=\\frac{1}{C} \\sum_{c=1}^{C} X_{b, c, h, w}, \\quad \\sigma_{b, h, w}=\\sqrt{\\frac{1}{C} \\sum_{c=1}^{C}\\left(X_{b, c, h, w}^{2}-\\mu_{b, h, w}\\right)+\\epsilon} $$\n$$ X_{b, c, h, w}^{\\prime}=\\gamma\\left(\\frac{X_{b, c, h, w}-\\mu}{\\sigma}\\right)+\\beta $$\n VGGにponoを差し込んでみると，画像の構造をstaticsが捉えているように見える  ただDenseNetでは，map端に望まない反応が見られる   Moment Shortcut  Encoder-Decoder構造において，Encoderのponoで得られたstd $\\sigma$を$\\gamma$，mean $\\mu$を$\\beta$として $$ x\u0026rsquo; = \\gamma x + \\beta $$ CycleGANやPix2Pixで有効 $\\mu$,$\\sigma$に対して，convして，$\\beta,\\gamma \\in \\mathbb{R}^{B \\times H \\times W \\times C}$にしてからAffineするDynamic Moment Shortcutも提案  4.","tags":null,"title":"POSITIONAL NORMALIZATION","type":"post"},{"authors":null,"categories":["GAN"],"content":"1. どんなもの？  GANのIS，FIDを向上させる系の論文 BigGANベースに大きなアーキテクチャの変更なしに高精度な生成．  2. 先行研究と比べてどこがすごい？  ベースはBigGAN 潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新することでhigh qualityとdiversityを実現  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  キモは，潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新すること  Latent Optimisation  潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新する $$ \\Delta z = \\alpha \\frac{\\partial f(z)}{\\partial z} $$ $$ z\u0026rsquo; = z + \\Delta z $$ ここで，f(z)は$z$をGeneratorに入力し得られたデータをDiscriminatorに与えることで得られる出力  Natural Gradient Descent  更新する$z$の空間はユークリッド空間でないことが多い． 通常の勾配法ではうまく更新できないことがある． 自然勾配法を用いて$z$を更新する．  $$ \\Delta z = \\alpha F^{-1} \\frac{\\partial f(z)}{\\partial z} = \\alpha F^{-1}g $$\n ここで，$F$はフィッシャー情報行列 $F$の算出はcost大なので，近似すると($\\beta$はハイパラの定数)  $$ F\u0026rsquo; = g \\cdot g^T + \\beta I $$\n$$ \\Delta z=\\alpha\\left(\\frac{I}{\\beta}-\\frac{g g^{T}}{\\beta^{2}+\\beta g^{T} g}\\right) g=\\frac{\\alpha}{\\beta}\\left(1-\\frac{|g|^{2}}{\\beta+|g|^{2}}\\right) g $$\n4. どうやって有効だと検証した？ Imagenetの生成で実験． baseline(a)よりLOGAN(b)の方がdiversityのある生成ができている． 5. 議論はあるか？  $z$を更新するだけでここまで精度が上がるのは驚き ただ，baselineがBigGANなので庶民には手が出せない dynamicの話とかappendixについては，まだ見れてない  6. 次に読むべき論文はある？ ","date":1575903600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575903600,"objectID":"c40cd8a18661325b199914c865982a3a","permalink":"https://salty-vanilla.github.io/portfolio/post/logan/","publishdate":"2019-12-10T00:00:00+09:00","relpermalink":"/portfolio/post/logan/","section":"post","summary":"1. どんなもの？  GANのIS，FIDを向上させる系の論文 BigGANベースに大きなアーキテクチャの変更なしに高精度な生成．  2. 先行研究と比べてどこがすごい？  ベースはBigGAN 潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新することでhigh qualityとdiversityを実現  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  キモは，潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新すること  Latent Optimisation  潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新する $$ \\Delta z = \\alpha \\frac{\\partial f(z)}{\\partial z} $$ $$ z\u0026rsquo; = z + \\Delta z $$ ここで，f(z)は$z$をGeneratorに入力し得られたデータをDiscriminatorに与えることで得られる出力  Natural Gradient Descent  更新する$z$の空間はユークリッド空間でないことが多い． 通常の勾配法ではうまく更新できないことがある． 自然勾配法を用いて$z$を更新する．  $$ \\Delta z = \\alpha F^{-1} \\frac{\\partial f(z)}{\\partial z} = \\alpha F^{-1}g $$\n ここで，$F$はフィッシャー情報行列 $F$の算出はcost大なので，近似すると($\\beta$はハイパラの定数)  $$ F\u0026rsquo; = g \\cdot g^T + \\beta I $$","tags":null,"title":"LOGAN: Latent Optimisation for Generative Adversarial Networks","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  Autoencoder（差分ベース）の異常検知モデル 潜在変数にMemory構造を導入することで正常データ以外も復元できてしまう”汎化”を防ぐ  2. 先行研究と比べてどこがすごい？  Autoencoderを使った異常検知では，モデルが汎化してしまい異常データまでも復元できてしまう問題があった 潜在変数にMemory構造を追加することで，正常データの分布内のデータしか復元できないようにした  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Memory構造がキモ  全体の流れ  Encoderからまず$z$を得る $$ z = f_e(x; \\theta_e) $$ メモリ構造を用いて$\\hat{z}$を得る（後述） Decoderで$\\hat{z}$から復元する  $$ \\hat{x} = f_d(\\hat{z}; \\theta_d) $$\nMemory   それぞれ変数を定義する\n $M \\in \\mathbb{R}^{N \\times C}$: Memory行列 $m_i$: $M$の$i$行目Vector $N$: メモリ数 $C$: $\\hat{z}$の次元数（論文内では$z$の次元数と一致） $w \\in \\mathbb{R}^{1 \\times N} $: Attention Weight Vector    Encoderから得られた$z$と$m_i$の距離（内積）を算出して，softmaxすることで$w$を求める $$ w_i = \\frac{\\exp(d(z, m_i))}{\\Sigma^N_{j=1}\\exp(d(z, m_j))} $$\n  $$ d(z, m_i) = \\frac{zm_i^T}{|z||m_i|} $$\n $\\hat{z}$を求める $$ \\hat{z} = wM = \\Sigma^N_{i=1}w_im_i $$  Hard Shrinkage for Sparse Addressing 上述のMemory構造でも復元できてしまう異常サンプルは出てくるので，$w$をスパースにすることでより制限する\n\\[ \\hat{w}_i = \\begin{cases} w_i \u0026amp; \\text{ if } w_i \u0026gt; \\lambda \\\\ 0 \u0026amp; \\text{ otherwise } \\end{cases} \\]\nObjective 再構成誤差と$\\hat{w}$そスパースにするための誤差の重み付き和 $$ L(\\theta_e, \\theta_d, M) = \\frac{1}{T} \\Sigma^T_{t=1}[R(x^t, \\hat{x}^t) + \\alpha E(\\hat{w}^t)] $$\n$$ R(x^t, \\hat{x}^t) = |x^t - \\hat{x}^t| ^2 $$\n$$ E(\\hat{w}^t) = \\Sigma^T_{i=1}-\\hat{w}^t\\log{\\hat{w}^t} $$\n論文内では,$\\alpha = 0.0002$\n4. どうやって有効だと検証した？ 画像では，MNIST・Cifar10で実験 動画では，UCSD-Ped2・CUHK・ShanghaiTechで実験 5. 議論はあるか？  汎化にスポット当てた論文でgood MVTec で実験してみたい  6. 次に読むべき論文はある？ ","date":1575903600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575903600,"objectID":"8897429e0892f9f34304db2a3f79d713","permalink":"https://salty-vanilla.github.io/portfolio/post/memorizing_normality_to_detect_anomaly_memory-augmented_deep_autoencoder_for_unsupervised_anomaly_detection/","publishdate":"2019-12-10T00:00:00+09:00","relpermalink":"/portfolio/post/memorizing_normality_to_detect_anomaly_memory-augmented_deep_autoencoder_for_unsupervised_anomaly_detection/","section":"post","summary":"1. どんなもの？  Autoencoder（差分ベース）の異常検知モデル 潜在変数にMemory構造を導入することで正常データ以外も復元できてしまう”汎化”を防ぐ  2. 先行研究と比べてどこがすごい？  Autoencoderを使った異常検知では，モデルが汎化してしまい異常データまでも復元できてしまう問題があった 潜在変数にMemory構造を追加することで，正常データの分布内のデータしか復元できないようにした  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Memory構造がキモ  全体の流れ  Encoderからまず$z$を得る $$ z = f_e(x; \\theta_e) $$ メモリ構造を用いて$\\hat{z}$を得る（後述） Decoderで$\\hat{z}$から復元する  $$ \\hat{x} = f_d(\\hat{z}; \\theta_d) $$\nMemory   それぞれ変数を定義する\n $M \\in \\mathbb{R}^{N \\times C}$: Memory行列 $m_i$: $M$の$i$行目Vector $N$: メモリ数 $C$: $\\hat{z}$の次元数（論文内では$z$の次元数と一致） $w \\in \\mathbb{R}^{1 \\times N} $: Attention Weight Vector    Encoderから得られた$z$と$m_i$の距離（内積）を算出して，softmaxすることで$w$を求める $$ w_i = \\frac{\\exp(d(z, m_i))}{\\Sigma^N_{j=1}\\exp(d(z, m_j))} $$","tags":null,"title":"Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection","type":"post"},{"authors":null,"categories":["Anomaly Detection","VAE"],"content":"1. どんなもの？ Autoencoderベースの異常検知手法．Autoencoderの問題である画像内の一部の異常が画像全体の復元に影響を与えてしまい上手く異常部位をLocalicationできないという問題にタックル．\n2. 先行研究と比べてどこがすごい？  Autoencoderベースのモデルでは，異常画像が入力された際に異常部位以外も再構成が崩れてしまい上手くLocalizationできないという問題があった また，Blurが発生してしまう 上記2点を繰り返し，$x$を更新していく方法で解決する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？   エネルギー関数は，再構成誤差($L_r$)と正則化項（更新しても原画像から離れすぎないようにする正則化） $$ E(x_t) = L_r(x_t) + \\lambda|| x_t - x_0 || $$ $$ L_r(x_t) = \\mathbb{E} [ | f_{VAE}(x_t) - x_t | ^r ] $$\n  エネルギー関数を最小化するように，入力画像$x_0$を更新していく $$ x_{t+1} = x_t - \\alpha \\nabla_x E(x_t) $$\n  再構成が大きい部位は更新量を大きく，小さい部位は小さくすればなお良し $$ x_{x+1} = x_t - \\alpha ( \\nabla_xE(x_t) \\odot | f_{VAE}(x_t) - x_t | ^2 ) $$\n  つまるところ，学習済みのVAEを用意して，テストデータを繰り返し入力・更新して元のManifoldにより近づけるイメージ （近いモデルはAnoGAN）\n  4. どうやって有効だと検証した？   MVTECに対して，実験\n  それぞれ ***-gradが提案手法   通常のAutoencoderより，適切に異常部位のLocalizationができていることを確認   5. 議論はあるか？  iterativeにすることで推論時間はどのくらいになる？ AnoGANと似たようなmethodだが，比較は？  6. 次に読むべき論文はある？  Bin Dai and David P. Wipf. Diagnosing and enhancing VAE models. CoRR, abs/1903.05789, 2019. Ian  ","date":1575817200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575817200,"objectID":"2c63b045ec3d2c60a3dba4a7d4959a99","permalink":"https://salty-vanilla.github.io/portfolio/post/iterative_energy-based_projection_on_a_normal_data_manifold_for_anomaly_localization/","publishdate":"2019-12-09T00:00:00+09:00","relpermalink":"/portfolio/post/iterative_energy-based_projection_on_a_normal_data_manifold_for_anomaly_localization/","section":"post","summary":"1. どんなもの？ Autoencoderベースの異常検知手法．Autoencoderの問題である画像内の一部の異常が画像全体の復元に影響を与えてしまい上手く異常部位をLocalicationできないという問題にタックル．\n2. 先行研究と比べてどこがすごい？  Autoencoderベースのモデルでは，異常画像が入力された際に異常部位以外も再構成が崩れてしまい上手くLocalizationできないという問題があった また，Blurが発生してしまう 上記2点を繰り返し，$x$を更新していく方法で解決する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？   エネルギー関数は，再構成誤差($L_r$)と正則化項（更新しても原画像から離れすぎないようにする正則化） $$ E(x_t) = L_r(x_t) + \\lambda|| x_t - x_0 || $$ $$ L_r(x_t) = \\mathbb{E} [ | f_{VAE}(x_t) - x_t | ^r ] $$\n  エネルギー関数を最小化するように，入力画像$x_0$を更新していく $$ x_{t+1} = x_t - \\alpha \\nabla_x E(x_t) $$\n  再構成が大きい部位は更新量を大きく，小さい部位は小さくすればなお良し $$ x_{x+1} = x_t - \\alpha ( \\nabla_xE(x_t) \\odot | f_{VAE}(x_t) - x_t | ^2 ) $$","tags":null,"title":"Iterative energy-based projection on a normal data manifold for anomaly localization","type":"post"},{"authors":null,"categories":null,"content":"   はじめに 工業製品の製造工程において，出荷製品の品質安定化のために検査は必要不可欠である． とくに外観検査工程では人による目視検査が主であるが，検査員毎の判断基準のばらつきが長年の課題であった． 近年では深層学習技術の進歩により，これまで困難とされてきた目視検査工程でも自動化が検討されている． 従来の深層学習では正常品と異常品を識別するために大量のサンプルが必要であるが，現実には大量の異常品を確保することは困難である． そのため，正常品のみ，もしくは正常品と少数の異常品から良否識別できる枠組みが求められている． また，画像検査においては，1枚の異常画像の中に正常な領域と異常な領域が混在していることがある． このとき，異常な領域が占める割合が大きければ，検出は容易であるが，小さい場合は難しい． また，異常には様々な種類が存在し，それぞれを検出するのに適した解像度が存在するはずである． そのため，本稿ではComplementary GANに Multi-scale Patch の枠組みを加えたモデルに正常品のみを学習させ，正常分布とその補集合分布をモデリングし異常検知を行う手法を提案する．\n従来のNNを使った異常検知 差分ベース  Autoencoder AnoGAN ADGAN  メリット  差分ベースなので，欠陥箇所のLocalizationが可能 学習が容易  デメリット  外観検査においては差分の出づらい欠陥が存在する Blurが発生し，高周波成分が差分として現れてしまう    潜在変数ベース  Flow-based Model Adversarial Autoencoder  メリット  異常度を対数尤度としてダイレクトに算出できる 潜在変数による低次元データの可視化が可能  デメリット  欠陥情報が消失してしまう Out of distributionのデータでも尤度が高くなってしまうことがある．    Complementary GAN そもそもGANとは？  GeneratorとDiscriminatorの2つのNetworkを持つ Generatorは，Discriminatorを騙すように本物に近いデータを生成する Discriminatorは，入力が本物のデータなのか・Generatorによって生成された偽のデータなのかを識別する GeneratorとDiscriminatorが↑の学習をすることで，Generatorは本物に近いデータを生成できるようになる．  結局GANは何を学習している？  Discriminatorは生成分布とデータ分布の”離れ度合い”を測るDivergence Estimator Generatorは算出された”離れ度合い”を最小化する その結果，生成分布とデータ分布が近づいていき，本物に近い画像が生成できる  Discriminatorの出力って異常検知に使える？  Discriminatorは，本物と偽物が見極められるので，本物を正常データとすれば，正常/異常が分別できるのでは！？という考え それは難しい Discriminatorが識別しているのは，本物のデータであるか偽物のデータであって，偽物データの中に異常分布の要素は全く含まれていない  GANとComplementary GANの違いは？  GANはデータ分布と生成分布を測り，近づける Complementary GANはデータ分布と生成分布を測り，データ分布の補集合分布と生成分布を近づける つまり，Complementary GANは正常データには存在しないデータを生成し，Discriminatorは正常と正常ではないの識別境界となる  Multi-scale Patch Discriminator  外観検査では，欠陥の大きさは様々 CNNで，Conv + Poolingを積み重ねていくと小さい欠陥の情報は消えてしまう かといって，浅すぎるCNNでは識別はできない  そこで，Discriminatorの出力を[0, 1]のスカラーではなく，正常度MAPとすることで↑の問題に対処する\n実験 LEDチップ画像 サンプル データ内訳     良品 不良品     training 70000 0   test 10000 204    生成された補集合画像  不良品画像とは一致しないが，良品画像には近いが良品ではないものが生成できていることを確認    Discriminatorによる異常度MAP  赤に近いほど異常度が大きく，青に近いほど異常度が低い 各行左から，入力・8x8 MAP・4x4 MAP・2x2 MAP 8x8 MAPでは小さい欠陥が，2x2 MAPでは面積の大きい欠陥が検出される    精度   Reference  Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … Bengio, Y. (2014). Generative Adversarial Nets. Advances in Neural Information Processing Systems, 2672–2680. Zheng, P., Yuan, S., Wu, X., Li, J., \u0026amp; Lu, A. (2018). One-Class Adversarial Nets for Fraud Detection. ArXiv Preprint ArXiv:1803.01798. Bergmann, P., Fauser, M., Sattlegger, D., \u0026amp; Steger, C. (2019). MVTec AD \u0026ndash; A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Karras, T., Laine, S., \u0026amp; Aila, T. (2018). A Style-Based Generator Architecture for Generative Adversarial Networks. Retrieved from https://arxiv.org/abs/1812.04948  ","date":1575126000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575126000,"objectID":"92ac6e90d5886054b39de0842a0ca6ac","permalink":"https://salty-vanilla.github.io/portfolio/project/visual_inspection/","publishdate":"2019-12-01T00:00:00+09:00","relpermalink":"/portfolio/project/visual_inspection/","section":"project","summary":"工業部品や食品の外観検査をニューラルネットワークによって自動化","tags":null,"title":"Visual Inspection","type":"project"},{"authors":null,"categories":null,"content":"1. どんなもの？ Metric Learningの論文．分類をして，各クラス内の分散を小さく，クラス間の分散を大きくする系のMetric Learining．\n2. 先行研究と比べてどこがすごい？  クラス分類モデルのSoftmaxを少し改良するだけで適用できる ArcFaceと先行研究のSpehereFace・CosFaseのLoss関数は似ていて，それを一般化している  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Architecture 全体的な流れとしては， Base Block（VGGとかResNetとか）から特徴ベクトルを出力\n\\[ x' = f(x) \\]\n出力された特徴ベクトルをL2正則化\n\\[ x'' = \\frac{x'}{|x'|^2} \\]\n全結合層の重みをL2正則化\n\\[ w' = \\frac{w}{|w|^2} \\]\n正則化された特徴ベクトルと重みを内積（これがcosの値）\n\\[ cos\\theta = x'' \\cdot w' \\]\nこれにAdditive Angular Margin Penaltyを適用する．\nAdditive Angular Margin Penalty Additive Angular Margin Penaltyは正解ラベルに対応する出力の値に対して，Marginを加えることで，クラス内分散を小さくするような学習を行う． イメージとしては，正解ラベルにのみ厳しい罰則を与えてよりDiscriminativeにする感じ．\n正解クラス\\(j\\)の出力に対して，Marginを加算する\n\\[ \\theta_j' = \\{ \\begin{array}{ll} arccos(cos\\theta_i) + m \u0026 i=j \\\\ arccos(cos\\theta_i) \u0026 otherwise \\end{array} \\]\n各要素を定数倍する（温度パラメータ）\n\\[ logit = s cos(\\theta_j') \\]\nsoftmax関数にかける\n\\[ y = softmax(logit) \\]\nこの一連の流れを組み込んだLoss関数は\n\\[ L_{3}=-\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{e^{s\\left(\\cos \\left(\\theta_{y_{i}}+m\\right)\\right)}}{e^{s\\left(\\cos \\left(\\theta_{y_{i}}+m\\right)\\right)}+\\sum_{j=1, j \\neq y_{i}}^{n} e^{s \\cos \\theta_{j}}} \\]\nArcFace・SpehereFace・CosFase の一般化 \\(m_1\\)がSpehereFace，\\(m_2\\)がArcFace，\\(m_3\\)がCosFace．\n\\[ L_{4}=-\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{e^{s\\left(\\cos \\left(m_{1} \\theta_{y_{i}}+m_{2}\\right)-m_{3}\\right)}}{e^{s\\left(\\cos \\left(m_{1} \\theta_{y_{i}}+m_{2}\\right)-m_{3}\\right)}+\\sum_{j=1, j \\neq y_{i}}^{n} e^{s \\cos \\theta_{j}}} \\]\nそれぞれの識別境界の違いは下図になるらしい． 4. どうやって有効だと検証した？ 顔認識データセットであるLFW，CFP-FP，AgeDB30で実験． 比較手法がどれも精度が優秀なので，あまり有効さはわからない．\n5. 議論はあるか？  Out of dataset のサンプルが来た時にどれくらい精度がでるか？  6. 次に読むべき論文はある？  CosFace: Large Margin Cosine Loss for Deep Face Recognition https://arxiv.org/abs/1801.09414 SphereFace: Deep Hypersphere Embedding for Face Recognition https://arxiv.org/abs/1704.08063  ","date":1573916400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573916400,"objectID":"cbb19ff663abc875ed87ef1f97ea3bcf","permalink":"https://salty-vanilla.github.io/portfolio/post/arcface/","publishdate":"2019-11-17T00:00:00+09:00","relpermalink":"/portfolio/post/arcface/","section":"post","summary":"1. どんなもの？ Metric Learningの論文．分類をして，各クラス内の分散を小さく，クラス間の分散を大きくする系のMetric Learining．\n2. 先行研究と比べてどこがすごい？  クラス分類モデルのSoftmaxを少し改良するだけで適用できる ArcFaceと先行研究のSpehereFace・CosFaseのLoss関数は似ていて，それを一般化している  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Architecture 全体的な流れとしては， Base Block（VGGとかResNetとか）から特徴ベクトルを出力\n\\[ x' = f(x) \\]\n出力された特徴ベクトルをL2正則化\n\\[ x'' = \\frac{x'}{|x'|^2} \\]\n全結合層の重みをL2正則化\n\\[ w' = \\frac{w}{|w|^2} \\]\n正則化された特徴ベクトルと重みを内積（これがcosの値）\n\\[ cos\\theta = x'' \\cdot w' \\]\nこれにAdditive Angular Margin Penaltyを適用する．\nAdditive Angular Margin Penalty Additive Angular Margin Penaltyは正解ラベルに対応する出力の値に対して，Marginを加えることで，クラス内分散を小さくするような学習を行う． イメージとしては，正解ラベルにのみ厳しい罰則を与えてよりDiscriminativeにする感じ．\n正解クラス\\(j\\)の出力に対して，Marginを加算する\n\\[ \\theta_j' = \\{ \\begin{array}{ll} arccos(cos\\theta_i) + m \u0026 i=j \\\\ arccos(cos\\theta_i) \u0026 otherwise \\end{array} \\]","tags":null,"title":"ArcFace: Additive Angular Margin Loss for Deep Face Recognition","type":"post"},{"authors":null,"categories":null,"content":"1. どんなもの？ 異常検知の論文．Autoencoderの出力を複数にすることでAutoencoderの異常検知の問題を解決する．\n2. 先行研究と比べてどこがすごい？  Autoencoderの入出力による異常検知では，出力がぼやけてしまい高周波成分が再構成できず正常と異常のSN比が小さいという問題があった． 後述するMultiple-Hypothesesにより高周波成分の再構成に成功．  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Multiple-Hypotheses VAEのDecoderから得られる出力を複数にする． 具体的には，$H$個のDeconv Layerを最終層に配置し，それぞれ独立のパラメータで出力させる（事後分布はGaussian）． winner-takes-all (WTA) loss 複数のDecoderの出力に対して，全ておいて再構成誤差をBack Propagationするのではなく， 最も再構成誤差が低い出力(winner)のみから再構成誤差をBack Propagationさせる．\n\\[ \\begin{aligned} L_{W T A}\\left(x_{i} | \\theta_{h}\\right) \u0026=E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{h}}\\left(x_{i} | z_{k}\\right)\\right] \\\\ \\text { s.t. } h \u0026=\\arg \\max _{j} E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{j}}\\left(x_{i} | z_{k}\\right)\\right] \\end{aligned} \\]\nDiscriminator WTA Lossでは再構成誤差をBack Propagationする出力以外については更新がされないことになってしまう． そのため，それ以外の出力についても入力の分布に近づけるようにDiscriminatorを用意する． realはもちろん入力画像で，fakeはVAEの出力（Bestとそれ以外）とランダムサンプリングされた$z$からDecoderを介して得られた出力である．\n\\[ \\begin{aligned} \\min _{D} \\max _{G} L_{D}(x, z)=\u0026\\min _{D} \\max _{G} \\underbrace{-\\log \\left(p_{D}\\left(x_{r e a l}\\right)\\right)}_{L_{real}} +L_{f a k e}(x, z) \\end{aligned} \\]\n\\[ \\begin{array}{l}{L_{\\text {fake }}(x, z)=\\log \\left(p_{D}\\left(\\hat{x}_{z \\sim \\mathcal{N}(0,1)}\\right)\\right)} {+\\log \\left(p_{D}\\left(\\hat{x}_{z \\sim \\mathcal{N}}\\left(\\mu_{\\left.z | x, \\Sigma_{z | x}\\right)}\\right)\\right)+\\log \\left(p_{D}\\left(\\hat{x}_{\\text {best-guess }}\\right)\\right)\\right.}\\end{array} \\]\nVAEのLoss関数は，\n\\[ \\min _{G} L_{G}=\\min _{G} L_{W T A}+K L\\left(q_{\\phi}(z | x) \\| \\mathcal{N}(0,1)\\right)-L_{D} \\]\n異常度の算出 WTA Lossを異常度とする． Sumしなければ，異常箇所のLocalizationに使えるのは従来のAutoencoder通り．\n4. どうやって有効だと検証した？ CIFAR10(1vs9)とMETAL ANOMALY（論文内にはリンクなし）で実験． CIFAR10でAUROC: 67.1． METAL ANOMALYでは異常度が大きいPixelの上位10%のSumを全体の異常度として算出．\n5. 議論はあるか？  Blurが解消されたのは，VAE-GAN構造にしたことによるところが大きいと思うが果たして． 高周波成分が再構成されることにより，今まで差分として出てこなかった部分もあると思う．  6. 次に読むべき論文はある？ ","date":1572534000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572534000,"objectID":"ff3a913e37d04845f459625da0d43b59","permalink":"https://salty-vanilla.github.io/portfolio/post/anomaly_detection_with_multiple-hypotheses_predictions/","publishdate":"2019-11-01T00:00:00+09:00","relpermalink":"/portfolio/post/anomaly_detection_with_multiple-hypotheses_predictions/","section":"post","summary":"1. どんなもの？ 異常検知の論文．Autoencoderの出力を複数にすることでAutoencoderの異常検知の問題を解決する．\n2. 先行研究と比べてどこがすごい？  Autoencoderの入出力による異常検知では，出力がぼやけてしまい高周波成分が再構成できず正常と異常のSN比が小さいという問題があった． 後述するMultiple-Hypothesesにより高周波成分の再構成に成功．  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Multiple-Hypotheses VAEのDecoderから得られる出力を複数にする． 具体的には，$H$個のDeconv Layerを最終層に配置し，それぞれ独立のパラメータで出力させる（事後分布はGaussian）． winner-takes-all (WTA) loss 複数のDecoderの出力に対して，全ておいて再構成誤差をBack Propagationするのではなく， 最も再構成誤差が低い出力(winner)のみから再構成誤差をBack Propagationさせる．\n\\[ \\begin{aligned} L_{W T A}\\left(x_{i} | \\theta_{h}\\right) \u0026=E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{h}}\\left(x_{i} | z_{k}\\right)\\right] \\\\ \\text { s.t. } h \u0026=\\arg \\max _{j} E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{j}}\\left(x_{i} | z_{k}\\right)\\right] \\end{aligned} \\]\nDiscriminator WTA Lossでは再構成誤差をBack Propagationする出力以外については更新がされないことになってしまう． そのため，それ以外の出力についても入力の分布に近づけるようにDiscriminatorを用意する． realはもちろん入力画像で，fakeはVAEの出力（Bestとそれ以外）とランダムサンプリングされた$z$からDecoderを介して得られた出力である．\n\\[ \\begin{aligned} \\min _{D} \\max _{G} L_{D}(x, z)=\u0026\\min _{D} \\max _{G} \\underbrace{-\\log \\left(p_{D}\\left(x_{r e a l}\\right)\\right)}_{L_{real}} +L_{f a k e}(x, z) \\end{aligned} \\]","tags":null,"title":"Anomaly Detection With Multiple-Hypotheses Predictions","type":"post"},{"authors":null,"categories":null,"content":"1. どんなもの？ 推論時に時間がかかってしまうAnoGANを高速化する枠組み．\n2. 先行研究と比べてどこがすごい？ AnoGANでは，推論時に$z$から$x$へのmappingを行うために学習済みGANのDiscriminatorの結果と再構成誤差からLossを算出し，勾配降下法によって$z$を探索していた． つまり，推論時にも”学習”のフェーズが存在し処理時間が長かった．\nf-AnoGANでは，推論時の勾配降下による探索を無くし，推論の高速化を行った．\n3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ $z$ から$x$を推論する枠組みを3つ提案．\nziz encoder 学習済みのGANのGeneratorを用いて，$z$をGeneratorに入力し，その出力をziz encoderに入力し得られた潜在ベクトルとの再構成誤差を最小化する．\n$n$は総画素数． $$ L(z) = \\frac{1}{n}|z - E(G(z))|^2 $$\nizi encoder 学習済みのGANのGeneratorを用いて，$x$をEncoderに入力し，その出力をizi encoderに入力し得られた画像との再構成誤差を最小化する． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 $$\nizif encoder izi encoderの派生形で，izi encoderのLossと同様の再構成誤差と，Discriminatorに$x$と$G(E(x))$を入力した際の中間層の出力の再構成誤差の和を最小化する． $f(\\cdot)$はDiscriminatorの中間層の出力で，$n_d$は$f(\\cdot)$の次元数で$k$は重みパラメータ．． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n異常度の算出 $$ A(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n4. どうやって有効だと検証した？ AnoGANと同様にretinal spectral-domain optical coherence tomography (SD-OCT)をデータセットとして実験． Autoencoder，AAE，ALI，WGANのDiscriminator，iterative(AnoGAN)と比較して精度も上回った．\n5. 議論はあるか？ 追加のEncoderをつけるという簡単な手法で高速化＆高精度化を果たした点がGood． 構成的にはGANomalyに近い感じがするが，精度比較のほどは果たして？\n6. 次に読むべき論文はある？  AnoGAN https://arxiv.org/abs/1703.05921 GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training https://arxiv.org/abs/1805.06725 Adversarially Learned Inference https://arxiv.org/abs/1606.00704  ","date":1570978800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570978800,"objectID":"dbf2807c36d84c7a0f8affaefadded0c","permalink":"https://salty-vanilla.github.io/portfolio/post/f-anogan/","publishdate":"2019-10-14T00:00:00+09:00","relpermalink":"/portfolio/post/f-anogan/","section":"post","summary":"1. どんなもの？ 推論時に時間がかかってしまうAnoGANを高速化する枠組み．\n2. 先行研究と比べてどこがすごい？ AnoGANでは，推論時に$z$から$x$へのmappingを行うために学習済みGANのDiscriminatorの結果と再構成誤差からLossを算出し，勾配降下法によって$z$を探索していた． つまり，推論時にも”学習”のフェーズが存在し処理時間が長かった．\nf-AnoGANでは，推論時の勾配降下による探索を無くし，推論の高速化を行った．\n3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ $z$ から$x$を推論する枠組みを3つ提案．\nziz encoder 学習済みのGANのGeneratorを用いて，$z$をGeneratorに入力し，その出力をziz encoderに入力し得られた潜在ベクトルとの再構成誤差を最小化する．\n$n$は総画素数． $$ L(z) = \\frac{1}{n}|z - E(G(z))|^2 $$\nizi encoder 学習済みのGANのGeneratorを用いて，$x$をEncoderに入力し，その出力をizi encoderに入力し得られた画像との再構成誤差を最小化する． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 $$\nizif encoder izi encoderの派生形で，izi encoderのLossと同様の再構成誤差と，Discriminatorに$x$と$G(E(x))$を入力した際の中間層の出力の再構成誤差の和を最小化する． $f(\\cdot)$はDiscriminatorの中間層の出力で，$n_d$は$f(\\cdot)$の次元数で$k$は重みパラメータ．． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n異常度の算出 $$ A(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n4. どうやって有効だと検証した？ AnoGANと同様にretinal spectral-domain optical coherence tomography (SD-OCT)をデータセットとして実験． Autoencoder，AAE，ALI，WGANのDiscriminator，iterative(AnoGAN)と比較して精度も上回った．\n5. 議論はあるか？ 追加のEncoderをつけるという簡単な手法で高速化＆高精度化を果たした点がGood． 構成的にはGANomalyに近い感じがするが，精度比較のほどは果たして？","tags":null,"title":"f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks","type":"post"},{"authors":null,"categories":null,"content":"背景 手法 ","date":1556809200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556809200,"objectID":"816dc8a0372121d1b0260f07e0230f4d","permalink":"https://salty-vanilla.github.io/portfolio/project/wlid_life/","publishdate":"2019-05-03T00:00:00+09:00","relpermalink":"/portfolio/project/wlid_life/","section":"project","summary":"大量のカメラトラップ画像から野生動物が何頭いるかを自動判定","tags":null,"title":"Wild Life","type":"project"},{"authors":null,"categories":null,"content":"1. どんなもの？ Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を向上させる．\n2. 先行研究と比べてどこがすごい？  Saliency Mapを用いることで有効な領域の情報を重視し，無関係な情報を抑制する Local feature vector (CNNの中間層の出力)とGlobal feature vector (CNNの後段のFCの出力)を組み合わせる 適合度によって重要なLocal feature vectorだけを分類に活用する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 学習可能なAttention Estimatorを通常のCNNに付け加えるだけで，Attention Mapによる解釈性，精度の向上．\n  $S$個のAttention Moduleを↑のようにCNNに加える．$s$個目のAttention Moduleは，長さ$M$のベクトル$N$個からなる集合である．\n  $s$個目のlocal feature vectorは $$ \\mathbf{L^s} = { \\mathbf{l_1^s}, \\mathbf{l_2^s}, \u0026hellip;, \\mathbf{l_N^s} } $$ ここで，ベクトルの長さ$M$はFeature Mapのチャネル数に等しく，ベクトルの個数$N$はFeature Mapの画素数に等しい．\n  全結合層で各ベクトルの長さをglobal feature vector $\\mathbf{g}$の長さ$M'$に揃える $$ \\mathbf{\\hat{l^s_i}} = w\\cdot{\\mathbf{l_i^s}} $$\n  local feature vectorとglobal feature vectorから各画素のCompatibility scoresを求める $$ C^s(\\mathbf{\\hat{L_s}}, \\mathbf{g}) = {c_1^s, c_2^s, \u0026hellip;, c_n^s} $$ $$ c_i^s = \\mathbf{\\hat{l^s_i}} \\cdot{\\mathbf{g}} $$\n  Compatibility scoresに対して，softmaxを適用してAttention Mapを算出 $$ a_i^s = \\frac{exp(c_i^s)}{\\sum_j^N exp(c_j^s)} $$\n  各モジュールの出力はAttention MapとFeature Mapの内積 $$ \\mathbf{g^s} = \\sum_i^n a_i^s \\cdot{\\mathbf{l_i^s}} $$\n  最終的には，全Moduleの出力を連結することでModule全体の出力として，最後にFC層\n  $$ \\mathbf{g_a} = { \\mathbf{g_1}, \\mathbf{g_2}, \u0026hellip;, \\mathbf{g_S}} $$ $$ O = W \\cdot{\\mathbf{g_a}} $$\n4. どうやって有効だと検証した？ CIFAR10，CIFAR100，CUB200，SVHNで実験． BaselineであるVGG，VGG+GAP, VGG+PAN, ResNet164と比較して精度向上． 浅い層では局所的な情報を重視し，深い層では物体全体の情報を重視していることがわかる\n5. 議論はあるか？ Adversarial AttackやCross Domainな認識タスクに対しても有効であることが示されている．\n6. 次に読むべき論文はある？ ","date":1525532400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525532400,"objectID":"aa74104a1b07b41903f5c46506262534","permalink":"https://salty-vanilla.github.io/portfolio/post/learn_to_pay_attention/","publishdate":"2018-05-06T00:00:00+09:00","relpermalink":"/portfolio/post/learn_to_pay_attention/","section":"post","summary":"1. どんなもの？ Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を向上させる．\n2. 先行研究と比べてどこがすごい？  Saliency Mapを用いることで有効な領域の情報を重視し，無関係な情報を抑制する Local feature vector (CNNの中間層の出力)とGlobal feature vector (CNNの後段のFCの出力)を組み合わせる 適合度によって重要なLocal feature vectorだけを分類に活用する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 学習可能なAttention Estimatorを通常のCNNに付け加えるだけで，Attention Mapによる解釈性，精度の向上．\n  $S$個のAttention Moduleを↑のようにCNNに加える．$s$個目のAttention Moduleは，長さ$M$のベクトル$N$個からなる集合である．\n  $s$個目のlocal feature vectorは $$ \\mathbf{L^s} = { \\mathbf{l_1^s}, \\mathbf{l_2^s}, \u0026hellip;, \\mathbf{l_N^s} } $$ ここで，ベクトルの長さ$M$はFeature Mapのチャネル数に等しく，ベクトルの個数$N$はFeature Mapの画素数に等しい．\n  全結合層で各ベクトルの長さをglobal feature vector $\\mathbf{g}$の長さ$M'$に揃える $$ \\mathbf{\\hat{l^s_i}} = w\\cdot{\\mathbf{l_i^s}} $$\n  local feature vectorとglobal feature vectorから各画素のCompatibility scoresを求める $$ C^s(\\mathbf{\\hat{L_s}}, \\mathbf{g}) = {c_1^s, c_2^s, \u0026hellip;, c_n^s} $$ $$ c_i^s = \\mathbf{\\hat{l^s_i}} \\cdot{\\mathbf{g}} $$","tags":null,"title":"Learn to Pay Attention","type":"post"},{"authors":null,"categories":null,"content":"国内会議  中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;CNNによる回帰分析を用いた打痕判定に関する考察\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2016, pp.204-205(2016.12.9) 中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;回帰型CNNを用いた工業製品における外観検査手法の研究\u0026rdquo;, 第22回知能メカトロニクスワークショップ, 3A1-4(2017.8.28) 神本恭佑, 中塚俊介, 相澤宏旭, 加藤邦人, 小林裕幸, 坂野和見 : \u0026ldquo;Denoising Autoencoder Generative Adversarial Networks を用いた欠損検出の検討\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.54-55(2017.12.7) 中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.148-149(2017.12.8) 安藤正規，中塚俊介，相澤宏旭，中森さつき，池田敬，森部絢嗣，寺田和憲，加藤邦人: \u0026ldquo;機械学習による自動撮影カメラ画像からの獣種自動判別技術の開発\u0026rdquo;，日本哺乳類学会2018年度大会，S2-05，(2018.9)  国際会議  Shunsuke Nakatsuka, Kunihito Kato, Yosuke Nakanishi : \u0026ldquo;Study on Visual Inspection Method using CNN Regression\u0026rdquo;, Asia International Symposium on Mechatronics, D1-5(2017.9.15) Kyosuke Komoto, Shunsuke Nakatsuka Hiroaki, Aizawa, Kunihito Kato, Hiroyuki Kobayashi, Kazumi Banno : \u0026ldquo;A Performance Evaluation of Defect Detection by using Denoising AutoEncoder Generative Adversarial Networks\u0026rdquo;, International Workshop on Advanced Image Technology 2018, Session E2-4 (2018.1.9) Shunsuke Nakatsuka, Hiroaki Aizawa and Kunihito Kato : \u0026ldquo;A Method of Generation of Normal Model and Discrimination of Defects by Adversarial AutoEncoder under Small Number of Defective Samples\u0026rdquo;, Proceeding of 24rd International Workshop on Frontiers of Computer Vision, OS3-1,(2018.2.22)  論文誌  中塚俊介，相澤宏旭，加藤邦人：\u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と異常検出\u0026rdquo;，精密工学会誌，投稿中 安藤正規，中塚俊介，相澤宏旭，中森さつき，池田敬，森部絢嗣，寺田和憲，加藤邦人: \u0026ldquo;深層学習（Deep Learning）によるカメラトラップ画像の判別\u0026rdquo;，哺乳類科学, 投稿中  雑誌  中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, 映像情報インダストリアル, pp.57-68(2018.03)  特許  加藤邦人, 中塚俊介, 相澤宏旭 : \u0026ldquo;異常品判定方法\u0026rdquo; (特願2017-196758/2017.10.10出願)  受賞  Best Paper Award受賞 Shunsuke Nakatsuka, Kunihito Kato, Yosuke Nakanishi : \u0026ldquo;Study on Visual Inspection Method using CNN Regression\u0026rdquo;, Asia International Symposium on Mechatronics, D1-5(2017年9月15日受賞) ViEW2017 ビジョン技術の実利用ワークショップ 小田原賞（優秀論文賞）, 中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.148-149 (2017年12月8日 受賞)  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"40ea366a28f9524de71378c3212c5489","permalink":"https://salty-vanilla.github.io/portfolio/publication/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/portfolio/publication/","section":"","summary":"国内会議  中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;CNNによる回帰分析を用いた打痕判定に関する考察\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2016, pp.204-205(2016.12.9) 中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;回帰型CNNを用いた工業製品における外観検査手法の研究\u0026rdquo;, 第22回知能メカトロニクスワークショップ, 3A1-4(2017.8.28) 神本恭佑, 中塚俊介, 相澤宏旭, 加藤邦人, 小林裕幸, 坂野和見 : \u0026ldquo;Denoising Autoencoder Generative Adversarial Networks を用いた欠損検出の検討\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.54-55(2017.12.7) 中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.148-149(2017.12.8) 安藤正規，中塚俊介，相澤宏旭，中森さつき，池田敬，森部絢嗣，寺田和憲，加藤邦人: \u0026ldquo;機械学習による自動撮影カメラ画像からの獣種自動判別技術の開発\u0026rdquo;，日本哺乳類学会2018年度大会，S2-05，(2018.9)  国際会議  Shunsuke Nakatsuka, Kunihito Kato, Yosuke Nakanishi : \u0026ldquo;Study on Visual Inspection Method using CNN Regression\u0026rdquo;, Asia International Symposium on Mechatronics, D1-5(2017.9.15) Kyosuke Komoto, Shunsuke Nakatsuka Hiroaki, Aizawa, Kunihito Kato, Hiroyuki Kobayashi, Kazumi Banno : \u0026ldquo;A Performance Evaluation of Defect Detection by using Denoising AutoEncoder Generative Adversarial Networks\u0026rdquo;, International Workshop on Advanced Image Technology 2018, Session E2-4 (2018.","tags":null,"title":"Publications","type":"page"}]