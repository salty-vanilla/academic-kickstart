[{"authors":["admin"],"categories":null,"content":"2013年岐阜大学工学部 電気電子・情報工学科に入学．情報分野を専門領域として学ぶ． その中で，人工知能・コンピュータビジョンに興味を持ち，2015年より加藤研究室に所属する． 学部・修士課程を通して，ニューラルネットワーク・画像処理・異常検知の研究に従事．特に工業製品や食品における外観検査の自動化をテーマとして研究を行った． また2018年度より応用生物科学部と協同しニューラルネットワークを用いた野生動物検知の研究にも着手．\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://salty-vanilla.github.io/portfolio/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/portfolio/authors/admin/","section":"author","summary":"2013年岐阜大学工学部 電気電子・情報工学科に入学．情報分野を専門領域として学ぶ． その中で，人工知能・コンピュータビジョンに興味を持ち，20","tags":null,"title":"中塚 俊介","type":"author"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  SSL型の異常検知 Cutoutを異常検知・外観検査に適応させたような形  2. 先行研究と比べてどこがすごい？  SSL型のAD手法は，大域的異常にしか対応できなかった  cifar10とかには強かったが，MVTecには弱い 要は外観検査向きではない   自然画像認識のデータセット拡張手法であるCutoutをベースに局所的異常に対応可能な形に  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 学習  画像内からランダムな大きさ・角度のパッチを切り出して，画像内にランダムに張り付けることで異常データを生成  特に細長い矩形をscarと呼ぶ 学習時にはscarと通常の矩形の両方を使う   Cutpasteしてない画像を正常，Cutpasteした画像を異常として識別器を学習  $$ \\mathcal{L} = \\mathbb{E}_{x \\sim \\mathcal{X}} [ \\text{BCE}(f(x), 0) + \\text{BCE}(f(CP(x)), 1) ] $$\n推論  全training dataに対して，NNの中間層の出力を得てその平均$\\mu$と分散$\\Sigma$を算出 Gaussian Density Estimator (GDE)を用いて，確率密度を算出して異常度とする  $$ \\log{p_{gde}(x)} \\propto { -\\frac{1}{2} (f^*(x) - \\mu)^T \\Sigma^{-1} (f^*(x) - \\mu) } $$\n異常個所の可視化にはGrad-CAMを用いる  Patch Base  cutpaste適用前の画像に対して，random cropしたら可能（当たり前） 推論時には一定ストライドで推論を繰り返す  $$ \\mathcal{L} = \\mathbb{E}_{x \\sim \\mathcal{X}} [ \\text{BCE}(f(\\text{crop}(x)), 0) + \\text{BCE}(f(CP(\\text{crop}(x)))), 1) ] $$\nPretrained model  EfficentNetなどの学習済みモデルをcutpasteでfinetuneして，GDEで異常度を算出  4. どうやって有効だと検証した？  MVTec で実験  3-way: 正常，CP-scar，CPの3クラスで識別器を学習 Ensemble: 3-way のモデルを5個学習してEnsemble   pretrained modelの実験      5. 議論はあるか？  外観検査などでは局所的でも異常があれば不良だから検出する必要がある  そんな不良は良品に欠陥（打痕や汚れなど）をCutpasteした形   SSL系で初めて，MVTecで高精度でADできた  精度的にはPaDiMに劣る    6. 次に読むべき論文はある？  T. Devries and G. W. Taylor, “Improved Regularization of Convolutional Neural Networks with Cutout,” arXiv Prepr. arXiv1708.04552, 2017.  ","date":1620000000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620000000,"objectID":"1261242465779a329b05732cf5f8de2b","permalink":"https://salty-vanilla.github.io/portfolio/post/cutpaste/","publishdate":"2021-05-03T00:00:00Z","relpermalink":"/portfolio/post/cutpaste/","section":"post","summary":"Cutoutを異常検知に適応させたCutpasteを提案．SSL型のADで初めてMVTecで高精度．画像の一部を切り貼りして疑似不良を生成し，識別器を学習するのみという非常に単純な枠組みながらPaDiMに迫る精度．","tags":["CVPR2021"],"title":"CutPaste: Self-Supervised Learning for Anomaly Detection and Localization","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  ImageNetで事前学習済みモデルを利用した異常検知 事前学習モデルで得られる特徴Mapを用いる MVTecでSoTA  2. 先行研究と比べてどこがすごい？  NNの更新などは一切なく，学習するパラメータは平均ベクトルと共分散行列の集合のみ kNNなどを使わないので，推論が高速  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 学習  Pretrained modelから多重解像度な特徴Mapを抽出 アップサンプリングして，1番空間解像度の大きい特徴Mapと空間解像度を揃えて，\n$H \\times W \\times N$のtensorにする これらを$N$次元ベクトルの$H \\times W$個の集合と考え，訓練データ（正常のみ）から得られる特徴Mapに対して，position毎に平均ベクトルと共分散行列を求める  推論  テストデータに対して，Pretrained modelから特徴Map抽出 学習で求めたpositino毎の平均ベクトルと共分散行列からマハラノビス距離を算出  $$ A(x) = \\sum_h^H{ \\sum_w^W { \\sqrt{ ( x_{hw} - \\mu_{hw } )^T\\Sigma_{hw}^{-1}( x_{hw} - \\mu_{hw } ) } } } $$\n4. どうやって有効だと検証した？   MVTec でSoTA\n 実際の外観検査に近づけるために，±10度のrandom rotaionを加えた $256 \\times 256$にリサイズし，$224 \\times 224$にセンタークロップ     特徴MapのチャンネルをPCAで次元削減したり，ランダム選択したりしても，精度に影響はなかった   5. 議論はあるか？  非常に単純な枠組みだが，SoTA MVTecの精度はほぼ限界なので，Beyond MVTec AD求む random rotationの影響を実験すべき  6. 次に読むべき論文はある？ ","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"c03a0514b887c07e5656e497b9e69235","permalink":"https://salty-vanilla.github.io/portfolio/post/padim/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/portfolio/post/padim/","section":"post","summary":"1. どんなもの？ ImageNetで事前学習済みモデルを利用した異常検知 事前学習モデルで得られる特徴Mapを用いる MVTecでSoTA 2. 先行研究","tags":["ICPR2020"],"title":"PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization","type":"post"},{"authors":null,"categories":["Anomaly Detection","Domain Adaptation"],"content":"1. どんなもの？  Anomaly Detection + Domain Adaptationの枠組み 大量のドメインAのデータと少量のドメインBのデータからAD  2. 先行研究と比べてどこがすごい？  従来研究では↓のどちらかだった  ドメインAのラベルが必要 ドメインBにも大量のデータが必要    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Obejctive   domain invarianceの特徴を抽出することが目標\n 共通の特徴を抽出する$E_{sh}$ ドメインAのprivate encoder$E_{pv}$ sourceの復元データ $$x^{\\prime} _{src} = G(E _ {pv}(x _ {src}) + E _ {sh}(x _ {src}))$$ 共通の特徴とsource固有のデータからsourceを生成したデータ $$x^{\\prime} _{tgt} = G(E _ {pv}(x _ {src}) + E _ {sh}(x _ {tgt}))$$ ランダムにサンプリングされた潜在変数と共通の特徴から生成したデータ $$x _ {rnd} = G(z + E _ {sh}(x _ {src}))$$ この3つをfakeで$x_{src}$をtrueとしてGANを学習 $$ \\min _ {{E_{s h}, E_{p v}, G_{s r c}}} \\max _ {D _ {s r c}} V_{s r c}(D_{s r c}, G_{s r c}, E_{p v}, E_{s h})= \\newline \\mathbb{E} _ {\\boldsymbol{x} _ {s r c}}[\\log D_{s r c}(\\boldsymbol{x} _ {s r c})]+\\mathbb{E} _ {\\boldsymbol{x} _ {s r c}}[\\log (1-D_{s r c}(\\boldsymbol{x}_{s r c}^{\\prime})]+ +\\mathbb{E} _ {\\boldsymbol{x} _ {s r c}, \\boldsymbol{x} _ {t g t}}[\\log (1-D_{s r c}(\\boldsymbol{x} _ {t g t}^{\\prime})]+\\mathbb{E} _ {\\boldsymbol{x} _ {s r c}}[\\log (1-D_{s r c}(\\boldsymbol{x}_{r n d})] $$ cycle consistensy $$ l_1 = | x_{src} - x^{\\prime}_{src} |_2 $$ $$ l_2 = | x_{src} - x^{\\prime}_{tgt} |_2 $$ $x_{src}$に対して，$E_{sh}$と$E_{pv}$で得られる特徴量が遠くなるように内積を最小化 $$ l _ {dis} = | E _ {sh}(x _ {src})^T E _ {pv}(x _ {src}) | $$ 逆に共通の特徴が取れるようにするため内積の負を最大化 $$ l _ {sim} = - | E _ {sh}(x _ {src})^T E _ {pv}(x _ {tgt}) | $$  全てのLossを重み付き（$\\alpha=1.0$，$\\beta=0.5$）で足し算して最小化 $$ V_{src} + \\alpha(l_1 + l_2) + \\beta(l_{dis} + l_{sim}) $$\n  Anomaly Score $E_{sh}(x)$に対してIsolation Forestを適用することで算出\n4. どうやって有効だと検証した？   SourceをMNIST，TargetをUSPSで実験   SourceをMNIST，TargetをSVHNで実験   5. 議論はあるか？  複雑なLossだが安定性は？ 他の枠組み応用は可能か？  6. 次に読むべき論文はある？ ","date":1606694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606694400,"objectID":"ebccc93d3fde5163d31f02ddfa0d06ce","permalink":"https://salty-vanilla.github.io/portfolio/post/irad/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/portfolio/post/irad/","section":"post","summary":"1. どんなもの？ Anomaly Detection + Domain Adaptationの枠組み 大量のドメインAのデータと少量のドメインBのデータからAD 2. 先行研究と比べてどこがすごい？","tags":[],"title":"Anomaly Detection with Domain Adaptation","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  Anomaly Detectionの枠組み EGBAD(Efficient GAN Based Anomaly Detection)の改良版  2. 先行研究と比べてどこがすごい？  EGBADでは$x$と$G(E(x))$に一貫性がなく，入出力の誤差が大きくなることがあった   3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Loss  BiGANの$x$と$G(E(x))$に一貫性を強制するLossを導入 $$ \\mathcal{L} _ {R}(\\mathbf{x})=|\\mathbf{x}-G(E(\\mathbf{x}))|_{1} $$  $$ \\mathcal{L} _ {R^{\\prime}}(\\mathbf{z})=|\\mathbf{z}-E(G(\\mathbf{z}))|_{1} $$\n$$ \\mathcal{L} _ {C} (\\mathbf{x}, \\mathbf{z}) = \\mathcal{L} _ {R}(\\mathbf{x}) + \\mathcal{L} _ {R^{\\prime}}(\\mathbf{z}) $$\n GANのmetricにはWasserstein Distanceを使用  $$ \\min _ {G, E} \\max _ {D} \\mathbb{E} _ {\\mathbf{x} \\sim p_{\\text {data }}(\\mathbf{x})}[D(\\mathbf{x}, E(\\mathbf{x}))]-\\mathbb{E}_{\\mathbf{z} \\sim p(\\mathbf{z})}[D(G(\\mathbf{z}), \\mathbf{z}] $$\n ↑2つを重み$\\alpha$で足し合わせる $$ \\mathcal{L} _ {E, G}^{*}=(1-\\alpha) \\mathcal{L} _ {E, G}+\\alpha \\mathcal{L}_{C} $$  Anomaly Score $$ A(\\mathbf{x})=(1-\\lambda) \\mathcal{L} _ {R}(\\mathbf{x})+\\lambda \\mathcal{L} _ {f_{D}}(\\mathbf{x}) $$\n$$ \\mathcal{L} _ {f _ {D}}(\\mathbf{x})=\\left|f_{D}(\\mathbf{x}, E(\\mathbf{x}))-f_{D}(G(E(\\mathbf{x})), E(\\mathbf{x}))\\right|_{1} $$\n4. どうやって有効だと検証した？   MVTEC ADで実験   EGBADとの比較   5. 議論はあるか？  意外と今までconsistencyを導入したものはなかった？ 評価指標はこれで正しい？面積の大きい欠陥しか検出できない気がする 公式実装あり github  6. 次に読むべき論文はある？ ","date":1606694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606694400,"objectID":"b0defeb2654f23781d60ce0acb6feca4","permalink":"https://salty-vanilla.github.io/portfolio/post/cbigan/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/portfolio/post/cbigan/","section":"post","summary":"1. どんなもの？ Anomaly Detectionの枠組み EGBAD(Efficient GAN Based Anomaly Detection)の改良版 2. 先行研究と比べてどこがすごい？ EGBADでは$x$と$G(E","tags":[],"title":"Combining GANs and AutoEncoders for Efficient Anomaly Detection","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  Anomaly Detectionの枠組み AE系とGEOM系を組み合わせた  2. 先行研究と比べてどこがすごい？  AE系とGEOM系を組み合わせた ↑以外に新規性はないが調査までに  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Architecture  構造はVAE系   Objective  再構成誤差  $$ \\mathcal{L} _ {c r}=\\left|\\left(x_{i}-f\\left(\\hat{x} _ {i}\\right)\\right)\\right|_{2} $$\n GEOM誤差．VAEの平均に対して分類を行う  $$ \\mathcal{L} _ {geo}=- \\sum^N_i q_i \\log g (\\tilde{x_{q_i}}) $$\n 全体のloss  $$ \\mathcal{L} _ {multitask} = \\mathcal{L}_{geo} + \\epsilon \\mathcal{L} _ {cr} $$\nAnomaly score $$ score = (1-\\lambda)s_g + \\lambda s_r $$ $$ s_g = - \\sum^N_i q_i \\log g (\\tilde{x_{q_i}}) $$ $$ s_r = \\alpha \\times | x_i-f(x_i) |_2 $$ 4. どうやって有効だと検証した？  脳のCTスキャンデータで実験   5. 議論はあるか？  比較手法が少ない  6. 次に読むべき論文はある？ ","date":1606348800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606348800,"objectID":"8a291e78c122f546c58ac33eda32cc95","permalink":"https://salty-vanilla.github.io/portfolio/post/ss_ood_brain_ct/","publishdate":"2020-11-26T00:00:00Z","relpermalink":"/portfolio/post/ss_ood_brain_ct/","section":"post","summary":"1. どんなもの？ Anomaly Detectionの枠組み AE系とGEOM系を組み合わせた 2. 先行研究と比べてどこがすごい？ AE系とGEOM系を組み合わせた ↑","tags":[],"title":"Self-Supervised Out-of-Distribution Detection in Brain CT Scans","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  One Class Learningの枠組み side-informationを必要とせず，representation collapseに対してrobust negative examples を用いたDROCC-LN(Limeted Negatives)も提案  2. 先行研究と比べてどこがすごい？  GEOM系は画像などのtransformに対して事前知識が必要（汎用性もない） DeepSVDDは全てが同じ特徴に落ちてしまうrepresentation collapseが問題  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 仮定：\n The set of typical points $S$ lies on a low dimensional locally linear manifold that is well-sampled. In other words, outside a small radius around a training (typical) point, most points are anomalous.\n  正常 $S$ は低次元な局所的線形多様体上に存在し，よくsamplingされている．言い換えるとtrainingデータの周りの小さな半径の外側が異常である．\n DROCC  入力データをNNで次元を落として正常ベクトル$f_\\theta(x)$とその外側ベクトル$f_\\theta(\\tilde{x})$を生成 $f_\\theta(\\tilde{x})$を生成するのに敵対的枠組みを利用 $l$はcrossentropyとして正常1・外側0として分類タスクに持っていく  $$ \\ell^{\\mathrm{dr}}(\\theta)=\\lambda|\\theta|^{2}+\\sum_{i=1}^{n}\\left[\\ell\\left(f_{\\theta}\\left(x_{i}\\right), 1\\right)+\\mu \\max _ {\\tilde{x} _ {i} \\in} \\ell\\left(f_{\\theta}\\left(\\tilde{x}_{i}\\right),-1\\right)\\right] $$\n$$ N_{i}(r) \\stackrel{\\text { def }}{=} \\{ | \\tilde{x_i} - x_i |_2 \\leq \\gamma \\cdot r; r \\leq | \\tilde{x_i} - x_i |, \\forall j=1,2, \\ldots n\\} $$ DROCC-LN  DROCCにラベルを付与（Outlier Exposureの枠組み） 距離を測るときに↑のようにユークリッドではなくマハラノビスで $| \\tilde{x_i} - x_i | _ \\Sigma$  $$ \\ell^{\\mathrm{lf}}(\\theta)=\\lambda|\\theta|^{2}+\\sum_{i=1}^{n}\\left[\\ell\\left(f_{\\theta}\\left(x_{i}\\right), y_i\\right)+\\mu \\max _ {\\tilde{x} _ {i} \\in} \\ell\\left(f_{\\theta}\\left(\\tilde{x}_{i}\\right),-1\\right)\\right] $$\n$$ N_{i}(r) \\coloneqq \\{ \\tilde{x_i}, r \\leq | \\tilde{x_i} - x_i | _ \\Sigma \\leq \\gamma \\ldots r \\} $$\n4. どうやって有効だと検証した？   Cifar10で実験   Imagenetで実験   音声データを使ってDeepSADと比較   5. 議論はあるか？  正常の外側をselfで作るself-supervisedの枠組みといっていい？ MVTec ADでの実験が欲しかった 公式実装あり github  6. 次に読むべき論文はある？ ","date":1606089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606089600,"objectID":"fa0d9eb41da6eca29a698cfc6bf74517","permalink":"https://salty-vanilla.github.io/portfolio/post/drocc/","publishdate":"2020-11-23T00:00:00Z","relpermalink":"/portfolio/post/drocc/","section":"post","summary":"1. どんなもの？ One Class Learningの枠組み side-informationを必要とせず，representation collapseに対して","tags":["ICLR2020"],"title":"DROCC: Deep Robust One-Class Classification","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  生成モデルVAEに根拠性を追加したモデル その根拠を利用することで異常検知可能 Disentangleな生成を可能にするLossも同時に提案  2. 先行研究と比べてどこがすごい？  VAEのような生成モデルでLatent Vectorに根拠性を持たせることはできなかった VAEのADモデルでは再構成誤差ベースだったが，本手法のAttention Mapのほうが高精度にADできる  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Generating VAE Attention  EncoderのFeature Map $A \\in \\R^{n \\times h \\times w}$でlatent vector $z \\in \\R^d$を微分+GAPすることでvector $\\alpha \\in \\R^n$を求める  $$ \\alpha_k = \\frac{1}{T} \\sum^h_{p=1}\\sum^w_{q=1} \\frac{\\partial z_i}{\\partial A^{pq}_k} $$\n $\\alpha$と$A$をチャネル毎にinner productしてReLUして，Attention Map $M$を算出($d$ channel分のMapを生成)  $$ M^i = ReLU(\\sum^n _ {k=1}\\alpha _ k A _ k) $$\n channel方向に平均とって，最終的なAttention Mapとする $$ M = \\frac{1}{D} \\sum^D_i M^i $$  Generating Anomaly Attention Explanations  訓練データ（正常データ）$x$全てから全体の平均ベクトル$\\mu_x$と分散ベクトル$\\sigma_y$を算出 テストデータ$y$から，Encoder使って$\\mu_y$と$\\sigma_y$を算出 $x$と$y$のnormal difference distributionを定義  $$ P_{q\\left(z_{i} \\mid x\\right)-q\\left(z_{i} \\mid y\\right)}(u)=\\frac{e^{-\\left[u-\\left(\\mu_{i}^{x}-\\mu_{i}^{y}\\right)\\right]^{2} /\\left[2\\left(\\left(\\sigma_{i}^{x}\\right)^{2}+\\left(\\sigma_{i}^{y}\\right)^{2}\\right)\\right]}}{\\sqrt{2 \\pi\\left(\\left(\\sigma_{i}^{x}\\right)^{2}+\\left(\\sigma_{i}^{y}\\right)^{2}\\right)}} $$\n この分布から新たなlatent vectorを生成して，↑のAttentionの枠組みの$z$に代入  式中の$u$は説明がないが，恐らく$u \\sim \\mathcal{N}(o, I)$    4. どうやって有効だと検証した？   MNISTで実験   UCSD Ped1で実験\n 2回目のDownsamplingのFeature Mapを用いるのがよさそう     MVTec ADで実験   5. 議論はあるか？  Fig 3が入力が\u0026quot;5\u0026quot;なのになぜ出力が\u0026quot;9\u0026rdquo; ? $u$ の記述が終始無し 公式実行待ち Disentangleは気が向いたら  6. 次に読むべき論文はある？ ","date":1597017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597017600,"objectID":"6f2645c3caef135c9246fec60c005de5","permalink":"https://salty-vanilla.github.io/portfolio/post/explaining_vae/","publishdate":"2020-08-10T00:00:00Z","relpermalink":"/portfolio/post/explaining_vae/","section":"post","summary":"1. どんなもの？ 生成モデルVAEに根拠性を追加したモデル その根拠を利用することで異常検知可能 Disentangleな生成を可能にするLossも","tags":["CVPR2020"],"title":"Towards Visually Explaining Variational Autoencoders","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  2stage のtrainingのAnomaly Detection 完ぺきではないGenerator $\\mathcal{G}_{old}$が1st stage，そこからgood/bad 判定のDiscriminatorの学習を行う GAN系のADモデル特有の精度不安定が解消  2. 先行研究と比べてどこがすごい？  Generatorのみを使うADモデル（Autoencoder含む）は訓練データに稀に異常が入っていると失敗する Generator + DiscriminatorのADモデルは精度が不安定 $\\mathcal{G}_{old}$は↑2つを改善したモデル  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  変数の定義  $X \\sim p_t$ : 正常データ $\\tilde{X} \\sim p_t +\\mathcal{N}_\\sigma$ : 正常データ + ノイズ $\\mathcal{G}$ : Generator (Autoencoder) $\\mathcal{D}$ : Discriminator    1st phase  GAN + DAE (Reconstruction) lossで$G$と$D$を訓練  $$ \\min _ {\\mathcal{G}} \\max _ {\\mathcal{D}}\\left(\\mathbb{E} _ {X \\sim p_{t}}[\\log (1-\\mathcal{D}(X))] + \\mathbb{E} _ {\\tilde{X} \\sim p _ {t}+\\mathcal{N} _ {\\sigma}}[\\log (\\mathcal{D}(\\mathcal{G}(\\tilde{X})))]\\right) $$\n$$ \\mathcal{L}_R = | X - \\mathcal{G}(\\tilde{X}) |^2 $$\n$$ \\mathcal{L} = \\mathcal{L}_{\\mathcal{G}+\\mathcal{D}} + \\lambda \\mathcal{L}_R $$\n ここで 数Epoch後（low-epoch generator ） のweightsを保存しておく．=\u0026gt; $\\mathcal{G}_{old}$ この段階でDiscriminatorの役割は real / fake の判定  2nd phase Good / Bad quality exmaples  Good quality examples : 正常データ $X$ Bad quality examples : ${G} _ {old}$ による生成データ $\\mathcal{G}_{old}(X)$ と Pseudo anomaly $\\mathcal{G}(\\hat{\\bar{X}})$  $$ \\hat{X}=\\frac{\\mathcal{G}^{old}\\left(X_{i}\\right)+\\mathcal{G}^{\\text {old}}\\left(X _ {j}\\right)}{2}=\\frac{\\hat{X} _ {i}^{\\text {low}}+\\hat{X} _ {j}^{\\text {low}}}{2}, \\text { where } i \\neq j $$\ntraining  $\\mathcal{D}$のみ最適化  $$ \\begin{array}{l} \\max _ {\\mathcal{D}}\\left(\\alpha \\mathbb{E} _ {X}[\\log (1-\\mathcal{D}(X))]+\\right. \\\\ (1-\\alpha) \\mathbb{E} _ {\\hat{X}}[\\log (1-\\mathcal{D}(\\hat{X}))]+\\beta \\mathbb{E} _ {\\hat{X}^{l o w}}\\left[\\log \\left(\\mathcal{D}\\left(\\hat{X}^{low}\\right)\\right)\\right]+ \\\\ \\left.\\quad(1-\\beta) \\mathbb{E}_{\\hat{X}^{pseudo}}\\left[\\log \\left(\\mathcal{D}\\left(\\hat{X}^{pseudo}\\right)\\right)\\right]\\right) \\end{array} $$\n異常度の算出  2nd phaseでGood / Bad quality exmaplesの識別ができる$\\mathcal{D}$が得られるので，  $$ OCC = \\begin{cases} \\text { normal class } \u0026amp; \\text { if } \\mathcal{D}(\\mathcal{G}(X))\u0026lt;\\tau \\\\ \\text { anomaly class } \u0026amp; \\text { otherwise. } \\end{cases} $$\n4. どうやって有効だと検証した？   Caltech-256で実験   Ped2で実験   何Epoch目で$mathcal{G}_{old}$作ればよいか実験 ⇒ 結構ロバスト   Caltech と Ped2のGood / Bad quality exmaples   5. 議論はあるか？  $\\mathcal{G}_{old}$のネーミングセンス良き MVTec ADではどうなる？  6. 次に読むべき論文はある？ ","date":1596585600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596585600,"objectID":"b075b6fa9cfeedfdbc7b183537468ae2","permalink":"https://salty-vanilla.github.io/portfolio/post/old_is_gold/","publishdate":"2020-08-05T00:00:00Z","relpermalink":"/portfolio/post/old_is_gold/","section":"post","summary":"1. どんなもの？ 2stage のtrainingのAnomaly Detection 完ぺきではないGenerator $\\mathcal{G}_{old}$が1st stage","tags":["CVPR2020"],"title":"Old Is Gold: Redefining the Adversarially Learned One-Class Classifier Training Paradigm","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  Unsupervised な Anomaly Detectionの枠組み Autoencoder系のADで，Autoencoderの潜在特徴MAPにMemory構造を採用 Autoencoderの汎化問題と正常パターンの多様性という問題にアタック 再構成のlossベース，フレーム予測のlossベースどちらにも展開可能  2. 先行研究と比べてどこがすごい？  Autoencoder系のADは，Autoencoderの表現力がありすぎて，異常も異常として復元してしまい再構成誤差が出ない問題があった またAutoencoder系のADは，正常分布のdiversityをカバーしきれないことがあった（表現力とのトレードオフ？）  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  変数の定義  $I_t$: $t$ frame目の入力画像 $\\hat{I}_t$: $t$ frame目のAutoencodeされた画像 $q_t \\in \\R^{H \\times W \\times C}$: $t$ frame目のquery map $q^k_t \\in \\R^{C} (k=1, \\cdots, K)$: $t$ frame目，position $k$ のquery vector（$K=H \\times W$） $p_m \\in \\R^{C} (m=1,\\cdots,M)$: $m$番目のmemory vector    Memory Read  query vectorのmemory vectorの内積をsoftmaxして，matching probability $w^{k,m}_t$を求める $$ w _ {t}^{k, m}=\\frac{\\exp \\left(\\left(\\mathbf{p} _ {m}\\right)^{T} \\mathbf{q} _ {t}^{k}\\right)}{\\sum _ {m^{\\prime}=1}^{M} \\exp \\left(\\left(\\mathbf{p} _ {m^{\\prime}}\\right)^{T} \\mathbf{q} _ {t}^{k}\\right)} $$ 各クエリ$q^k_t$に対して，memory vectorを使った重み付き平均を求めることで，新しい特徴とする $$ \\hat{\\mathbf{p}} _ {t}^{k}=\\sum _ {m^{\\prime}=1}^{M} w _ {t}^{k, m^{\\prime}} \\mathbf{p} _ {m^{\\prime}} $$ $q_t$と$\\hat{p}_t$を結合して，Decoderに入力する   Update   相関MAPを求める．↑の$w _ {t}^{k, m}$の式と似ているけど，softmaxのaxisが$k$方向 $$ v _ {t}^{k, m}=\\frac{\\exp \\left(\\left(\\mathbf{p} _ {m}\\right)^{T} \\mathbf{q} _ {t}^{k}\\right)}{\\sum_{k^{\\prime}=1}^{K} \\exp \\left(\\left(\\mathbf{p} _ {m}\\right)^{T} \\mathbf{q} _ {t}^{k^{\\prime}}\\right)} $$\n  最大値で正規化 $$ v^{\\prime k, m} _ {t} = \\frac{v_{t}^{k, m}}{\\max _ {k^{\\prime} \\in U _ {t}^{m}} v _ {t}^{k^{\\prime}, m}} $$\n  重み付き平均を加算して更新．$f$はL2-norm $$ \\mathbf{p}^{m} \\leftarrow f\\left(\\mathbf{p}^{m}+\\sum_{k \\in U_{i}^{m}} v_{t}^{\\prime k, m} \\mathbf{q}_{t}^{k}\\right) $$\n  updateはtraining, test段階両方で行う．動画にはnormalとabnormalなフレームが混在してることがある．abnormalのときにはメモリのupdateを行わない\n 基準は$\\mathcal{E} _ {t}$がしきい値$\\gamma$以上 $i, j$は入出力画像のposition $$ \\mathcal{E} _ {t}=\\sum_{i, j} W _ {i j}\\left(\\hat{\\mathbf{I}} _ {t}, \\mathbf{I} _ {t}\\right)\\left|\\hat{\\mathbf{I}}_{t}^{i j}-\\mathbf{I} _ {t}^{i j}\\right| _ {2} $$    $$ W _ {i j}\\left(\\hat{\\mathbf{I}} _ {t}, \\mathbf{I} _ {t}\\right)=\\frac{1-\\exp \\left(-\\left|\\hat{\\mathbf{I}} _ {t}^{i j}-\\mathbf{I} _ {t}^{i j}\\right| _ {2}\\right)}{\\sum_{i, j} 1-\\exp \\left(-\\left|\\hat{\\mathbf{I}} _ {t}^{i j}-\\mathbf{I} _ {t}^{i j}\\right| _ {2}\\right)} $$\nTraining Loss  3つのLossの重み付き和 $$ \\mathcal{L} = \\mathcal{L}_{rec} + \\lambda_c \\mathcal{L} _ {compact} + \\lambda_s \\mathcal{L} _ {separate} $$  Reconstruction loss  普通のL2誤差．全フレーム分の合計． $$ \\mathcal{L}_{rec} = \\Sigma^T_t | \\mathbf{\\hat{I}_t} - \\mathbf{I_t} | _ 2 $$  Feature compactness loss  query $\\mathbf{q^k_t}$と一番近いmemory $\\mathbf{p}_p$を近づけることで，正常パタンのパタン内分散を小さくする $$ \\mathcal{L} _ {compact} = \\Sigma^T_t \\Sigma^K_k | \\mathbf{q^k _ t} - \\mathbf{p} _ p | _ 2 $$  Feature separateness loss  Feature compactness lossを極めると全ての特徴が1点に落ちればよくなるので，それを防ぐために2番目に近いmemory $\\mathbf{p}_n$ をquery $\\mathbf{q^k_t}$からmargin $\\alpha$ 分遠ざける $$ \\mathcal{L} _ {\\text {separate }}=\\sum _ {t}^{T} \\sum _ {k}^{K}\\left[\\left|\\mathbf{q} _ {t}^{k}-\\mathbf{p} _ {p}\\right| _ {2}-\\left|\\mathbf{q} _ {t}^{k}-\\mathbf{p} _ {n}\\right| _ {2}+\\alpha\\right] _ {+}$$  異常度の算出   query と memoryのL2 $$ D(\\mathbf{q_t}, \\mathbf{p})=\\frac{1}{K}\\Sigma^K_k | \\mathbf{q^k_t} - \\mathbf{p_p} | _ 2 $$\n  入出力のPSNR．$N$はピクセル数 $$ P(\\mathbf{\\hat{I} _ t}, \\mathbf{I}) = 10 \\log_10 \\frac{\\max(\\mathbf{I _ t})}{| \\mathbf{\\hat{I} _ t} - \\mathbf{I} | ^2 _ 2 / N} $$\n  $t$ frame目の異常度は $$ \\mathcal{S} _ {t}=\\lambda\\left(1-g\\left(P\\left(\\hat{\\mathbf{I}} _ {t}, \\mathbf{I} _ {t}\\right)\\right)\\right)+(1-\\lambda) g\\left(D\\left(\\mathbf{q} _ {t}, \\mathbf{p}\\right)\\right) $$\n  ↑の$g()$はmin-max normalization．2つの異常度のバランスをとる $$ g\\left(D\\left(\\mathbf{q} _ {t}, \\mathbf{p}\\right)\\right)=\\frac{D\\left(\\mathbf{q} _ {t}, \\mathbf{p}\\right)-\\min _ {t}\\left(D\\left(\\mathbf{q} _ {t}, \\mathbf{p}\\right)\\right.}{\\max _ {t}\\left(D\\left(\\mathbf{q} _ {t}, \\mathbf{p}\\right)\\right)-\\min _ {t}\\left(D\\left(\\mathbf{q} _ {t}, \\mathbf{p}\\right)\\right)} $$\n  4. どうやって有効だと検証した？  Ped2, Avenue, Shanghaiの3つ異常動画検出データセットで実験  画像は$256 \\times 256$ $H=W=32, C=512, M=10$   フレーム予測versionが最も精度高い   5. 議論はあるか？  testの際にもメモリ更新は面白い 再構成系のモデルがあまり精度高くないのが残念  6. 次に読むべき論文はある？  D. Gong,L. Liu,V. Le,B. Saha,M. R. Mansour,S. Venkatesh,and A. van den Hengel: “Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection,”(2019). my note  ","date":1592265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592265600,"objectID":"8928cb0798869963e150364148626c1a","permalink":"https://salty-vanilla.github.io/portfolio/post/memory_guided_anodetect/","publishdate":"2020-06-16T00:00:00Z","relpermalink":"/portfolio/post/memory_guided_anodetect/","section":"post","summary":"1. どんなもの？ Unsupervised な Anomaly Detectionの枠組み Autoencoder系のADで，Autoencoderの潜在特徴MAPにMemory構造を採","tags":["CVPR2020"],"title":"Learning Memory-guided Normality for Anomaly Detection","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  Unsupervised な Anomaly Detectionの枠組み Large Imageに対して，Patchで学習してAnomalyのSegmentationが可能 自然画像で学習したTeacherと工業製品で学習する複数のStudentモデル  2. 先行研究と比べてどこがすごい？  Unsupervised な Anomaly DetectionのSegmentaionにはAutoencoder系があったが再構成誤差によるもので，不正確だった transfer learningの枠組みは今まで工業製品のAnomaly Detectionでは使いづらかった  Domainの違い 解像度の違い    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  変数の定義  $ \\mathcal{D} = \\{ I_1, I_2, \\cdots, I_N \\} $ : データセット $I_n \\in \\R^{h \\times w \\times ch}$ : 入力画像 $S_i(I_n) \\in \\R^{h \\times w \\times d}$ : $i$番目のstudent networkに入力すると，入力と同じサイズのfeature mapが生成される $T(I_n) \\in \\R^{h \\times w \\times d}$ : teacher networkも同様 $y_{r, c} \\in \\R^d$ : $S_i(I)$のMapのposition $r, c$における特徴ベクトル． $p_{r, c} \\in \\R^{p \\times p \\times ch}$ : position $r, c$における$I$のパッチ    Learning Local Patch Descriptors  まずTeacher $T$ を学習するために，$\\hat{T}$を学習する  $\\hat{T}(I_n) \\notin \\R^{h \\times w \\times d}$ である（Poolingなどによって空間解像度が落ちる） FDFEを適用することで，空間解像度を落とさないようにすることで$T$ を求める   $\\hat{T}$はImagenetなどの自然画像で事前学習された$P$というNetworkを蒸留（Distillation）することで学習する  3つのLossを最小化することで蒸留  ↓の$p$はImagenet任意のデータセットの画像からCropしたもの $$ \\mathcal{L}(\\hat{T})=\\lambda_{k} \\mathcal{L} _ {k}(\\hat{T})+\\lambda_{m} \\mathcal{L} _ {m}(\\hat{T})+\\lambda_{c} \\mathcal{L}_{c}(\\hat{T}) $$    Knowledge Distillation. $$ \\mathcal{L}_{k}(\\hat{T})=|D(\\hat{T}(\\mathbf{p}))-P(\\mathbf{p})|^{2} $$\nMetric Learning 要はtriplet loss $$ \\mathcal{L} _ {m}(\\hat{T})=\\max \\{0, \\delta+\\delta^{+}-\\delta^{-}\\} $$\n$$ \\delta^{+}=\\left|\\hat{T}(\\mathbf{p})-\\hat{T}\\left(\\mathbf{p}^{+}\\right)\\right|^{2} $$\n$$ \\delta^{-}=\\min \\{\\|\\hat{T}(\\mathbf{p})-\\hat{T}(\\mathbf{p}^{-})\\|^{2},\\|\\hat{T}(\\mathbf{p}^{+})-\\hat{T}(\\mathbf{p}^{-})\\|^{2}\\} $$\nDescriptor Compactness $c$ をcurrent minibatchにおける$\\hat{T}$の出力の相関行列とすると $$ \\mathcal{L} _ {c}(\\hat{T})=\\sum_{i \\neq j} c_{i j} $$\nEnsemble of Student Networks  $\\mu \\in \\R^{d}$, $\\sigma \\in \\R^{d}$\n$\\mathcal{D}$のすべての画像を$T$に入力して得られた全Feature mapのh, w方向の平均と分散 $M$個のstudent networkをrandom initialize．構造は$T$と同じもの  入力をパッチにしなくても，パッチ相当$p_{r, c}, [r \\in \\{0, 1, \\cdots, h\\}, c \\in \\{0, 1, \\cdots, w\\}]$の特徴抽出が可能 studentの出力ベクトル$y_{r,c}$をガウス分布としてモデリングすると，\n（$\\mu _ {r, c}^{S_{i}}$ は$y_{r,c}$の平均，$s$はconstant covariance） $$ \\operatorname{Pr}\\left(\\mathbf{y} | \\mathbf{p} _ {r, c}\\right)=\\mathcal{N}\\left(\\mathbf{y} | \\boldsymbol{\\mu} _ {r, c}^{S_{i}}, s\\right) $$   loglikelihood 最大化によって最適化する $$ \\mathcal{L}\\left(S_{i}\\right)=\\frac{1}{w h} \\sum_{r, c}\\left|\\boldsymbol{\\mu}_{r, c}^{S_{i}}-\\left(\\mathbf{y}_{r, c}^{T}-\\boldsymbol{\\mu}\\right) \\operatorname{diag}(\\boldsymbol{\\sigma})^{-1}\\right|_{2}^{2} $$  異常度の算出   studentのloglikelihoodの平均 $$ \\begin{aligned} e_{r, c} \u0026amp;=\\left|\\boldsymbol{\\mu} _ {r, c}-\\left(\\mathbf{y} _ {r, c}^{T}-\\boldsymbol{\\mu}\\right) \\operatorname{diag}(\\boldsymbol{\\sigma})^{-1}\\right| _ {2}^{2} \\\\ \u0026amp;=\\left|\\frac{1}{M} \\sum_{i=1}^{M} \\boldsymbol{\\mu}_{r, c}^{S_{i}}-\\left(\\mathbf{y}_{r, c}^{T}-\\boldsymbol{\\mu}\\right) \\operatorname{diag}(\\boldsymbol{\\sigma})^{-1}\\right|_{2}^{2} \\end{aligned} $$\n  studentたちの回答のばらつきをみる $$ v_{r, c}=\\frac{1}{M} \\sum_{i=1}^{M}\\left|\\boldsymbol{\\mu}_{r, c}^{S_{i}}\\right|_{2}^{2}-\\left|\\boldsymbol{\\mu}_{r, c}\\right|_{2}^{2} $$\n  ↑2つのscoreを合わせて $$ \\tilde{e} _ {r, c}+\\tilde{v} _ {r, c}=\\frac{e_{r, c}-e_{\\mu}}{e_{\\sigma}}+\\frac{v_{r, c}-v_{\\mu}}{v_{\\sigma}} $$   Multi-Scale Anomaly Segmentation  $L$種類のreceptive fieldのteacherとstudentを学習させれば，Multi-scaleの枠組みも可能 $$ \\frac{1}{L} \\sum_{l=1}^{L}\\left(\\tilde{e}_{r, c}^{(l)}+\\tilde{v}_{r, c}^{(l)}\\right) $$  4. どうやって有効だと検証した？  Imagenetで学習したResnet18を$P$として，512次元の特徴を抽出させる MNIST，Cifar10での実験では$p=33$で実験  MVTecでも実験  teacherをshallowにするために，\n$P$の出力をPCAして累積寄与率95%になるように次元数削減しているらしい     5. 議論はあるか？  公式実装待ち  6. 次に読むべき論文はある？ ","date":1591488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591488000,"objectID":"0fe7306d698cd9085b2d19d188d3aaa0","permalink":"https://salty-vanilla.github.io/portfolio/post/student_teacher_anodetct/","publishdate":"2020-06-07T00:00:00Z","relpermalink":"/portfolio/post/student_teacher_anodetct/","section":"post","summary":"1. どんなもの？ Unsupervised な Anomaly Detectionの枠組み Large Imageに対して，Patchで学習してAnomalyのSegmentationが可能 自然画","tags":["CVPR2020"],"title":"Uninformed Students: Student-Teacher Anomaly Detection with Discriminative Latent Embeddings","type":"post"},{"authors":null,"categories":["Feature Learning"],"content":"1. どんなもの？  Patchで学習したCNNをOriginalに対して，sliding windowして特徴抽出する枠組みの改善 ↑は計算が冗長で計算時間が長い Patchで学習したCNNを再学習することなく，pooling layerを置き換えるだけでOK  2. 先行研究と比べてどこがすごい？  大きい画像に対して，sliding windowして特徴抽出する方法は計算が冗長で計算時間が長い  sliding window使わない方法では，poolingやstride などで特徴抽出された画像は元画像よりかなり小さくなる  e.g.) VGGの場合は，224x224 -\u0026gt; 7x7で1/32のサイズになる     Patchで学習したCNNを再学習することなく，pooling layerを置き換えるだけでOK   3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  変数の定義  $I \\in \\R^{I_h \\times I_w \\times I_c}$ : Originalの入力画像 $P_{x, y} \\in \\R^{P_h \\times P_w \\times I_c}$ : 位置$(x,y)$のパッチ $O_{x, y} = C_p(P_{x, y}) \\in \\R^{k}$ : 位置$(x,y)$のパッチを通常のCNN $C_p$でfeature extractして得られたベクトル $O \\in \\R^{I_h \\times I_w \\times I_c}$ :    sliding windowせず，$O \\in \\R^{I_h \\times I_w \\times I_c}$ が得られるモデル$C_L$を求めたい\nLayers without pooling  poolingやstride convでないlayerは，Patchで学習したCNNを転用する  Multipool to consider all locations  Pooling LayerをMultipoolに置き換え 2x2のPoolingでは↓のように4つのPooling Patternが考えられる   $$ \\operatorname{Pool}_{s \\times s}^{x, y}(I)=\\operatorname{Pool} _ {s \\times s}\\left(\\operatorname{SHIF} T _ {y, x}(I)\\right) $$\nLayerの出力は4つのPooling Patternの出力の集合．\n通常Poolingすると，解像度が落ちるがこの方法では落ちていない．\n$$ L _ {I}^{\\text {multipool}}=\\{\\text {Pool} _ {s \\times s}^{0,0}, \\text {Pool} _ {s \\times s}^{0,1}, \\ldots, \\text {Pool} _ {s \\times s}^{0, s-1}, \\ldots, \\text {Pool} _ {s \\times s}^{s-1,0}, \\ldots, \\operatorname{Pool} _ {s \\times s}^{s-1, s-1}\\} $$\nUnwarping   1個のMultipoolを持つCNNの出力は，Leftであり，それを並べ替えてRightにする   演算的には，(Leftのshape:$(s=2, s=2, \\frac{I_h=4}{s=2}, \\frac{I_w=6}{s=2}, k=1)$)\n transpose dim=(1, 2) -\u0026gt; (2, 2, 2, 3, 1) reshape (2x2, 2x3, 1) -\u0026gt; (4, 6, 1)    $n$個のMultipoolを持つ場合は，出力のshapeは$(s^n, s^n, \\frac{I_h}{s^n}, \\frac{I_w}{s^n}, k)$\n  loop for i in range(0, n)\n reshape -\u0026gt; $(s^{n-i}, s^{n-i}, \\frac{I_h}{s^{n-i}}, \\frac{I_w}{s^{n-i}}, k)$ transpose dim=(1, 2) -\u0026gt; $(s^{n-i}, \\frac{I_w}{s^{n-i}}, s^{n-i}, \\frac{I_h}{s^{n-i}}, k)$    reshape -\u0026gt; $(I_h, I_h, k)$\n    ※ 論文内の記述を理解できなかったので，プログラムの方から解釈してます↑\n4. どうやって有効だと検証した？ GTX TITAN Xを使って，sliding windowと速度比較 5. 議論はあるか？  Unwarpingの式の記述の仕方が理解できなかった Githubのプログラムはこれであってるのか？  reshapeとtranspose周り    6. 次に読むべき論文はある？ ","date":1591401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591401600,"objectID":"4758cbbb6ebd0ebb8dee50d9632e1a71","permalink":"https://salty-vanilla.github.io/portfolio/post/fdfe/","publishdate":"2020-06-06T00:00:00Z","relpermalink":"/portfolio/post/fdfe/","section":"post","summary":"1. どんなもの？ Patchで学習したCNNをOriginalに対して，sliding windowして特徴抽出する枠組みの改善 ↑は計算が冗長で計","tags":null,"title":"Fast Dense Feature Extraction for CNNs","type":"post"},{"authors":null,"categories":["Reinforcement Learning"],"content":"強化学習の目的 変数の定義  $\\mathcal{S}$ : 状態の集合 $\\mathcal{A}$ : 行動の集合 $P_T(s _ {t+1} | s_t, a_t)$ : 状態$s_t$で行動$a_t$をしたときにに，状態$s_{t+1}$に遷移する確率を出力する関数（状態遷移確率関数） $\\pi(a_t | s_t)$ :　状態$s_t$時の行動$a_t$を選択する確率を出力する関数（政策関数） $R(s_t, a_t, s_{t+1})$ :　報酬関数 $\\gamma$ : 割引率  目的関数 $$ \\mathbb{E}[ \\Sigma^{\\infty}_{t=0} \\gamma^{t} R(s_t, a_t, s _ {t+1}) ], \\forall s_0 \\in \\mathcal{S}, \\forall a_0 \\in \\mathcal{A} $$\n$$ a_t \\stackrel{iid}{\\sim} \\pi(a_t | s_t) $$ $$ s _ {t+1} \\stackrel{iid}{\\sim} P_T(s _ {t+1} | s_t,a_t) $$ $$ s_t \\in \\mathcal{S}, a_t \\in \\mathcal{A} $$ $$ \\gamma \\in (0, 1] $$\n最適政策関数 最適政策関数$\\pi^*$は以下で表される\n$$ \\pi^*(a|s) = \\argmax_\\pi \\mathbb{E}[ \\Sigma^{\\infty}_{t=0} \\gamma^{t} R(s_t, a_t, s _ {t+1}) ] $$\nまた、政策$\\pi$で得られる報酬の総和を収益（Return）という $$ C_t = \\mathbb{E}_\\pi[ \\Sigma^\\infty _ {\\tau=0} \\gamma^\\tau R(s _{t+\\tau}, a _{t+\\tau}, s _ {t+\\tau+1}) ] $$ $ r_t = R(s_t, a_t, s _{t+1}) $ とすると，$C_t$は以下のような再帰構造を持つ\n$$ \\begin{aligned} C_t \u0026amp;= r_t + \\mathbb{E}_\\pi[ \\Sigma^\\infty _ {\\tau=1} \\gamma^\\tau R(s _{t+\\tau}, a _{t+\\tau}, s _ {t+\\tau+1}) ] \\\\ \u0026amp;= r_t + \\gamma C _ {t+1} \\end{aligned} $$\n状態価値関数 $$ \\begin{aligned} V^\\pi(s) \u0026amp;= \\mathbb{E}_{\\pi} [ r_0 + \\gamma C_1 | s_0 = s ] \\\\ \u0026amp;= \\displaystyle\\sum _{a \\in \\mathcal{A}} \\pi(a | s) \\displaystyle\\sum _{s^{\\prime} \\in S} P_T(s^{\\prime} | s, a)R(s, a, s^{\\prime}) + \\gamma \\displaystyle\\sum _{a \\in \\mathcal{A}} \\pi(a | s) \\displaystyle\\sum _{s^{\\prime} \\in S}P_T(s^{\\prime} | s, a)V^\\pi(s^{\\prime}) \\\\ \u0026amp;= \\displaystyle\\sum _{a \\in \\mathcal{A}} \\pi(a | s) \\displaystyle\\sum _{s^{\\prime} \\in S} P_T(s^{\\prime} | s, a)(R(s, a, s^{\\prime}) + \\gamma V^\\pi(s^{\\prime}) ) \\end{aligned} $$\n状態行動価値関数 $$ \\begin{aligned} Q^\\pi(s,a) \u0026amp;= \\mathbb{E}_{\\pi} [ r_0 + \\gamma C_1 | s_0 = s, a_0=a ] \\\\ \u0026amp;= \\displaystyle\\sum _{s^{\\prime} \\in S} P_T(s^{\\prime} | s, a)R(s, a, s^{\\prime}) + \\gamma \\displaystyle\\sum _{a^{\\prime} \\in \\mathcal{A}} \\displaystyle\\sum _{s^{\\prime} \\in S}P_T(s^{\\prime} | s, a)\\pi(a^{\\prime} | s^{\\prime})Q^\\pi(s^{\\prime},a^{\\prime}) \\\\ \u0026amp;= \\displaystyle\\sum _{s^{\\prime} \\in S} P_T(s^{\\prime} | s, a)(R(s, a, s^{\\prime}) + \\gamma \\displaystyle\\sum _{a^{\\prime} \\in \\mathcal{A}} \\pi(a^{\\prime} | s^{\\prime})Q^\\pi(s^{\\prime},a^{\\prime})) \\end{aligned} $$\n状態価値関数と状態行動価値関数の関係 $$ V^\\pi(s) = \\mathbb{E} _{\\pi(a | s)} [ Q^\\pi(s,a)] $$\n$$ Q^\\pi(s,a) = \\mathbb{E} _ {P_T(s^{\\prime} | s,a)} [ V^\\pi(s^{\\prime}) ] $$\n動的計画法の問題点 状態遷移確率関数（モデル）$P_T(s _ {t+1} | s_t, a_t)$ が既知なら動的計画法で収益最大化問題が解ける．\nしかし，モデルが未知の場合はモデルフリーな手法が必要となる．\nまた，モデルが既知でも状態空間と行動空間が大きい場合は，計算量が膨大になってしまう．\nQ-learning   試行錯誤，逐次更新を繰り返すことで，行動価値を直接推定・最適化する（モデルフリー）\n  下式1行目の$r _{t+1} + \\gamma \\max _{a^\\prime \\in \\mathcal{A}}Q(s _{t+1},a^\\prime )$ が試行錯誤で得られた推定価値\n  $\\alpha$ : 学習率\n  $$ \\begin{aligned} Q(s_t, a_t) \u0026amp;\\leftarrow (1 - \\alpha)Q(s_t,a_t) + \\alpha ( r _{t+1} + \\gamma \\max _{a^\\prime \\in \\mathcal{A}}Q(s _{t+1},a^\\prime )) \\\\ \u0026amp;= Q(s_t,a_t) + \\alpha ( r _{t+1} + \\gamma \\max _{a^\\prime \\in \\mathcal{A}}Q(s _{t+1},a^\\prime) - Q(s_t, a_t)) \\end{aligned} $$\n Off-policy(政策に依存しない)であるため，任意のpolicyに従いながらQ値の更新が可能．  epsilon greedy policy  確率$\\epsilon$で$\\mathcal{A}$の中からランダムで行動選択 確率$1-\\epsilon$で行動価値最大の行動を取る 学習が進むにつれて，$\\epsilon$を0に近づけることで，決定的にしていく  $$ a^* = \\argmax_aQ^\\pi(s,a) $$\n$$ \\pi^\\prime(a|s) = \\begin{cases} 1-\\epsilon + \\frac{\\epsilon}{| \\mathcal{A}|} \u0026amp; \\text{ if } a = a^* \\\\ \\frac{\\epsilon}{| \\mathcal{A}|} \u0026amp; \\text{ otherwise } \\end{cases} $$\nsoftmax policy (Boltzman policy)  温度パラメータ$T$によってランダム性を調整する 学習が進むにつれて，$T$を0に近づけることで，決定的にしていく  $$ \\pi^\\prime(a|s) = \\frac{\\exp(Q^\\pi(s,a)/T)}{\\sum_{a^\\prime \\in \\mathcal{A}}\\exp(Q^\\pi(s,a)/T)} $$\n","date":1590796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590796800,"objectID":"6d0f555c3631c5e6f9ea072b9366a402","permalink":"https://salty-vanilla.github.io/portfolio/post/dqn/","publishdate":"2020-05-30T00:00:00Z","relpermalink":"/portfolio/post/dqn/","section":"post","summary":"強化学習の目的 変数の定義 $\\mathcal{S}$ : 状態の集合 $\\mathcal{A}$ : 行動の集合 $P_T(s _ {t+1} | s_t, a_t)$ : 状態$s_t$で行動$a_t$をしたときにに，状態$s_{t+1}$に遷移","tags":["tutorial"],"title":"Deep Q Network","type":"post"},{"authors":null,"categories":["SVM"],"content":"1. どんなもの？  SVMの距離をユークリッド空間ではなく，非ユークリッド空間で取る 具体的にはPoincare disk上とか  2. 先行研究と比べてどこがすごい？  SVMの距離算出を比ユークリッド空間で行う  階層構造を持つデータなどに対して精度良く識別ができる textとかgraphとか    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 前提知識 Hyperbolid model  内積が$x*y = x_0y_0 - x_1y_2 - \\cdots x_ny_n$で定義されるMinkowski space $n$次元のhyperbolid model $\\mathbb{L_n}$は$\\mathbb{R} ^ {n+1}$の単位球の上半平面上にある $$ \\mathbb{L}^{n}=\\left \\{ x: x=\\left(x_{0}, \\ldots, x_{n}\\right) \\in \\mathbb{R}^{n+1}, x * x=1, x_{0}\u0026gt;0\\right \\} $$   Poincare Ball  有名なポアンカレ円盤 $$ \\mathbb{B}^{n}=\\left \\{ x: x=\\left(x_{1}, \\ldots, x_{n}\\right) \\in \\mathbb{R}^{n},|x|^{2}\u0026lt;1\\right \\} $$ hyperbolidの特殊な形と言える $$ \\left(x_{0}, \\ldots, x_{n}\\right) \\in \\mathbb{L}^{n} \\Leftrightarrow\\left(\\frac{x_{1}}{1+x_{0}}, \\ldots, \\frac{x_{n}}{1+x_{0}}\\right) \\in \\mathbb{B}^{n} $$   https://qiita.com/hibit/items/5a49bedaa826fddf0a33   SVM  目的関数は $$ \\operatorname{minimize} _ {w \\in \\mathbb{R} ^ {n}} \\frac{1}{2}|w|^{2}+C \\sum_{j=1}^{m} \\max \\left(0,1-y^{(j)}\\left(w^{T} x^{(j)}\\right)\\right) $$  Hyperbolic Support Vector Classification  $x$からdecision boundaryまでの距離を下で定義 $$ \\sinh ^{-1}\\left(\\frac{w * x}{\\sqrt{-w * w}}\\right) $$ 目的関数は $$ \\operatorname{minimize} _ {w \\in \\mathbb{R}^{n+1}}-\\frac{1}{2} w * w+C \\sum_{j=1}^{m} \\max \\left(0, \\sinh ^{-1}(1)-\\sinh ^{-1}\\left(y^{(j)}\\left(w * x^{(j)}\\right)\\right)\\right) $$ $$ \\text{subject to } w * w\u0026lt;0 $$  4. どうやって有効だと検証した？  GMM（混合数4）から発生させたデータに対して実験  4つのreal datasetに対して実験  生で使うのではなく，embdして識別 比較がずるい気がする     5. 議論はあるか？  精度云々は置いておいて，距離を非ユークリッド空間でとるアイデア  6. 次に読むべき論文はある？  https://tech-blog.abeja.asia/entry/poincare-embeddings https://tech-blog.abeja.asia/entry/hyperbolic_ml_2019 Nickel, M., \u0026amp; Kiela, D. (2018). Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry. Retrieved from http://arxiv.org/abs/1806.03417  ","date":1583107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583107200,"objectID":"15e76c45d585e819aa1afd2a54cd2093","permalink":"https://salty-vanilla.github.io/portfolio/post/hyperbolic_svm/","publishdate":"2020-03-02T00:00:00Z","relpermalink":"/portfolio/post/hyperbolic_svm/","section":"post","summary":"1. どんなもの？ SVMの距離をユークリッド空間ではなく，非ユークリッド空間で取る 具体的にはPoincare disk上とか 2. 先行研究と比べてどこ","tags":null,"title":"Large-Margin Classification in Hyperbolic Space Hyunghoon","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う Deep SVDDベースのDeep SADを提案  Deep SVDD + 少量の教師つきデータ + mutual info    2. 先行研究と比べてどこがすごい？  Deep SVDD (Unsupervised: 正常データのみ)にSemi-Supervised: 正常データ + 少量の教師つきデータ の枠組みを追加 最近この問題設定流行り？  より実利用に近い感じがしてgood   classification と one-class learning のいいとこどり   3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Deep SVDD + 少量の教師つきデータ + mutual info  Mutual Information  Information Bottleneck (classification)では，入力$x$と潜在変数$z$，ラベル$y$それぞれのmutual info $\\mathbb{I}$を最大化 $$ min_{p(z|x)} {\\mathbb{I}(X; Z) - \\alpha\\mathbb{I}(Z; Y)} $$ Unsupervisedなら，正則化項$R$を使って $$ max_{p(z|x)} {\\mathbb{I}(X; Z) + \\beta R(Z)} $$ autoencoderはInfomaxの枠組みとも考えられる  Deep SVDD  以前まとめた https://salty-vanilla.github.io/portfolio/post/deep_svdd/ を参照 $$ \\min _ {w} \\frac{1}{n} \\sum_{i=1}^{n}\\left|\\phi\\left(\\boldsymbol{x} _ {i} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2}+\\frac{\\lambda}{2} \\sum_{\\ell=1}^{L}\\left|\\boldsymbol{W}^{\\ell}\\right|_{F}^{2}, \\quad \\lambda\u0026gt;0 $$ Deep SVDDはemprical varianceを最小化している $s(x) = \\left|\\phi\\left(\\boldsymbol{x} _ {i} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2} $ はlatent gaussian のentropyの上界とみなせて，それの最小化をしている  AutoencoderでNNを初期化していることが前提    Deep SAD (Semi-supervised Anomaly Dection) 変数の定義  $x_1, \\cdots, x_n$ : unlabeled samples $(\\tilde{x_1}, \\tilde{y_1}), \\cdots, (\\tilde{x_m}, \\tilde{y_m})$ : labeled samples  normalなら $\\tilde{y} = +1$ anomalyなら $\\tilde{y} = -1$    目的関数   Unsupervised のInfomaxを適用して $$ max_{p(z|x)} {\\mathbb{I}(X; Z) + \\beta (\\mathbb{H}(Z^{-}) - \\mathbb{H}(Z^{+}))} $$\n $\\mathbb{H}$ : entropy $Z^{-}$ : $\\tilde{y} = -1$ の$x$に対する潜在変数 $Z^{+}$ : $\\tilde{y} = +1$ の$x$に対する潜在変数    これにDeep SVDDの枠組みを適用すると $$ \\min _ {\\boldsymbol{w}} \\frac{1}{n+m} \\sum_{i=1}^{n}\\left|\\phi\\left(\\boldsymbol{x} _ {i} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2}+\\frac{\\eta}{n+m} \\sum_{j=1}^{m}\\left(\\left|\\phi\\left(\\tilde{\\boldsymbol{x}} _ {j} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2}\\right)^{\\tilde{y} _ {j}}+\\frac{\\lambda}{2} \\sum_{\\ell=1}^{L}\\left|\\boldsymbol{W}^{\\ell}\\right|_{F}^{2} $$\n 1, 3項目はDeepSVDD 2項目が↑式の正則化項にあたる  normalなら$c$に近く anomalyなら$c$から遠く      4. どうやって有効だと検証した？  MNIST, Fashion-MNIST, Cifar10で実験 labelつきデータの異常データを増やすほどAUC上昇  labelなしデータの中に異常データが混入しても他手法よりも精度が落ちない   5. 議論はあるか？  Deep SVDD + Semisupervisedは自分も考えていただけに先越された感 今年はこの問題設定流行りそう  6. 次に読むべき論文はある？ ","date":1582761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"d853b2f9089fc65f3dd48a9e92b1662f","permalink":"https://salty-vanilla.github.io/portfolio/post/deep_sad/","publishdate":"2020-02-27T00:00:00Z","relpermalink":"/portfolio/post/deep_sad/","section":"post","summary":"1. どんなもの？ 大量の正常データと少量の異常データからAnomaly Detectionを行う Deep SVDDベースのDeep SADを提案 Deep SVDD + 少量の","tags":null,"title":"Deep Semi-Supervised Anomaly Detection","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う 入力は2入力でWeight SharingされたNNから得られた特徴ベクトル同士を結合して異常度回帰  2. 先行研究と比べてどこがすごい？  正常データからAnomaly Detectionモデルを作れるのは当たり前 実利用においては，少量の異常データを如何にうまく使うかが求められる DevNetの異常度のreference scoreがデータに一切依存していないことを改善？  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Pairwise Relation を学習 大量の正常データと少量の異常データからAnomaly Detectionを行う テスト時には正常データと異常データと比較することで異常度算出  変数の定義  $\\mathcal{U} = \\{ u_1, u_2, \\cdots, u_N \\}$ : unlabeled samples (正常データとごく少量の異常データ) $\\mathcal{A} = \\{ a_1, a_2, \\cdots, a_K \\}$ : labeled samples (少量の異常データ) その他の変数は下を参照   Loss関数 $$ \\underset{\\Theta}{\\arg \\min } \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} _ {i}, \\mathbf{x} _ {j}, y_{i j} \\in \\mathcal{B}}\\left|y_{i j}-\\phi\\left(\\left(\\mathbf{x} _ {i}, \\mathbf{x}_{j}\\right) ; \\Theta\\right)\\right|+\\lambda R(\\Theta) $$\n $\\mathcal{B}$ は$\\mathcal{U}$(正常)と$\\mathcal{A}$(異常)からサンプリングされたサンプルで構成 $c_1 \u0026lt; c_2 \u0026lt; c_3$ 異常/異常の組み合わせ : $y=c_1$ (めちゃめちゃ遠くに) 異常/正常の組み合わせ : $y=c_2$ (遠くに) 正常/正常の組み合わせ : $y=c_3$ (近くに)  異常度の算出 $$ s_{\\mathbf{x}_{k}}=\\frac{1}{2 E}\\left[\\sum_{i=1}^{E} \\phi\\left(\\left(\\mathbf{a}_{i}, \\mathbf{x}_{k}\\right) ; \\Theta^{*}\\right)+\\sum_{j=1}^{E} \\phi\\left(\\left(\\mathbf{x}_{k}, \\mathbf{u}_{j}\\right) ; \\Theta^{*}\\right)\\right] $$\n $x_k$が異常なら$s_{x_k}$が大（理論値 : $c_1 + c_2$） $x_k$が正常なら$s_{x_k}$が小（理論値 : $c_2 + c_3$）  4. どうやって有効だと検証した？  様々なAD datasetでSoTA  Deep SVDD: AD．タスクに合わせてenhanceしたモデルを実装したとのこと prototypical networks (FSNet) : few-shot classification iForest: AD DevNet: 筆者のmethod     5. 議論はあるか？  $c_1$, $c_2$, $c_3$のチューニングは必要？ サンプリング方法を同じにしたSiamse Networkとの比較は？ Deep SVDDをどうenhanceしたか？  6. 次に読むべき論文はある？ ","date":1582675200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582675200,"objectID":"31ad7af78894e8b3a0620c8b53cf6b74","permalink":"https://salty-vanilla.github.io/portfolio/post/prenet/","publishdate":"2020-02-26T00:00:00Z","relpermalink":"/portfolio/post/prenet/","section":"post","summary":"1. どんなもの？ 大量の正常データと少量の異常データからAnomaly Detectionを行う 入力は2入力でWeight SharingされたNN","tags":null,"title":"Deep Weakly-supervised Anomaly Detection","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  大量の正常データと少量の異常データからAnomaly Detectionを行う 枠組みとしてはDeep SVDDに近い  2. 先行研究と比べてどこがすごい？  正常データからAnomaly Detectionモデルを作れるのは当たり前 実利用においては，少量の異常データを如何にうまく使うかが求められる end2end  AnoGANなどはnot end2end    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  大量の正常データと少量の異常データからAnomaly Detectionを行う  変数の定義  $ \\mathcal{X} = \\{ x_1, x_2, \\cdots, x_N, x_{N+1}, \\cdots, x_{N+K} \\} $ : training samples $\\mathcal{U} = \\{ x_1, x_2, \\cdots, x_N \\}$ : unlabeled samples (正常データとごく少量の異常データ) $\\mathcal{K} = \\{ x_{N+1}, x_{N+2}, \\cdots, x_{N+K} \\}$ : labeled samples (少量の異常データ) $K \u0026laquo; N$ : 異常データは少量 $\\phi(x, \\theta)$ : Scoring Network  Framework   Scoring NetworkからScoreを算出\n  Reference Scoreを算出\n 確率分布$F$から$l$個の乱数を生成 $l$個の乱数から平均$\\mu_R$と分散$\\sigma_R$を算出 なにかNNとかあるわけではないので注意 $F$は$\\mathcal{N}(\\mu=0, \\sigma=1)$，$l=5000$くらいで十分らしい    Deviation Lossを算出\n $x \\sim \\mathcal{U}$ なら $y=0$ (正常) deviationを$0$に $x \\sim \\mathcal{K}$ なら $y=1$ (異常) deviationを$a$に $$ \\operatorname{dev}(\\mathbf{x})=\\frac{\\phi(\\mathbf{x} ; \\Theta)-\\mu_{\\Re}}{\\sigma_{\\mathcal{R}}} $$ $$ L\\left(\\phi(\\mathbf{x} ; \\Theta), \\mu_{\\mathcal{R}}, \\sigma_{\\mathcal{R}}\\right)=(1-y)|dev(\\mathbf{x})|+y \\max (0, a-\\operatorname{dev}(\\mathbf{x})) $$     4. どうやって有効だと検証した？  様々なAD datasetでSoTA  REPEN: limited labeld dataのAD Deep SVDD: AD．タスクに合わせてenhanceしたモデルを実装したとのこと prototypical networks (FSNet) : few-shot classification iForest: AD     5. 議論はあるか？  $F$が標準正規分布なら，$\\mu_R=0$，$\\sigma=0$となってデータに全く依存しないReference Scoreになってるけどいいのか？  この筆者の次の論文では解決されるらしい[1]   結局ミニバッチのサンプリングを$\\mathcal{U}$から半分，$\\mathcal{K}$から半分とってきてるのが大きそう  6. 次に読むべき論文はある？  Pang, G., Shen, C., Jin, H., \u0026amp; Hengel, A. van den. (2019). Deep Weakly-supervised Anomaly Detection. Retrieved from https://arxiv.org/abs/1910.13601  ","date":1581811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581811200,"objectID":"69d5f6c2d457b02ecb25867109ffc731","permalink":"https://salty-vanilla.github.io/portfolio/post/devnet/","publishdate":"2020-02-16T00:00:00Z","relpermalink":"/portfolio/post/devnet/","section":"post","summary":"1. どんなもの？ 大量の正常データと少量の異常データからAnomaly Detectionを行う 枠組みとしてはDeep SVDDに近い 2. 先行研究と比","tags":null,"title":"Deep Anomaly Detection with Deviation Networks","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  One-Class SVM (OCSVM)の非線形カーネルをNNで置き換えたモデル anomaly detectionの枠組みとして，soft-boundary と one-class Deep SVDDを提案  2. 先行研究と比べてどこがすごい？  OCSVMの非線形カーネルをNNで置き換えた  OSCVMより優れた表現力を持つ   SVDD (Support Vector Data Description) OCSVMのobjective  $x$ : sample $w$ : weights $\\phi$ : kernel function $\\rho$ : distance from the origin to hyperplane $w$ $\\xi$ : margin $$ \\min _ {\\boldsymbol{w}, \\rho, \\boldsymbol{\\xi}} \\frac{1}{2}|\\boldsymbol{w}|_{\\mathcal{F}_{k}}^{2}-\\rho+\\frac{1}{\\nu n} \\sum_{i=1}^{n} \\xi_{i} $$ $$ \\text { s.t. } \\quad\\left\\langle\\boldsymbol{w}, \\phi_{k}\\left(\\boldsymbol{x} _ {i}\\right)\\right\\rangle_{\\mathcal{F} _ {k}} \\geq \\rho-\\xi_{i}, \\quad \\xi_{i} \\geq 0, \\quad \\forall i $$    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  OCSVM + NN   soft boudary  objective $$ \\min _ {R, W} R^{2}+\\frac{1}{\\nu n} \\Sigma_{i=1}^n \\max ( 0, \\|\\phi(x_{i} ; \\mathcal{W})-c\\|^{2}-R^{2}) +\\frac{\\lambda}{2} \\sum_{\\ell=1}^{L}\\left|\\boldsymbol{W}^{\\ell}\\right|_{F}^{2} $$  $R$はミニバッチ内の0.9 quantile目のdistance : $\\|\\phi(x_{i} ; \\mathcal{W})-c\\|^{2}$ $R$より中心から離れたサンプルだけにペナルティを与える感じ    one-class  objective $$ \\min _ {w} \\frac{1}{n} \\sum_{i=1}^{n}\\left|\\phi\\left(\\boldsymbol{x}_ {i} ; \\mathcal{W}\\right)-\\boldsymbol{c}\\right|^{2}+\\frac{\\lambda}{2} \\sum_{\\ell=1}^{L}\\left|\\boldsymbol{W}^{\\ell}\\right|_{F}^{2} $$  異常度の算出 $$ s(\\boldsymbol{x})=\\left|\\phi\\left(\\boldsymbol{x} ; \\mathcal{W}^{*}\\right)-\\boldsymbol{c}\\right|^{2} $$\nProperties  weightを0初期化しない  $\\boldsymbol{c}$は初期化したNNの出力の平均ベクトルとする   biasを用いない bounded function （有界関数）を活性化関数に使わない  relu族を使おう   $nu$はoutlierの割合の上限とする  4. どうやって有効だと検証した？  Cifar10，MNISTで実験 OCSVMに勝るのはもちろん，DCAEやAnoGANより高精度  同クラス内でもnormal / anomalousなsampleが検出できている   5. 議論はあるか？  MNISTやCifarはNovelty Detectionの成分が強い気がする  外観検査とかで使えるかは検証しないとわからん 傷があるとか局所的に異常とか   ミニバッチの大きさはどのくらい精度に影響する？  6. 次に読むべき論文はある？  Chalapathy, R., Menon, A. K., \u0026amp; Chawla, S. (2018). Anomaly Detection using One-Class Neural Networks. Retrieved from http://arxiv.org/abs/1802.06360  ","date":1581811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581811200,"objectID":"1138a5ea742f15cc14d17a6e61d94fc8","permalink":"https://salty-vanilla.github.io/portfolio/post/deep_svdd/","publishdate":"2020-02-16T00:00:00Z","relpermalink":"/portfolio/post/deep_svdd/","section":"post","summary":"1. どんなもの？ One-Class SVM (OCSVM)の非線形カーネルをNNで置き換えたモデル anomaly detectionの枠組みとして，soft-boundary と one-class Deep","tags":null,"title":"Deep One-Class Classification","type":"post"},{"authors":null,"categories":["Semi-supervised Learning"],"content":"1. どんなもの？  Pseudo labelとConsistency regularizationを組み合わせたSemi-supervised learning (SSL) 非常に単純な枠組みだが，Cifar10を40labels だけでerror率：11.39を達成  2. 先行研究と比べてどこがすごい？  Pseudo labelとConsistency regularizationの組み合わせでSSLのSOTA  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Pseudo labelとConsistency regularizationの組み合わせ 変数の定義  $x_b$ : labeled training exmaple $p_b$ : one-hot label $\\mathbb{X} = { (x_b, p_b): b \\in (1, \\cdots, B) }$ : labelありデータの集合 $u_b$: unlabeled training exmaple $\\mathbb{U} = {(u_b): b \\in (1, \\cdots, \\mu B)}$ : labelなしデータの集合 $H(p, q)$ : $p$, $q$のcrossentropy    Consistency regularization  loss関数は確率的なaugmentation $\\alpha$と$p_m$を用いて， $$ \\sum_{b=1}^{\\mu B}\\left|p_{\\mathrm{m}}\\left(y | \\alpha\\left(u_{b}\\right)\\right)-p_{\\mathrm{m}}\\left(y | \\alpha\\left(u_{b}\\right)\\right)\\right|_{2}^{2} $$ 確率的なので，↑は0にはならないことに注意  Pseudo label  $u_b$に対して，擬似的ラベル$q_b$を付与する $$ q_b = p_m(y|u_b) $$ unlabeld dataに対するloss関数は，指示関数 $\\mathbb{I}$，しきい値 $\\tau$を用いて $$ \\frac{1}{\\mu B} \\sum_{b=1}^{\\mu B} \\mathbb{I}\\left(\\max \\left(q_{b}\\right) \\geq \\tau\\right) \\mathrm{H}\\left(\\hat{q}_{b}, q_{b}\\right) $$ $$ \\hat{q}_{b} = argmax(q_b) $$  FixMatch  labeled exmapleに対してはConsistency regularization (図の上側) $\\alpha$は弱いaugmentation (e.g. filpとか軽微なshift) $$ \\ell_{s}=\\frac{1}{B} \\sum_{b=1}^{B} \\mathrm{H}\\left(p_{b}, p_{\\mathrm{m}}\\left(y | \\alpha\\left(x_{b}\\right)\\right)\\right) $$ unlabeld exampleに対してはPseudo label(図の下側) $\\mathcal{A}$は強いaugmentation (AutoAugmentベースの手法：RandAugment，CTAugment) $$ \\ell_{u}=\\frac{1}{\\mu B} \\sum_{b=1}^{\\mu B} \\mathbb{I}\\left(\\max \\left(q_{b}\\right) \\geq \\tau\\right) \\mathrm{H}\\left(\\hat{q}_{b}, p_{\\mathrm{m}}\\left(y | \\mathcal{A}\\left(u_{b}\\right)\\right)\\right) $$ $$ q_b = p_m(y | \\alpha(u_b)) $$   Additional important factors  weight decayが有効 AdamよりSGDが良い learning scheduleにはcosine learning rate decayを使う $$ \\eta \\cos (\\frac{7 \\pi K}{16K} ) $$  4. どうやって有効だと検証した？  Cifar10，Cifar100，SVHNで実験  Cifar100以外はSOTA    下の10枚（つまり1クラス1枚）だけを用いてCifar10学習しても78%のAccuracy   5. 議論はあるか？  Section 5は気が向いたら 単純な方法 + 少ラベルでこれほどの精度が出るのは驚き Goodfellow曰く革命 The quiet semisupervised revolution continues https://t.co/FAY4v9aHbe\n\u0026mdash; Ian Goodfellow (@goodfellow_ian) January 22, 2020    6. 次に読むべき論文はある？  David Berthelot, Nicholas Carlini, Ekin D. Cubuk, Alex Ku- rakin, Kihyuk Sohn, Han Zhang, and Colin Raffel. Remix- match: Semi-supervised learning with distribution matching and augmentation anchoring. In Eighth International Conference on Learning Representations, 2020. Ekin D. Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V. Le. Randaugment: Practical automated data augmen- tation with a reduced search space. arXiv preprint arXiv:1909.13719, 2019. David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raffel. Mixmatch: A holistic approach to semi-supervised learning. In Advances in Neural Information Processing Systems 32. 2019.  ","date":1580169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580169600,"objectID":"9ade4b00c27babea930d01f9ec796248","permalink":"https://salty-vanilla.github.io/portfolio/post/fixmatch/","publishdate":"2020-01-28T00:00:00Z","relpermalink":"/portfolio/post/fixmatch/","section":"post","summary":"1. どんなもの？ Pseudo labelとConsistency regularizationを組み合わせたSemi-supervised learning (SSL) 非常に単純な枠","tags":null,"title":"FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence","type":"post"},{"authors":null,"categories":["Anomaly Detection","Self-supervised Learning"],"content":"1. どんなもの？  Classification-BasedなSelf-supervised learningモデルを使った異常検知手法 幾何変換モデルを発展させた  2. 先行研究と比べてどこがすごい？  ベースはGeometric-transformation classification(GEOM) ↓2点の解決  GEOMでは，Anomalyに対しても正常度が高くなってしまうことがあった GEOMでは，画像しか対応できず1次元データに対しては適用不可だった    3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  GEOMのSoftmax + Categorical Cross Entoropyをcenter vectorをanchorとしたtripletに 幾何変換ではなく，アフィン変換（幾何ではなく，$Wx+b$）に  GEOM   GEOMでは画像$x \\in X$を幾何変換$m \\in M$で変換することで$T(x, m)$を生成\n  $T(x, m)$を入力，$m$を教師ラベルとすることで幾何変換判別モデルを学習していた (Self-supervised)\n  正常データならこの変換の判別がうまくできるし，正常データでないなら判別がうまくできないという仮定を利用して異常検知\n  尤度としては $$ P\\left(m^{\\prime} | T(x, m)\\right)=\\frac{P\\left(T(x, m) \\in X_{m^{\\prime}}\\right) P\\left(m^{\\prime}\\right)}{\\sum_{\\tilde{m}} P\\left(T(x, m) \\in X_{\\tilde{m}}\\right) P(\\tilde{m})}=\\frac{P\\left(T(x, m) \\in X_{m^{\\prime}}\\right)}{\\sum_{\\tilde{m}} P\\left(T(x, m) \\in X_{\\tilde{m}}\\right)} $$\n  問題点\n 正常データに対して高い尤度を持つことは確認できるけど，異常データに対して低い尤度を持つとは言い難い Outlier Exposureみたいに異常も教えてあげればいいけど，異常データを実際に学習に使えない場合は多い    triplet lossの導入  ↑の問題解決のために，判別モデルではなくmetric learning（距離学習系）の採用 $T(x, m)$から特徴ベクトルを抽出するモデル$f$を学習 lossにはtriplet lossを採用．anchorはそれぞれの幾何変換$m$の特徴ベクトルのcenter vector $c_m$，$s$はmargin $$ c_m = \\frac{1}{N}\\Sigma_{x \\in X}f(T(x, m)) $$  $$ L=\\sum_{i} \\max \\left(\\left|f\\left(T\\left(x_{i}, m\\right)\\right)-c_{m}\\right|^{2}+s-\\min _{m^{\\prime} \\neq m}\\left|f\\left(T\\left(x_{i}, m\\right)\\right)-c_{m^{\\prime}}\\right|^{2}, 0\\right) $$\n 正常度は $$ \\tilde{P}\\left(m^{\\prime} | T(x, m)\\right)=\\frac{e^{-\\left|f(T(x, m))-c_{m^{\\prime}}\\right|^{2}+\\epsilon}}{\\sum_{\\tilde{m}} e^{-\\left|f(T(x, m))-c_{\\tilde{m}}\\right|^{2}+M \\cdot \\epsilon}} $$  $$ \\text {Score}(x)=-\\log P(x \\in X)=-\\sum_{m} \\log \\tilde{P}\\left(T(x, m) \\in X_{m}\\right)=-\\sum_{m} \\log \\tilde{P}(m | T(x, m)) $$\ntransformation  幾何変換は画像データにしか適用できない場合がある Affine transformの適用．$W_m$, $b_m$はrandom matrix, vector $$ T(x,m) = W_m x + b_m $$ 幾何変換は↑の特殊な形といえる．つまり一般化した形 無制限のvariationの獲得 adversarial examplesから守ることができる  4. どうやって有効だと検証した？  Cifar10で実験 transformの数は8  1次元データでも実験   5. 議論はあるか？  Dirichlet weightingとは？ ICLR2020 accept  6. 次に読むべき論文はある？  Izhak Golan and Ran El-Yaniv. Deep anomaly detection using geometric transformations. In NeurIPS, 2018 Dan Hendrycks, Mantas Mazeika, and Thomas G Dietterich. Deep anomaly detection with outlier exposure. arXiv preprint arXiv:1812.04606, 2018  ","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"4429d3b3e440b96c07743e98fbd1b7ff","permalink":"https://salty-vanilla.github.io/portfolio/post/classification-based_anomaly_detection_for_general_data/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/portfolio/post/classification-based_anomaly_detection_for_general_data/","section":"post","summary":"1. どんなもの？ Classification-BasedなSelf-supervised learningモデルを使った異常検知手法 幾何変換モデ","tags":null,"title":"Classification-Based Anomaly Detection for General Data","type":"post"},{"authors":null,"categories":["Anomaly Detection","Novelty Detection","Out of Distribution Detection"],"content":"1. どんなもの？  OoD Detectionの枠組み 入力をSVD + 特異値0埋めでBlurして，low-rank projectorとなるようなNNを学習 ↑のようなNNを用いることで，target distribution specificな特徴を抽出  2. 先行研究と比べてどこがすごい？  従来のOoD Detectionの手法では，OoDなデータに対しても高い尤度を持つことが多々あった 幾何変換は使わないので，幾何的な意味を持たないDomainにも適用できそう  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  入力をSVD + 特異値0埋めでBlur low-rank projectorとなるようなNN  GENERATING BLURRED DATA  変数の定義  target distribution (training dataset): $D$ training data sample: $d \\in \\mathbb{R}^{H \\times W \\times i}$ $d$の$j$番目のチャネル画像$d_j$のnonzero singular values: $[ \\sigma_{j1}, \\sigma_{j2}, \\cdots, \\sigma_{jN_j} ]$ $d_j$のnonzero singular valuesの数: N_j   $d_j$をSVDすると $$ d_{j}=\\Sigma_{t=1}^{N_{j}} \\sigma_{j t} u_{j t} v_{j t}^{T} $$ $[ \\sigma_{j1}, \\sigma_{j2}, \\cdots, \\sigma_{jN_j} ]$ のbottom $K$個を0にして，復元するとBlurredなデータが生成される  rankが落ちるから    OOD DETECTION VIA SVD-RND  変数の定義  Predictor Network: $f$ $i$番目のbottom K: $K_i$ $i$番目のtarget network: $g_i$ (random networkで学習時に一切更新されない) $i$の個数: $b_{train}$   $b_{train} = 1$のときのモデル構造  Objective $$ f^{*}=\\arg \\min _ {f}\\left[\\Sigma_{x \\in D_{\\text {train }}}\\left|f(x)-g_{0}(x)\\right| _ {2}^{2}+\\Sigma_{i=1}^{b_{\\text {train }}} \\Sigma_{x \\in D_{K_{i}}}\\left|f(x)-g_{i}(x)\\right|_{2}^{2}\\right] $$ $f(x)$を$g_i(x)$に近づけることで，$f$がlow-rank projectorになることを期待 $f$がtarget distribution specificな特徴を獲得する 推論時にはscoreとして下を用いる $$ \\left|f(x)-g_{0}(x)\\right|_2^2 $$ VQ-VAEやRNDではtarget distribution specificな特徴を獲得できていないため，blurred dataでも高い尤度を持つ   4. どうやって有効だと検証した？  Cifar-10, TinyImageNet, LSUN, CelebAで実験 Cifar-10がtargetなら，他はOoDといったようにして実験  $fpr@tpr=0.95$で評価 (異常検知でいうところの5%見逃し許容したときの過検出率)  SVD-RNDは学習枚数が少なくても精度が優秀   5. 議論はあるか？  5章で更に検証してるけど，詳細は気が向いたら $K_1=28$とかは記述あるけど，$K_2$は29とかでいいんだろうか？ ICLR2020 accept  6. 次に読むべき論文はある？  Burda, Y., Edwards, H., Storkey, A., \u0026amp; Klimov, O. (2018). Exploration by Random Network Distillation. Retrieved from https://arxiv.org/abs/1810.12894  ","date":1579564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579564800,"objectID":"7b615c098bfafac7df75b5f63005387c","permalink":"https://salty-vanilla.github.io/portfolio/post/svdrnd/","publishdate":"2020-01-21T00:00:00Z","relpermalink":"/portfolio/post/svdrnd/","section":"post","summary":"1. どんなもの？ OoD Detectionの枠組み 入力をSVD + 特異値0埋めでBlurして，low-rank projectorとなるようなNNを学習","tags":null,"title":"Novelty Detection Via Blurring","type":"post"},{"authors":null,"categories":["Continual Learning","Flow Based"],"content":"1. どんなもの？  継続学習の枠組み 1クラスごとに，NICEを学習することで追加クラスに対応  2. 先行研究と比べてどこがすごい？  1クラスごとに学習するので，学習済みのデータは消しても良い クラス数の追加は好きなだけできる catastrophic forgetting を回避  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  クラスごとにNICEを学習することで，OoD問題に持っていく  NICE  invertibleな生成モデル 潜在変数を仮定し，尤度最大化  OvA-INN では標準正規分布を仮定 最大化する対数尤度は下式 $$ l_{i}(x)=\\sum_{d} \\log \\left( p_{d} \\left(f_{i, d}(x)\\right)\\right)=-\\sum_{d} \\frac{1}{2} f_{i, d}(x)^{2}+\\sum_{d} \\log \\left(\\frac{1}{\\sqrt{2 \\pi}}\\right)=-\\frac{1}{2}\\left|f_{i}(x)\\right|_{2}^{2}+\\beta $$    OvA-INN (One vs All - Invertible Neural Networks)  任意のクラス数分のNICEを用意して，それぞれ最適化 クラスそれぞれにNICEがあるので，forgetするわけはない クラス数が増えてもincremental に学習ができる $i$番目のクラスのNICE $f_i$のNLL $$ \\mathcal{L}(\\mathcal{X} _ i)= \\frac{1}{| \\mathcal{X} _ i |} \\sum_{x \\in \\mathcal{X} _ i} |f_{i}(x)|_{2}^{2} $$ OvA-INN の最終的な推論のラベルは $$ y^{*}=\\underset{y=1, \\ldots, t}{\\arg \\min }\\left|f_{y}(x)\\right|_{2}^{2} $$  4. どうやって有効だと検証した？ MNIST  MNISTをincremental に学習させて，Acc算出 従来手法よりも優秀   CIFAR100  クラス数が増えても，精度があまり落ちない   5. 議論はあるか？  クラス数分だけ，NICEがあるならforgetしないのは当たり前では？ Flow based model がOoD 検出には使えないかも？という問題には全く触れていない[1] ICLR2020 reject  6. 次に読むべき論文はある？  Choi, H., Jang, E., \u0026amp; Alemi, A. A. (2018). WAIC, but Why? Generative Ensembles for Robust Anomaly Detection. Retrieved from http://arxiv.org/abs/1810.01392  ","date":1579478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579478400,"objectID":"723269bf2e51bdd83de01e46eaeed25b","permalink":"https://salty-vanilla.github.io/portfolio/post/ova-inn/","publishdate":"2020-01-20T00:00:00Z","relpermalink":"/portfolio/post/ova-inn/","section":"post","summary":"1. どんなもの？ 継続学習の枠組み 1クラスごとに，NICEを学習することで追加クラスに対応 2. 先行研究と比べてどこがすごい？ 1クラスごとに学習する","tags":null,"title":"OvA-INN: Continual Learning with Invertible Neural Networks","type":"post"},{"authors":null,"categories":["Representation Learning"],"content":"1. どんなもの？  表現学習の枠組み Denoising Autoencoderをベースにより良い特徴表現を獲得 具体的には，入力データにノイズを付加するのではなくLaplacian Pyramidのrandom level目でノイズを付加する   2. 先行研究と比べてどこがすごい？  通常のDAEより優れた特徴表現の獲得 他の表現学習とは異なり，domain assumptionやpseudo labelを必要としない  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  入力データにノイズを付加するのではなく，Laplacian Pyramidのlevel $l$層目でノイズを付加する $l$層目のLaplacian Pyramid $x_l^L$ は，$l$層目のGaussian Pyramid $x_l^G$ を用いて下式 $$ x_l^L = x_l^G - upsample(x_{l+1}^G) $$ $x_0^G$ は元画像に等しい．上式の $l$ を 0 に向かって繰り返し計算すると元画像が求められる $$ x_l^G = x_l^L + upsample(x_{l+1}^G) $$ この繰り返しの途中でノイズを付加する   algorithmは以下  $c \\in C$ はどんなノイズを付加するかのセットと要素 objectiveは通常のMSE     4. どうやって有効だと検証した？ MNIST  通常のDAEと比較して，input space, laplacian spaceどちらのnoiseに対しても正確に復元できていることがわかる 再構成Lossも低い   CIFAR10  再構成，画像検索共に通常のDAEより高精度   Imagenet  Supervised learningと同じようなconv filterが学習できている  conv層後の特徴を線形分類したときの精度比較．  LapDAEとAET-project[1]を組み合わせた LapDAE + Transが最高精度    Pascal VOCに転移学習しても最高精度   5. 議論はあるか？  単純な方法でより良い特徴表現の獲得に成功している objectiveはMSEのままなのに，blurが軽減されているのはなぜ？ Gaussian pyramidを作る際にGaussian filterはかけてる？  6. 次に読むべき論文はある？  Zhang, L., Qi, G.-J., Wang, L., \u0026amp; Luo, J. (2019). AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations rather than Data. Retrieved from http://arxiv.org/abs/1901.04596  ","date":1579305600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579305600,"objectID":"20e60eb245d5a34503e17b8a28d01577","permalink":"https://salty-vanilla.github.io/portfolio/post/lapdae/","publishdate":"2020-01-18T00:00:00Z","relpermalink":"/portfolio/post/lapdae/","section":"post","summary":"1. どんなもの？ 表現学習の枠組み Denoising Autoencoderをベースにより良い特徴表現を獲得 具体的には，入力データにノイズを付加するのではなくLa","tags":null,"title":"Laplacian Denoising Autoencoder","type":"post"},{"authors":null,"categories":["GAN"],"content":"1. どんなもの？  StyleGANのver2 StyleGANの問題の問題を改善 FIDの向上に加えて，PPL: Perceptual Path Lengthも向上  2. 先行研究と比べてどこがすごい？  StyleGANの問題であった水滴状のノイズ，潜在変数を走査しても顔のパーツが自然に変化しないなどの問題を改善 Instance Normの見直し，Progressive Growingの見直し，PPLの導入  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Revisit Instance Norm  StyleGANでは雨粒状のノイズ (artifact)が現れていた 原因はAdaINの演算    NVIDIAの動画がわかりやすい     この原因は Instance Norm にあり\n INは各feature mapの平均と分散で正規化 絶対値が小さくてもスパイク状の分布のfeature mapがあるとartifactが出てしまう INを無くせば，artifactが出ないらしい    a. StyleGAN\nb. StyleGANの詳細\nc. INのartifactを考慮した形\n A(mapping networkの出力$f(z)$)，conv後のstdのみを使うように変更 B(noise image)のaddはBlockの外に出した  d. (c)のoperationをweight demodulationで簡易化\n AのAdaINではAのstdで割り算していた これをfeature mapに対して割り算するのではなく，convのweightに対して割り算することで等価の演算に $s$はAをaffineして得られたスケールベクトル，$w \\in \\mathbb{R} ^{{ch_{in}} \\times {ch_{out}} \\times {hw}}$はconvのweight $$ w_{ijk}^{\\prime} = s_i \\cdot w_{ijk} $$ $$ w_{ijk}^{\\prime\\prime} = \\frac{w_{ijk}^{\\prime}}{\\sqrt{\\Sigma_{i,k}{{w_{ijk}^{\\prime}}^2 + \\epsilon}}} $$ 入力が標準偏差1のrandom variableであることを仮定している．これは$\\sigma$割っていることと同義 $$ \\sigma_j = \\sqrt{\\Sigma_{i,k}{{w_{ijk}^{\\prime}}^2}} $$  Image quality and generator smoothness While Perceptual Path Length  潜在空間のPerceptual Path Length: PPLが小さい ⇔ 生成のQuality高い PPLを正則化項として追加する $$ \\mathbb{E}_{w,y \\sim N(0,\\mathbf{I})} ( ||\\mathbf{J_w^T y}|| - a)^2 $$ $$ \\mathbf{J_w^T y} = \\nabla_w(g(w) \\cdot y) $$   Lazy Reguralization  loss関数は，logistic lossと$R_1$[1] $R_1$は毎ミニバッチごとに算出しなくても，16ミニバッチごとくらいでいいよということ それがlazy  Revisiting Progressive Growing   StyleGANでは，顔のパーツが潜在変数の変化に追従しないという問題あり\n 画像では，顔の向きが変わっているのに口が変わっていない     これは，StyleGANのProgressive Growing構造によるもの\n 各resolutionのGを段階的に学習することで，Gのレイヤは高周波成分を出力するように その結果，GがShift invarianceを失ってしまう    代替の構造として以下の(b),(c)を使う\n Generatorは(b) Discriminatorは(c)    4. どうやって有効だと検証した？   全工夫の有効性は   weight demodulationの有効性は以下\n artifactが消えたのがわかる     PPLの有効性は以下\n PPLが小さくなっている     PGに替わる構造の有効性は以下\n GとDにskipとresidualを選んだのはこの表から     生成は以下   5. 議論はあるか？  PG構造なくしたのはGood．非常に簡潔になった AdaINによるartifactへの対処としてのweight modulationも簡潔 しかし，依然として学習時間はDGX-1で13days  6. 次に読むべき論文はある？  Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for GANs do actually converge? CoRR, abs/1801.04406, 2018. 5, 10 Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proc. CVPR, 2018. 1, 2, 4, 10, 12, 16 Animesh Karnewar, Oliver Wang, and Raghu Sesha Iyengar. MSG-GAN: multi-scale gradient GAN for stable image syn- thesis. CoRR, abs/1903.06048, 2019. 6  ","date":1577664000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577664000,"objectID":"aae105df73d88d47c774b8b0e940e650","permalink":"https://salty-vanilla.github.io/portfolio/post/stylegan2/","publishdate":"2019-12-30T00:00:00Z","relpermalink":"/portfolio/post/stylegan2/","section":"post","summary":"1. どんなもの？ StyleGANのver2 StyleGANの問題の問題を改善 FIDの向上に加えて，PPL: Perceptual Path Lengthも向上 2. 先行研究と比","tags":null,"title":"Analyzing and Improving the Image Quality of StyleGAN","type":"post"},{"authors":null,"categories":["Time Series"],"content":"1. どんなもの？  音の生波形から，eventのclassificationを行う raw waveformを1D CNNで周波数解析し，得られたTransformed Imageを2D CNNで識別 training dataが少ない場合でも有効なMix-trainingを提案  2. 先行研究と比べてどこがすごい？  Audio ClassificationはGoogleのBottleneck featureを使った識別，Handcrafted featureを使った識別がBaselineだった Bottleneckは情報のlostが，Handcraftedは抽出の困難さが問題 end-to-endな周波数特徴の抽出，識別を可能に  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  キモは，周波数特徴を抽出する1D CNNとその特徴を識別する2D CNN  Raw-waveforms-based network 1D CNN  1D CNNで時間方向にdownsamplingをかけることで，周波数特徴を抽出 FFTをNNに任せてるイメージで，識別に適した周波数特徴を抽出してくれることを期待 最終的には，$C \\times 1 \\times T$ (channel, 1, time)のfeature mapをtransposeして，$1 \\times C \\times T$ (1, channel, time)の画像に  2D CNN  得られた周波数特徴画像を2D Convolution 勾配消失を防ぐため，multi-resolutionalなfeature mapからpredictionを出力 attentionつき（attentionは多分，以下の構造）   Avg Poolは多分GAP．．．？  Mix-training strategy  training dataが少ない場合に有効なMix-training．pretraining的な扱い 2つの入力を$\\alpha \\in (0, 1)$でblend  $$ \\tilde{x}_k = \\alpha x_i + (1-\\alpha) x_j $$\n $\\tilde{x}_k$に対応する教師ラベルは以下（$y_i$,$y_j$はmulti-hot label)  $$ \\tilde{y}_k = sign(y_i + y_j) $$\n loss関数は  $$ L=-\\frac{1}{K} \\sum_{k, n} \\left(1-\\tilde{y}_{k n}\\right) \\log \\left(1-t_{k n}\\right)+\\tilde{y}_{k n} \\log t_{k n} $$\n$$ \\mathbf{t_k} = f_\\theta (\\tilde{x}_k) = [ t_{k1}, t_{k2}, \u0026hellip;, t_{kN} ] $$\n Mix-trainingが終わった後にはmixしないデータでfine-tuning  4. どうやって有効だと検証した？  Audio SetでBaselineとの精度比較 精度的には負けてるが，pretrainingなしなのはgoodかも   mix-trainingの有効性確認も mix-upよりも高精度  5. 議論はあるか？  周波数特徴画像にFFTのような説明性はあるか？ mix-trainingの教師データの総和が1にならないが良いのか．．． stemのConv 1x7は妥当か？  6. 次に読むべき論文はある？  Yu, C., Barsim, K. S., Kong, Q., \u0026amp; Yang, B. (2018). Multi-level Attention Model for Weakly Supervised Audio Classification. Retrieved from http://arxiv.org/abs/1803.02353 Zhang, H., Cisse, M., Dauphin, Y. N., \u0026amp; Lopez-Paz, D. (2017). mixup: Beyond Empirical Risk Minimization. Retrieved from https://arxiv.org/abs/1710.09412  ","date":1577059200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577059200,"objectID":"06e15f630c9d2aa98227d3509e99fcb6","permalink":"https://salty-vanilla.github.io/portfolio/post/an_end-to-end_audio_classification_system_based_on_raw_waveforms_and_mix-training_strategy/","publishdate":"2019-12-23T00:00:00Z","relpermalink":"/portfolio/post/an_end-to-end_audio_classification_system_based_on_raw_waveforms_and_mix-training_strategy/","section":"post","summary":"1. どんなもの？ 音の生波形から，eventのclassificationを行う raw waveformを1D CNNで周波数解析し，得られたTrans","tags":null,"title":"An End-to-End Audio Classification System based on Raw Waveforms and Mix-Training Strategy","type":"post"},{"authors":null,"categories":["Normalization"],"content":"1. どんなもの？  pixelごとにチャネル方向に串刺しにして正規化する系の正規化手法 Encoder-Decoder構造（Domain transferなど）に適用すると良い生成  2. 先行研究と比べてどこがすごい？  BN，LN，INなどとは違って，空間解像度を保った正規化なのでstructuralな情報が残せる もちろん収束は早くなるし，安定もする  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Positional Normalization  feature mapの各Pixel（position)ごとにチャネル方向にstaticsを求める つまり，staticsのshapeは（b, h, w)  $$ \\mu_{b, h, w}=\\frac{1}{C} \\sum_{c=1}^{C} X_{b, c, h, w}, \\quad \\sigma_{b, h, w}=\\sqrt{\\frac{1}{C} \\sum_{c=1}^{C}\\left(X_{b, c, h, w}^{2}-\\mu_{b, h, w}\\right)+\\epsilon} $$\n$$ X_{b, c, h, w}^{\\prime}=\\gamma\\left(\\frac{X_{b, c, h, w}-\\mu}{\\sigma}\\right)+\\beta $$\n VGGにponoを差し込んでみると，画像の構造をstaticsが捉えているように見える  ただDenseNetでは，map端に望まない反応が見られる   Moment Shortcut  Encoder-Decoder構造において，Encoderのponoで得られたstd $\\sigma$を$\\gamma$，mean $\\mu$を$\\beta$として $$ x\u0026rsquo; = \\gamma x + \\beta $$ CycleGANやPix2Pixで有効 $\\mu$,$\\sigma$に対して，convして，$\\beta,\\gamma \\in \\mathbb{R}^{B \\times H \\times W \\times C}$にしてからAffineするDynamic Moment Shortcutも提案  4. どうやって有効だと検証した？  Domain transfer (Map \u0026lt;-\u0026gt; Photo, Horse \u0026lt;-\u0026gt; Zebra)で実験 CycleGAN (baseline)を上回るのはもちろん，SPADEにも勝っている parameter数も少ない  5. 議論はあるか？  情報量的には軽量版Unetと感じた Unetはパラメータ数，計算量も格段に多くなるのでGood MUNITはlatent spaceにたどり着かないかもしれない情報がでるけど，大丈夫なのか  6. 次に読むべき論文はある？ ","date":1576540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576540800,"objectID":"80400532f5ef19e07cb1962865a07008","permalink":"https://salty-vanilla.github.io/portfolio/post/pono/","publishdate":"2019-12-17T00:00:00Z","relpermalink":"/portfolio/post/pono/","section":"post","summary":"1. どんなもの？ pixelごとにチャネル方向に串刺しにして正規化する系の正規化手法 Encoder-Decoder構造（Domain transf","tags":null,"title":"POSITIONAL NORMALIZATION","type":"post"},{"authors":null,"categories":["GAN"],"content":"1. どんなもの？  GANのIS，FIDを向上させる系の論文 BigGANベースに大きなアーキテクチャの変更なしに高精度な生成．  2. 先行研究と比べてどこがすごい？  ベースはBigGAN 潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新することでhigh qualityとdiversityを実現  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  キモは，潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新すること  Latent Optimisation  潜在変数をDiscriminatorが騙されやすいように更新した後，パラメータを更新する $$ \\Delta z = \\alpha \\frac{\\partial f(z)}{\\partial z} $$ $$ z\u0026rsquo; = z + \\Delta z $$ ここで，f(z)は$z$をGeneratorに入力し得られたデータをDiscriminatorに与えることで得られる出力  Natural Gradient Descent  更新する$z$の空間はユークリッド空間でないことが多い． 通常の勾配法ではうまく更新できないことがある． 自然勾配法を用いて$z$を更新する．  $$ \\Delta z = \\alpha F^{-1} \\frac{\\partial f(z)}{\\partial z} = \\alpha F^{-1}g $$\n ここで，$F$はフィッシャー情報行列 $F$の算出はcost大なので，近似すると($\\beta$はハイパラの定数)  $$ F\u0026rsquo; = g \\cdot g^T + \\beta I $$\n$$ \\Delta z=\\alpha\\left(\\frac{I}{\\beta}-\\frac{g g^{T}}{\\beta^{2}+\\beta g^{T} g}\\right) g=\\frac{\\alpha}{\\beta}\\left(1-\\frac{|g|^{2}}{\\beta+|g|^{2}}\\right) g $$\n4. どうやって有効だと検証した？ Imagenetの生成で実験． baseline(a)よりLOGAN(b)の方がdiversityのある生成ができている． 5. 議論はあるか？  $z$を更新するだけでここまで精度が上がるのは驚き ただ，baselineがBigGANなので庶民には手が出せない dynamicの話とかappendixについては，まだ見れてない  6. 次に読むべき論文はある？ ","date":1575936000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575936000,"objectID":"c40cd8a18661325b199914c865982a3a","permalink":"https://salty-vanilla.github.io/portfolio/post/logan/","publishdate":"2019-12-10T00:00:00Z","relpermalink":"/portfolio/post/logan/","section":"post","summary":"1. どんなもの？ GANのIS，FIDを向上させる系の論文 BigGANベースに大きなアーキテクチャの変更なしに高精度な生成． 2. 先行研究と比べてど","tags":null,"title":"LOGAN: Latent Optimisation for Generative Adversarial Networks","type":"post"},{"authors":null,"categories":["Anomaly Detection"],"content":"1. どんなもの？  Autoencoder（差分ベース）の異常検知モデル 潜在変数にMemory構造を導入することで正常データ以外も復元できてしまう”汎化”を防ぐ  2. 先行研究と比べてどこがすごい？  Autoencoderを使った異常検知では，モデルが汎化してしまい異常データまでも復元できてしまう問題があった 潜在変数にMemory構造を追加することで，正常データの分布内のデータしか復元できないようにした  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？  Memory構造がキモ  全体の流れ  Encoderからまず$z$を得る $$ z = f_e(x; \\theta_e) $$ メモリ構造を用いて$\\hat{z}$を得る（後述） Decoderで$\\hat{z}$から復元する  $$ \\hat{x} = f_d(\\hat{z}; \\theta_d) $$\nMemory   それぞれ変数を定義する\n $M \\in \\mathbb{R}^{N \\times C}$: Memory行列 $m_i$: $M$の$i$行目Vector $N$: メモリ数 $C$: $\\hat{z}$の次元数（論文内では$z$の次元数と一致） $w \\in \\mathbb{R}^{1 \\times N} $: Attention Weight Vector    Encoderから得られた$z$と$m_i$の距離（内積）を算出して，softmaxすることで$w$を求める $$ w_i = \\frac{\\exp(d(z, m_i))}{\\Sigma^N_{j=1}\\exp(d(z, m_j))} $$\n  $$ d(z, m_i) = \\frac{zm_i^T}{|z||m_i|} $$\n $\\hat{z}$を求める $$ \\hat{z} = wM = \\Sigma^N_{i=1}w_im_i $$  Hard Shrinkage for Sparse Addressing 上述のMemory構造でも復元できてしまう異常サンプルは出てくるので，$w$をスパースにすることでより制限する\n\\[ \\hat{w}_i = \\begin{cases} w_i \u0026amp; \\text{ if } w_i \u0026gt; \\lambda \\\\ 0 \u0026amp; \\text{ otherwise } \\end{cases} \\]\nObjective 再構成誤差と$\\hat{w}$そスパースにするための誤差の重み付き和 $$ L(\\theta_e, \\theta_d, M) = \\frac{1}{T} \\Sigma^T_{t=1}[R(x^t, \\hat{x}^t) + \\alpha E(\\hat{w}^t)] $$\n$$ R(x^t, \\hat{x}^t) = |x^t - \\hat{x}^t| ^2 $$\n$$ E(\\hat{w}^t) = \\Sigma^T_{i=1}-\\hat{w}^t\\log{\\hat{w}^t} $$\n論文内では,$\\alpha = 0.0002$\n4. どうやって有効だと検証した？ 画像では，MNIST・Cifar10で実験 動画では，UCSD-Ped2・CUHK・ShanghaiTechで実験 5. 議論はあるか？  汎化にスポット当てた論文でgood MVTec で実験してみたい  6. 次に読むべき論文はある？ ","date":1575936000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575936000,"objectID":"8897429e0892f9f34304db2a3f79d713","permalink":"https://salty-vanilla.github.io/portfolio/post/memorizing_normality_to_detect_anomaly_memory-augmented_deep_autoencoder_for_unsupervised_anomaly_detection/","publishdate":"2019-12-10T00:00:00Z","relpermalink":"/portfolio/post/memorizing_normality_to_detect_anomaly_memory-augmented_deep_autoencoder_for_unsupervised_anomaly_detection/","section":"post","summary":"1. どんなもの？ Autoencoder（差分ベース）の異常検知モデル 潜在変数にMemory構造を導入することで正常データ以外も復元できてしまう","tags":null,"title":"Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection","type":"post"},{"authors":null,"categories":["Anomaly Detection","VAE"],"content":"1. どんなもの？ Autoencoderベースの異常検知手法．Autoencoderの問題である画像内の一部の異常が画像全体の復元に影響を与えてしまい上手く異常部位をLocalicationできないという問題にタックル．\n2. 先行研究と比べてどこがすごい？  Autoencoderベースのモデルでは，異常画像が入力された際に異常部位以外も再構成が崩れてしまい上手くLocalizationできないという問題があった また，Blurが発生してしまう 上記2点を繰り返し，$x$を更新していく方法で解決する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？   エネルギー関数は，再構成誤差($L_r$)と正則化項（更新しても原画像から離れすぎないようにする正則化） $$ E(x_t) = L_r(x_t) + \\lambda|| x_t - x_0 || $$ $$ L_r(x_t) = \\mathbb{E} [ | f_{VAE}(x_t) - x_t | ^r ] $$\n  エネルギー関数を最小化するように，入力画像$x_0$を更新していく $$ x_{t+1} = x_t - \\alpha \\nabla_x E(x_t) $$\n  再構成が大きい部位は更新量を大きく，小さい部位は小さくすればなお良し $$ x_{x+1} = x_t - \\alpha ( \\nabla_xE(x_t) \\odot | f_{VAE}(x_t) - x_t | ^2 ) $$\n  つまるところ，学習済みのVAEを用意して，テストデータを繰り返し入力・更新して元のManifoldにより近づけるイメージ （近いモデルはAnoGAN）\n  4. どうやって有効だと検証した？   MVTECに対して，実験\n  それぞれ ***-gradが提案手法   通常のAutoencoderより，適切に異常部位のLocalizationができていることを確認   5. 議論はあるか？  iterativeにすることで推論時間はどのくらいになる？ AnoGANと似たようなmethodだが，比較は？  6. 次に読むべき論文はある？  Bin Dai and David P. Wipf. Diagnosing and enhancing VAE models. CoRR, abs/1903.05789, 2019. Ian  ","date":1575849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575849600,"objectID":"2c63b045ec3d2c60a3dba4a7d4959a99","permalink":"https://salty-vanilla.github.io/portfolio/post/iterative_energy-based_projection_on_a_normal_data_manifold_for_anomaly_localization/","publishdate":"2019-12-09T00:00:00Z","relpermalink":"/portfolio/post/iterative_energy-based_projection_on_a_normal_data_manifold_for_anomaly_localization/","section":"post","summary":"1. どんなもの？ Autoencoderベースの異常検知手法．Autoencoderの問題である画像内の一部の異常が画像全体の復元に影響を与えて","tags":null,"title":"Iterative energy-based projection on a normal data manifold for anomaly localization","type":"post"},{"authors":null,"categories":null,"content":"   はじめに 工業製品の製造工程において，出荷製品の品質安定化のために検査は必要不可欠である． とくに外観検査工程では人による目視検査が主であるが，検査員毎の判断基準のばらつきが長年の課題であった． 近年では深層学習技術の進歩により，これまで困難とされてきた目視検査工程でも自動化が検討されている． 従来の深層学習では正常品と異常品を識別するために大量のサンプルが必要であるが，現実には大量の異常品を確保することは困難である． そのため，正常品のみ，もしくは正常品と少数の異常品から良否識別できる枠組みが求められている． また，画像検査においては，1枚の異常画像の中に正常な領域と異常な領域が混在していることがある． このとき，異常な領域が占める割合が大きければ，検出は容易であるが，小さい場合は難しい． また，異常には様々な種類が存在し，それぞれを検出するのに適した解像度が存在するはずである． そのため，本稿ではComplementary GANに Multi-scale Patch の枠組みを加えたモデルに正常品のみを学習させ，正常分布とその補集合分布をモデリングし異常検知を行う手法を提案する．\n従来のNNを使った異常検知 差分ベース  Autoencoder AnoGAN ADGAN  メリット  差分ベースなので，欠陥箇所のLocalizationが可能 学習が容易  デメリット  外観検査においては差分の出づらい欠陥が存在する Blurが発生し，高周波成分が差分として現れてしまう    潜在変数ベース  Flow-based Model Adversarial Autoencoder  メリット  異常度を対数尤度としてダイレクトに算出できる 潜在変数による低次元データの可視化が可能  デメリット  欠陥情報が消失してしまう Out of distributionのデータでも尤度が高くなってしまうことがある．    Complementary GAN そもそもGANとは？  GeneratorとDiscriminatorの2つのNetworkを持つ Generatorは，Discriminatorを騙すように本物に近いデータを生成する Discriminatorは，入力が本物のデータなのか・Generatorによって生成された偽のデータなのかを識別する GeneratorとDiscriminatorが↑の学習をすることで，Generatorは本物に近いデータを生成できるようになる．  結局GANは何を学習している？  Discriminatorは生成分布とデータ分布の”離れ度合い”を測るDivergence Estimator Generatorは算出された”離れ度合い”を最小化する その結果，生成分布とデータ分布が近づいていき，本物に近い画像が生成できる  Discriminatorの出力って異常検知に使える？  Discriminatorは，本物と偽物が見極められるので，本物を正常データとすれば，正常/異常が分別できるのでは！？という考え それは難しい Discriminatorが識別しているのは，本物のデータであるか偽物のデータであって，偽物データの中に異常分布の要素は全く含まれていない  GANとComplementary GANの違いは？  GANはデータ分布と生成分布を測り，近づける Complementary GANはデータ分布と生成分布を測り，データ分布の補集合分布と生成分布を近づける つまり，Complementary GANは正常データには存在しないデータを生成し，Discriminatorは正常と正常ではないの識別境界となる  Multi-scale Patch Discriminator  外観検査では，欠陥の大きさは様々 CNNで，Conv + Poolingを積み重ねていくと小さい欠陥の情報は消えてしまう かといって，浅すぎるCNNでは識別はできない  そこで，Discriminatorの出力を[0, 1]のスカラーではなく，正常度MAPとすることで↑の問題に対処する\n実験 LEDチップ画像 サンプル データ内訳     良品 不良品     training 70000 0   test 10000 204    生成された補集合画像  不良品画像とは一致しないが，良品画像には近いが良品ではないものが生成できていることを確認    Discriminatorによる異常度MAP  赤に近いほど異常度が大きく，青に近いほど異常度が低い 各行左から，入力・8x8 MAP・4x4 MAP・2x2 MAP 8x8 MAPでは小さい欠陥が，2x2 MAPでは面積の大きい欠陥が検出される    精度   Reference  Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … Bengio, Y. (2014). Generative Adversarial Nets. Advances in Neural Information Processing Systems, 2672–2680. Zheng, P., Yuan, S., Wu, X., Li, J., \u0026amp; Lu, A. (2018). One-Class Adversarial Nets for Fraud Detection. ArXiv Preprint ArXiv:1803.01798. Bergmann, P., Fauser, M., Sattlegger, D., \u0026amp; Steger, C. (2019). MVTec AD \u0026ndash; A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Karras, T., Laine, S., \u0026amp; Aila, T. (2018). A Style-Based Generator Architecture for Generative Adversarial Networks. Retrieved from https://arxiv.org/abs/1812.04948  ","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"92ac6e90d5886054b39de0842a0ca6ac","permalink":"https://salty-vanilla.github.io/portfolio/project/visual_inspection/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/portfolio/project/visual_inspection/","section":"project","summary":"工業部品や食品の外観検査をニューラルネットワークによって自動化","tags":null,"title":"Visual Inspection","type":"project"},{"authors":null,"categories":null,"content":"1. どんなもの？ Metric Learningの論文．分類をして，各クラス内の分散を小さく，クラス間の分散を大きくする系のMetric Learining．\n2. 先行研究と比べてどこがすごい？  クラス分類モデルのSoftmaxを少し改良するだけで適用できる ArcFaceと先行研究のSpehereFace・CosFaseのLoss関数は似ていて，それを一般化している  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Architecture 全体的な流れとしては， Base Block（VGGとかResNetとか）から特徴ベクトルを出力\n\\[ x' = f(x) \\]\n出力された特徴ベクトルをL2正則化\n\\[ x'' = \\frac{x'}{|x'|^2} \\]\n全結合層の重みをL2正則化\n\\[ w' = \\frac{w}{|w|^2} \\]\n正則化された特徴ベクトルと重みを内積（これがcosの値）\n\\[ cos\\theta = x'' \\cdot w' \\]\nこれにAdditive Angular Margin Penaltyを適用する．\nAdditive Angular Margin Penalty Additive Angular Margin Penaltyは正解ラベルに対応する出力の値に対して，Marginを加えることで，クラス内分散を小さくするような学習を行う． イメージとしては，正解ラベルにのみ厳しい罰則を与えてよりDiscriminativeにする感じ．\n正解クラス\\(j\\)の出力に対して，Marginを加算する\n\\[ \\theta_j' = \\{ \\begin{array}{ll} arccos(cos\\theta_i) + m \u0026 i=j \\\\ arccos(cos\\theta_i) \u0026 otherwise \\end{array} \\]\n各要素を定数倍する（温度パラメータ）\n\\[ logit = s cos(\\theta_j') \\]\nsoftmax関数にかける\n\\[ y = softmax(logit) \\]\nこの一連の流れを組み込んだLoss関数は\n\\[ L_{3}=-\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{e^{s\\left(\\cos \\left(\\theta_{y_{i}}+m\\right)\\right)}}{e^{s\\left(\\cos \\left(\\theta_{y_{i}}+m\\right)\\right)}+\\sum_{j=1, j \\neq y_{i}}^{n} e^{s \\cos \\theta_{j}}} \\]\nArcFace・SpehereFace・CosFase の一般化 \\(m_1\\)がSpehereFace，\\(m_2\\)がArcFace，\\(m_3\\)がCosFace．\n\\[ L_{4}=-\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{e^{s\\left(\\cos \\left(m_{1} \\theta_{y_{i}}+m_{2}\\right)-m_{3}\\right)}}{e^{s\\left(\\cos \\left(m_{1} \\theta_{y_{i}}+m_{2}\\right)-m_{3}\\right)}+\\sum_{j=1, j \\neq y_{i}}^{n} e^{s \\cos \\theta_{j}}} \\]\nそれぞれの識別境界の違いは下図になるらしい． 4. どうやって有効だと検証した？ 顔認識データセットであるLFW，CFP-FP，AgeDB30で実験． 比較手法がどれも精度が優秀なので，あまり有効さはわからない．\n5. 議論はあるか？  Out of dataset のサンプルが来た時にどれくらい精度がでるか？  6. 次に読むべき論文はある？  CosFace: Large Margin Cosine Loss for Deep Face Recognition https://arxiv.org/abs/1801.09414 SphereFace: Deep Hypersphere Embedding for Face Recognition https://arxiv.org/abs/1704.08063  ","date":1573948800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573948800,"objectID":"cbb19ff663abc875ed87ef1f97ea3bcf","permalink":"https://salty-vanilla.github.io/portfolio/post/arcface/","publishdate":"2019-11-17T00:00:00Z","relpermalink":"/portfolio/post/arcface/","section":"post","summary":"1. どんなもの？ Metric Learningの論文．分類をして，各クラス内の分散を小さく，クラス間の分散を大きくする系のMetric Learining．","tags":null,"title":"ArcFace: Additive Angular Margin Loss for Deep Face Recognition","type":"post"},{"authors":null,"categories":null,"content":"1. どんなもの？ 異常検知の論文．Autoencoderの出力を複数にすることでAutoencoderの異常検知の問題を解決する．\n2. 先行研究と比べてどこがすごい？  Autoencoderの入出力による異常検知では，出力がぼやけてしまい高周波成分が再構成できず正常と異常のSN比が小さいという問題があった． 後述するMultiple-Hypothesesにより高周波成分の再構成に成功．  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Multiple-Hypotheses VAEのDecoderから得られる出力を複数にする． 具体的には，$H$個のDeconv Layerを最終層に配置し，それぞれ独立のパラメータで出力させる（事後分布はGaussian）． winner-takes-all (WTA) loss 複数のDecoderの出力に対して，全ておいて再構成誤差をBack Propagationするのではなく， 最も再構成誤差が低い出力(winner)のみから再構成誤差をBack Propagationさせる．\n\\[ \\begin{aligned} L_{W T A}\\left(x_{i} | \\theta_{h}\\right) \u0026=E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{h}}\\left(x_{i} | z_{k}\\right)\\right] \\\\ \\text { s.t. } h \u0026=\\arg \\max _{j} E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{j}}\\left(x_{i} | z_{k}\\right)\\right] \\end{aligned} \\]\nDiscriminator WTA Lossでは再構成誤差をBack Propagationする出力以外については更新がされないことになってしまう． そのため，それ以外の出力についても入力の分布に近づけるようにDiscriminatorを用意する． realはもちろん入力画像で，fakeはVAEの出力（Bestとそれ以外）とランダムサンプリングされた$z$からDecoderを介して得られた出力である．\n\\[ \\begin{aligned} \\min _{D} \\max _{G} L_{D}(x, z)=\u0026\\min _{D} \\max _{G} \\underbrace{-\\log \\left(p_{D}\\left(x_{r e a l}\\right)\\right)}_{L_{real}} +L_{f a k e}(x, z) \\end{aligned} \\]\n\\[ \\begin{array}{l}{L_{\\text {fake }}(x, z)=\\log \\left(p_{D}\\left(\\hat{x}_{z \\sim \\mathcal{N}(0,1)}\\right)\\right)} {+\\log \\left(p_{D}\\left(\\hat{x}_{z \\sim \\mathcal{N}}\\left(\\mu_{\\left.z | x, \\Sigma_{z | x}\\right)}\\right)\\right)+\\log \\left(p_{D}\\left(\\hat{x}_{\\text {best-guess }}\\right)\\right)\\right.}\\end{array} \\]\nVAEのLoss関数は，\n\\[ \\min _{G} L_{G}=\\min _{G} L_{W T A}+K L\\left(q_{\\phi}(z | x) \\| \\mathcal{N}(0,1)\\right)-L_{D} \\]\n異常度の算出 WTA Lossを異常度とする． Sumしなければ，異常箇所のLocalizationに使えるのは従来のAutoencoder通り．\n4. どうやって有効だと検証した？ CIFAR10(1vs9)とMETAL ANOMALY（論文内にはリンクなし）で実験． CIFAR10でAUROC: 67.1． METAL ANOMALYでは異常度が大きいPixelの上位10%のSumを全体の異常度として算出．\n5. 議論はあるか？  Blurが解消されたのは，VAE-GAN構造にしたことによるところが大きいと思うが果たして． 高周波成分が再構成されることにより，今まで差分として出てこなかった部分もあると思う．  6. 次に読むべき論文はある？ ","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"ff3a913e37d04845f459625da0d43b59","permalink":"https://salty-vanilla.github.io/portfolio/post/anomaly_detection_with_multiple-hypotheses_predictions/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/portfolio/post/anomaly_detection_with_multiple-hypotheses_predictions/","section":"post","summary":"1. どんなもの？ 異常検知の論文．Autoencoderの出力を複数にすることでAutoencoderの異常検知の問題を解決する． 2. 先行研究と比","tags":null,"title":"Anomaly Detection With Multiple-Hypotheses Predictions","type":"post"},{"authors":null,"categories":null,"content":"1. どんなもの？ 推論時に時間がかかってしまうAnoGANを高速化する枠組み．\n2. 先行研究と比べてどこがすごい？ AnoGANでは，推論時に$z$から$x$へのmappingを行うために学習済みGANのDiscriminatorの結果と再構成誤差からLossを算出し，勾配降下法によって$z$を探索していた． つまり，推論時にも”学習”のフェーズが存在し処理時間が長かった．\nf-AnoGANでは，推論時の勾配降下による探索を無くし，推論の高速化を行った．\n3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ $z$ から$x$を推論する枠組みを3つ提案．\nziz encoder 学習済みのGANのGeneratorを用いて，$z$をGeneratorに入力し，その出力をziz encoderに入力し得られた潜在ベクトルとの再構成誤差を最小化する．\n$n$は総画素数． $$ L(z) = \\frac{1}{n}|z - E(G(z))|^2 $$\nizi encoder 学習済みのGANのGeneratorを用いて，$x$をEncoderに入力し，その出力をizi encoderに入力し得られた画像との再構成誤差を最小化する． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 $$\nizif encoder izi encoderの派生形で，izi encoderのLossと同様の再構成誤差と，Discriminatorに$x$と$G(E(x))$を入力した際の中間層の出力の再構成誤差の和を最小化する． $f(\\cdot)$はDiscriminatorの中間層の出力で，$n_d$は$f(\\cdot)$の次元数で$k$は重みパラメータ．． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n異常度の算出 $$ A(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n4. どうやって有効だと検証した？ AnoGANと同様にretinal spectral-domain optical coherence tomography (SD-OCT)をデータセットとして実験． Autoencoder，AAE，ALI，WGANのDiscriminator，iterative(AnoGAN)と比較して精度も上回った．\n5. 議論はあるか？ 追加のEncoderをつけるという簡単な手法で高速化＆高精度化を果たした点がGood． 構成的にはGANomalyに近い感じがするが，精度比較のほどは果たして？\n6. 次に読むべき論文はある？  AnoGAN https://arxiv.org/abs/1703.05921 GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training https://arxiv.org/abs/1805.06725 Adversarially Learned Inference https://arxiv.org/abs/1606.00704  ","date":1571011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571011200,"objectID":"dbf2807c36d84c7a0f8affaefadded0c","permalink":"https://salty-vanilla.github.io/portfolio/post/f-anogan/","publishdate":"2019-10-14T00:00:00Z","relpermalink":"/portfolio/post/f-anogan/","section":"post","summary":"1. どんなもの？ 推論時に時間がかかってしまうAnoGANを高速化する枠組み． 2. 先行研究と比べてどこがすごい？ AnoGANでは，推論時に$z$か","tags":null,"title":"f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks","type":"post"},{"authors":null,"categories":null,"content":"背景 手法 ","date":1556841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556841600,"objectID":"816dc8a0372121d1b0260f07e0230f4d","permalink":"https://salty-vanilla.github.io/portfolio/project/wlid_life/","publishdate":"2019-05-03T00:00:00Z","relpermalink":"/portfolio/project/wlid_life/","section":"project","summary":"大量のカメラトラップ画像から野生動物が何頭いるかを自動判定","tags":null,"title":"Wild Life","type":"project"},{"authors":null,"categories":null,"content":"1. どんなもの？ Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を向上させる．\n2. 先行研究と比べてどこがすごい？  Saliency Mapを用いることで有効な領域の情報を重視し，無関係な情報を抑制する Local feature vector (CNNの中間層の出力)とGlobal feature vector (CNNの後段のFCの出力)を組み合わせる 適合度によって重要なLocal feature vectorだけを分類に活用する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 学習可能なAttention Estimatorを通常のCNNに付け加えるだけで，Attention Mapによる解釈性，精度の向上．\n  $S$個のAttention Moduleを↑のようにCNNに加える．$s$個目のAttention Moduleは，長さ$M$のベクトル$N$個からなる集合である．\n  $s$個目のlocal feature vectorは $$ \\mathbf{L^s} = { \\mathbf{l_1^s}, \\mathbf{l_2^s}, \u0026hellip;, \\mathbf{l_N^s} } $$ ここで，ベクトルの長さ$M$はFeature Mapのチャネル数に等しく，ベクトルの個数$N$はFeature Mapの画素数に等しい．\n  全結合層で各ベクトルの長さをglobal feature vector $\\mathbf{g}$の長さ$M'$に揃える $$ \\mathbf{\\hat{l^s_i}} = w\\cdot{\\mathbf{l_i^s}} $$\n  local feature vectorとglobal feature vectorから各画素のCompatibility scoresを求める $$ C^s(\\mathbf{\\hat{L_s}}, \\mathbf{g}) = {c_1^s, c_2^s, \u0026hellip;, c_n^s} $$ $$ c_i^s = \\mathbf{\\hat{l^s_i}} \\cdot{\\mathbf{g}} $$\n  Compatibility scoresに対して，softmaxを適用してAttention Mapを算出 $$ a_i^s = \\frac{exp(c_i^s)}{\\sum_j^N exp(c_j^s)} $$\n  各モジュールの出力はAttention MapとFeature Mapの内積 $$ \\mathbf{g^s} = \\sum_i^n a_i^s \\cdot{\\mathbf{l_i^s}} $$\n  最終的には，全Moduleの出力を連結することでModule全体の出力として，最後にFC層\n  $$ \\mathbf{g_a} = { \\mathbf{g_1}, \\mathbf{g_2}, \u0026hellip;, \\mathbf{g_S}} $$ $$ O = W \\cdot{\\mathbf{g_a}} $$\n4. どうやって有効だと検証した？ CIFAR10，CIFAR100，CUB200，SVHNで実験． BaselineであるVGG，VGG+GAP, VGG+PAN, ResNet164と比較して精度向上． 浅い層では局所的な情報を重視し，深い層では物体全体の情報を重視していることがわかる\n5. 議論はあるか？ Adversarial AttackやCross Domainな認識タスクに対しても有効であることが示されている．\n6. 次に読むべき論文はある？ ","date":1525564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525564800,"objectID":"aa74104a1b07b41903f5c46506262534","permalink":"https://salty-vanilla.github.io/portfolio/post/learn_to_pay_attention/","publishdate":"2018-05-06T00:00:00Z","relpermalink":"/portfolio/post/learn_to_pay_attention/","section":"post","summary":"1. どんなもの？ Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を","tags":null,"title":"Learn to Pay Attention","type":"post"},{"authors":null,"categories":null,"content":"国内会議  中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;CNNによる回帰分析を用いた打痕判定に関する考察\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2016, pp.204-205(2016.12.9) 中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;回帰型CNNを用いた工業製品における外観検査手法の研究\u0026rdquo;, 第22回知能メカトロニクスワークショップ, 3A1-4(2017.8.28) 神本恭佑, 中塚俊介, 相澤宏旭, 加藤邦人, 小林裕幸, 坂野和見 : \u0026ldquo;Denoising Autoencoder Generative Adversarial Networks を用いた欠損検出の検討\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.54-55(2017.12.7) 中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.148-149(2017.12.8) 安藤正規，中塚俊介，相澤宏旭，中森さつき，池田敬，森部絢嗣，寺田和憲，加藤邦人: \u0026ldquo;機械学習による自動撮影カメラ画像からの獣種自動判別技術の開発\u0026rdquo;，日本哺乳類学会2018年度大会，S2-05，(2018.9) 神本恭佑，中塚俊介，加藤邦人:\u0026ldquo;SSIMを用いたAutoEncoderによる欠陥検出の検証\u0026rdquo;,動的画像処理実利用化ワークショップ DIA2019,OS2-20, pp.346-351,(2019.3.8) 中塚俊介, 加藤邦人:\u0026ldquo;多重解像度マップを持つ補集合GANを用いた正常データのみの学習による外観検査法\u0026rdquo;，ビジョン技術の実利用ワークショップ ViEW2019, OS3-H1(IS2-C10) (2019.12.6)  国際会議  Shunsuke Nakatsuka, Kunihito Kato, Yosuke Nakanishi : \u0026ldquo;Study on Visual Inspection Method using CNN Regression\u0026rdquo;, Asia International Symposium on Mechatronics, D1-5(2017.9.15) Kyosuke Komoto, Shunsuke Nakatsuka Hiroaki, Aizawa, Kunihito Kato, Hiroyuki Kobayashi, Kazumi Banno : \u0026ldquo;A Performance Evaluation of Defect Detection by using Denoising AutoEncoder Generative Adversarial Networks\u0026rdquo;, International Workshop on Advanced Image Technology 2018, Session E2-4 (2018.1.9) Shunsuke Nakatsuka, Hiroaki Aizawa and Kunihito Kato : \u0026ldquo;A Method of Generation of Normal Model and Discrimination of Defects by Adversarial AutoEncoder under Small Number of Defective Samples\u0026rdquo;, Proceeding of 24rd International Workshop on Frontiers of Computer Vision, OS3-1,(2018.2.22) Shunsuke Nakatsuka, Hiroaki Aizawa, Kunihito Kato, “Defective Products Detection using Adversarial AutoEncoder”, International Workshop on Advanced Image Technology 2019 (IWAIT2019), (2019.1.9) Keisuke Goto, Kunihito Kato, Shunsuke Nakatsuka, Takaho Saito and Hiroaki Aizawa:\u0026ldquo;Anomaly Detection of solder joint on print circuit board by using Adversarial Autoencoder\u0026rdquo;, Proceedings of the International Conference on Quality Control by Artificial Vision 2019 (QCAV2019),AV200-84 (2019.5.16) Kimiya Murase, Shunsuke Nakatsuka, Mariko Hosoe, Kunihito Kato: \u0026ldquo;Handwriting Feature Extraction Method for Writer Verification Independent of Character Type by using AdaBN and AdaIN\u0026rdquo;, International Workshop on Advanced Image Technology 2020 (IWAIT2020), Session 1A, Paper No.90 (2020.1.6)  論文誌  中塚俊介，相澤宏旭，加藤邦人：\u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と異常検出\u0026rdquo;, 精密工学会誌, Vol.84, No.12, pp.1071-1078 (2018) 安藤正規，中塚俊介，相澤宏旭，中森さつき，池田敬，森部絢嗣，寺田和憲，加藤邦人，“深層学習（Deep Learning）によるカメラトラップ画像の判別”，哺乳類科学，Vol.59, No.1, pp.49-60, (2019) 中塚俊介, 加藤邦人:“多重解像度マップを持つ補集合GANを用いた正常データのみの学習による異常品検出”，精密工学会誌，Vol.87, No.1, pp.120-126 (2021)  雑誌  中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, 映像情報インダストリアル, pp.57-68(2018.03)  特許  加藤邦人, 中塚俊介, 相澤宏旭 : \u0026ldquo;異常品判定方法\u0026rdquo; (特願2017-196758/2017.10.10出願) 加藤邦人, 中塚俊介, 相澤宏旭, 齊藤岳穂, 高田裕樹, 伊澤仁:\u0026ldquo;異常品判定方法\u0026rdquo;(特願2019-73372/2019.4.8出願) 齊藤岳穂, 加藤邦人, 中塚俊介 :\u0026ldquo;異常判別システムおよびその構築方法\u0026rdquo;(特願2019-77205/2019.4.15出願)  受賞  Best Paper Award受賞 Shunsuke Nakatsuka, Kunihito Kato, Yosuke Nakanishi : \u0026ldquo;Study on Visual Inspection Method using CNN Regression\u0026rdquo;, Asia International Symposium on Mechatronics, D1-5(2017年9月15日受賞) ViEW2017 ビジョン技術の実利用ワークショップ 小田原賞（優秀論文賞）, 中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.148-149 (2017年12月8日 受賞) ViEW2019 ビジョン技術の実利用ワークショップ 小田原賞（優秀論文賞）, 中塚俊介,加藤邦人:\u0026ldquo;多重解像度マップを持つ補集合GANを用いた正常データのみの学習による外観検査法\u0026rdquo;,ビジョン技術の実利用ワークショップ ViEW2019, OS3-H1(IS2-C10) (2019年12月6日 受賞)  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"23d1e75f872528fc12f5f2b142375ff7","permalink":"https://salty-vanilla.github.io/portfolio/publications/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/portfolio/publications/","section":"","summary":"中塚俊介の業績一覧 | List of publications by Shunsuke Nakatsuka","tags":null,"title":"Publications","type":"page"}]