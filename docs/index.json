[{"authors":["admin"],"categories":null,"content":"2013年岐阜大学工学部 電気電子・情報工学科に入学．情報分野を専門領域として学ぶ． その中で，人工知能・コンピュータビジョンに興味を持ち，2015年より加藤研究室に所属する． 学部・修士課程を通して，ニューラルネットワーク・画像処理・異常検知の研究に従事．特に工業製品や食品における外観検査の自動化をテーマとして研究を行った． また2018年度より応用生物科学部と協同しニューラルネットワークを用いた野生動物検知の研究にも着手．\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://salty-vanilla.github.io/portfolio/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/portfolio/author/admin/","section":"author","summary":"2013年岐阜大学工学部 電気電子・情報工学科に入学．情報分野を専門領域として学ぶ． その中で，人工知能・コンピュータビジョンに興味を持ち，2015年より加藤研究室に所属する． 学部・修士課程を通して，ニューラルネットワーク・画像処理・異常検知の研究に従事．特に工業製品や食品における外観検査の自動化をテーマとして研究を行った． また2018年度より応用生物科学部と協同しニューラルネットワークを用いた野生動物検知の研究にも着手．","tags":null,"title":"Nakatsuka Shunsuke ","type":"author"},{"authors":null,"categories":["Anomaly Detection","VAE"],"content":"1. どんなもの？ Autoencoderベースの異常検知手法．Autoencoderの問題である画像内の一部の異常が画像全体の復元に影響を与えてしまい上手く異常部位をLocalicationできないという問題にタックル．\n2. 先行研究と比べてどこがすごい？  Autoencoderベースのモデルでは，異常画像が入力された際に異常部位以外も再構成が崩れてしまい上手くLocalizationできないという問題があった また，Blurが発生してしまう 上記2点を繰り返し，$x$を更新していく方法で解決する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？   エネルギー関数は，再構成誤差($L_r$)と正則化項（更新しても原画像から離れすぎないようにする正則化） $$ E(x_t) = L_r(x_t) + \\lambda|| x_t - x_0 || $$ $$ L_r(x_t) = \\mathbb{E} [ | f_{VAE}(x_t) - x_t | ^r ] $$\n  エネルギー関数を最小化するように，入力画像$x_0$を更新していく $$ x_{t+1} = x_t - \\alpha \\nabla_x E(x_t) $$\n  再構成が大きい部位は更新量を大きく，小さい部位は小さくすればなお良し $$ x_{x+1} = x_t - \\alpha ( \\nabla_xE(x_t) \\odot | f_{VAE}(x_t) - x_t | ^2 ) $$\n  つまるところ，学習済みのVAEを用意して，テストデータを繰り返し入力・更新して元のManifoldにより近づけるイメージ （近いモデルはAnoGAN）\n  4. どうやって有効だと検証した？   MVTECに対して，実験\n  それぞれ ***-gradが提案手法   通常のAutoencoderより，適切に異常部位のLocalizationができていることを確認   5. 議論はあるか？  iterativeにすることで推論時間はどのくらいになる？ AnoGANと似たようなmethodだが，比較は？  6. 次に読むべき論文はある？  Bin Dai and David P. Wipf. Diagnosing and enhancing VAE models. CoRR, abs/1903.05789, 2019. Ian  ","date":1575817200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575817200,"objectID":"2c63b045ec3d2c60a3dba4a7d4959a99","permalink":"https://salty-vanilla.github.io/portfolio/post/iterative_energy-based_projection_on_a_normal_data_manifold_for_anomaly_localization/","publishdate":"2019-12-09T00:00:00+09:00","relpermalink":"/portfolio/post/iterative_energy-based_projection_on_a_normal_data_manifold_for_anomaly_localization/","section":"post","summary":"1. どんなもの？ Autoencoderベースの異常検知手法．Autoencoderの問題である画像内の一部の異常が画像全体の復元に影響を与えてしまい上手く異常部位をLocalicationできないという問題にタックル．\n2. 先行研究と比べてどこがすごい？  Autoencoderベースのモデルでは，異常画像が入力された際に異常部位以外も再構成が崩れてしまい上手くLocalizationできないという問題があった また，Blurが発生してしまう 上記2点を繰り返し，$x$を更新していく方法で解決する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？   エネルギー関数は，再構成誤差($L_r$)と正則化項（更新しても原画像から離れすぎないようにする正則化） $$ E(x_t) = L_r(x_t) + \\lambda|| x_t - x_0 || $$ $$ L_r(x_t) = \\mathbb{E} [ | f_{VAE}(x_t) - x_t | ^r ] $$\n  エネルギー関数を最小化するように，入力画像$x_0$を更新していく $$ x_{t+1} = x_t - \\alpha \\nabla_x E(x_t) $$\n  再構成が大きい部位は更新量を大きく，小さい部位は小さくすればなお良し $$ x_{x+1} = x_t - \\alpha ( \\nabla_xE(x_t) \\odot | f_{VAE}(x_t) - x_t | ^2 ) $$","tags":null,"title":"Iterative energy-based projection on a normal data manifold for anomaly localization","type":"post"},{"authors":null,"categories":null,"content":"   はじめに 工業製品の製造工程において，出荷製品の品質安定化のために検査は必要不可欠である． とくに外観検査工程では人による目視検査が主であるが，検査員毎の判断基準のばらつきが長年の課題であった． 近年では深層学習技術の進歩により，これまで困難とされてきた目視検査工程でも自動化が検討されている． 従来の深層学習では正常品と異常品を識別するために大量のサンプルが必要であるが，現実には大量の異常品を確保することは困難である． そのため，正常品のみ，もしくは正常品と少数の異常品から良否識別できる枠組みが求められている． また，画像検査においては，1枚の異常画像の中に正常な領域と異常な領域が混在していることがある． このとき，異常な領域が占める割合が大きければ，検出は容易であるが，小さい場合は難しい． また，異常には様々な種類が存在し，それぞれを検出するのに適した解像度が存在するはずである． そのため，本稿ではComplementary GANに Multi-scale Patch の枠組みを加えたモデルに正常品のみを学習させ，正常分布とその補集合分布をモデリングし異常検知を行う手法を提案する．\n従来のNNを使った異常検知 差分ベース  Autoencoder AnoGAN ADGAN  メリット  差分ベースなので，欠陥箇所のLocalizationが可能 学習が容易  デメリット  外観検査においては差分の出づらい欠陥が存在する Blurが発生し，高周波成分が差分として現れてしまう    潜在変数ベース  Flow-based Model Adversarial Autoencoder  メリット  異常度を対数尤度としてダイレクトに算出できる 潜在変数による低次元データの可視化が可能  デメリット  欠陥情報が消失してしまう Out of distributionのデータでも尤度が高くなってしまうことがある．    Complementary GAN そもそもGANとは？  GeneratorとDiscriminatorの2つのNetworkを持つ Generatorは，Discriminatorを騙すように本物に近いデータを生成する Discriminatorは，入力が本物のデータなのか・Generatorによって生成された偽のデータなのかを識別する GeneratorとDiscriminatorが↑の学習をすることで，Generatorは本物に近いデータを生成できるようになる．  結局GANは何を学習している？  Discriminatorは生成分布とデータ分布の”離れ度合い”を測るDivergence Estimator Generatorは算出された”離れ度合い”を最小化する その結果，生成分布とデータ分布が近づいていき，本物に近い画像が生成できる  Discriminatorの出力って異常検知に使える？  Discriminatorは，本物と偽物が見極められるので，本物を正常データとすれば，正常/異常が分別できるのでは！？という考え それは難しい Discriminatorが識別しているのは，本物のデータであるか偽物のデータであって，偽物データの中に異常分布の要素は全く含まれていない  GANとComplementary GANの違いは？  GANはデータ分布と生成分布を測り，近づける Complementary GANはデータ分布と生成分布を測り，データ分布の補集合分布と生成分布を近づける つまり，Complementary GANは正常データには存在しないデータを生成し，Discriminatorは正常と正常ではないの識別境界となる  Multi-scale Patch Discriminator  外観検査では，欠陥の大きさは様々 CNNで，Conv + Poolingを積み重ねていくと小さい欠陥の情報は消えてしまう かといって，浅すぎるCNNでは識別はできない  そこで，Discriminatorの出力を[0, 1]のスカラーではなく，正常度MAPとすることで↑の問題に対処する\n実験 LEDチップ画像 サンプル データ内訳     良品 不良品     training 70000 0   test 10000 204    生成された補集合画像  不良品画像とは一致しないが，良品画像には近いが良品ではないものが生成できていることを確認    Discriminatorによる異常度MAP  赤に近いほど異常度が大きく，青に近いほど異常度が低い 各行左から，入力・8x8 MAP・4x4 MAP・2x2 MAP 8x8 MAPでは小さい欠陥が，2x2 MAPでは面積の大きい欠陥が検出される    精度   Reference  Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … Bengio, Y. (2014). Generative Adversarial Nets. Advances in Neural Information Processing Systems, 2672–2680. Zheng, P., Yuan, S., Wu, X., Li, J., \u0026amp; Lu, A. (2018). One-Class Adversarial Nets for Fraud Detection. ArXiv Preprint ArXiv:1803.01798. Bergmann, P., Fauser, M., Sattlegger, D., \u0026amp; Steger, C. (2019). MVTec AD \u0026ndash; A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Karras, T., Laine, S., \u0026amp; Aila, T. (2018). A Style-Based Generator Architecture for Generative Adversarial Networks. Retrieved from https://arxiv.org/abs/1812.04948  ","date":1575126000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575126000,"objectID":"92ac6e90d5886054b39de0842a0ca6ac","permalink":"https://salty-vanilla.github.io/portfolio/project/visual_inspection/","publishdate":"2019-12-01T00:00:00+09:00","relpermalink":"/portfolio/project/visual_inspection/","section":"project","summary":"工業部品や食品の外観検査をニューラルネットワークによって自動化","tags":null,"title":"Visual Inspection","type":"project"},{"authors":null,"categories":null,"content":"1. どんなもの？ Metric Learningの論文．分類をして，各クラス内の分散を小さく，クラス間の分散を大きくする系のMetric Learining．\n2. 先行研究と比べてどこがすごい？  クラス分類モデルのSoftmaxを少し改良するだけで適用できる ArcFaceと先行研究のSpehereFace・CosFaseのLoss関数は似ていて，それを一般化している  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Architecture 全体的な流れとしては， Base Block（VGGとかResNetとか）から特徴ベクトルを出力\n\\[ x' = f(x) \\]\n出力された特徴ベクトルをL2正則化\n\\[ x'' = \\frac{x'}{|x'|^2} \\]\n全結合層の重みをL2正則化\n\\[ w' = \\frac{w}{|w|^2} \\]\n正則化された特徴ベクトルと重みを内積（これがcosの値）\n\\[ cos\\theta = x'' \\cdot w' \\]\nこれにAdditive Angular Margin Penaltyを適用する．\nAdditive Angular Margin Penalty Additive Angular Margin Penaltyは正解ラベルに対応する出力の値に対して，Marginを加えることで，クラス内分散を小さくするような学習を行う． イメージとしては，正解ラベルにのみ厳しい罰則を与えてよりDiscriminativeにする感じ．\n正解クラス\\(j\\)の出力に対して，Marginを加算する\n\\[ \\theta_j' = \\{ \\begin{array}{ll} arccos(cos\\theta_i) + m \u0026 i=j \\\\ arccos(cos\\theta_i) \u0026 otherwise \\end{array} \\]\n各要素を定数倍する（温度パラメータ）\n\\[ logit = s cos(\\theta_j') \\]\nsoftmax関数にかける\n\\[ y = softmax(logit) \\]\nこの一連の流れを組み込んだLoss関数は\n\\[ L_{3}=-\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{e^{s\\left(\\cos \\left(\\theta_{y_{i}}+m\\right)\\right)}}{e^{s\\left(\\cos \\left(\\theta_{y_{i}}+m\\right)\\right)}+\\sum_{j=1, j \\neq y_{i}}^{n} e^{s \\cos \\theta_{j}}} \\]\nArcFace・SpehereFace・CosFase の一般化 \\(m_1\\)がSpehereFace，\\(m_2\\)がArcFace，\\(m_3\\)がCosFace．\n\\[ L_{4}=-\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{e^{s\\left(\\cos \\left(m_{1} \\theta_{y_{i}}+m_{2}\\right)-m_{3}\\right)}}{e^{s\\left(\\cos \\left(m_{1} \\theta_{y_{i}}+m_{2}\\right)-m_{3}\\right)}+\\sum_{j=1, j \\neq y_{i}}^{n} e^{s \\cos \\theta_{j}}} \\]\nそれぞれの識別境界の違いは下図になるらしい． 4. どうやって有効だと検証した？ 顔認識データセットであるLFW，CFP-FP，AgeDB30で実験． 比較手法がどれも精度が優秀なので，あまり有効さはわからない．\n5. 議論はあるか？  Out of dataset のサンプルが来た時にどれくらい精度がでるか？  6. 次に読むべき論文はある？  CosFace: Large Margin Cosine Loss for Deep Face Recognition https://arxiv.org/abs/1801.09414 SphereFace: Deep Hypersphere Embedding for Face Recognition https://arxiv.org/abs/1704.08063  ","date":1573916400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573916400,"objectID":"cbb19ff663abc875ed87ef1f97ea3bcf","permalink":"https://salty-vanilla.github.io/portfolio/post/arcface/","publishdate":"2019-11-17T00:00:00+09:00","relpermalink":"/portfolio/post/arcface/","section":"post","summary":"1. どんなもの？ Metric Learningの論文．分類をして，各クラス内の分散を小さく，クラス間の分散を大きくする系のMetric Learining．\n2. 先行研究と比べてどこがすごい？  クラス分類モデルのSoftmaxを少し改良するだけで適用できる ArcFaceと先行研究のSpehereFace・CosFaseのLoss関数は似ていて，それを一般化している  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Architecture 全体的な流れとしては， Base Block（VGGとかResNetとか）から特徴ベクトルを出力\n\\[ x' = f(x) \\]\n出力された特徴ベクトルをL2正則化\n\\[ x'' = \\frac{x'}{|x'|^2} \\]\n全結合層の重みをL2正則化\n\\[ w' = \\frac{w}{|w|^2} \\]\n正則化された特徴ベクトルと重みを内積（これがcosの値）\n\\[ cos\\theta = x'' \\cdot w' \\]\nこれにAdditive Angular Margin Penaltyを適用する．\nAdditive Angular Margin Penalty Additive Angular Margin Penaltyは正解ラベルに対応する出力の値に対して，Marginを加えることで，クラス内分散を小さくするような学習を行う． イメージとしては，正解ラベルにのみ厳しい罰則を与えてよりDiscriminativeにする感じ．\n正解クラス\\(j\\)の出力に対して，Marginを加算する\n\\[ \\theta_j' = \\{ \\begin{array}{ll} arccos(cos\\theta_i) + m \u0026 i=j \\\\ arccos(cos\\theta_i) \u0026 otherwise \\end{array} \\]","tags":null,"title":"ArcFace: Additive Angular Margin Loss for Deep Face Recognition","type":"post"},{"authors":null,"categories":null,"content":"1. どんなもの？ 異常検知の論文．Autoencoderの出力を複数にすることでAutoencoderの異常検知の問題を解決する．\n2. 先行研究と比べてどこがすごい？  Autoencoderの入出力による異常検知では，出力がぼやけてしまい高周波成分が再構成できず正常と異常のSN比が小さいという問題があった． 後述するMultiple-Hypothesesにより高周波成分の再構成に成功．  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Multiple-Hypotheses VAEのDecoderから得られる出力を複数にする． 具体的には，$H$個のDeconv Layerを最終層に配置し，それぞれ独立のパラメータで出力させる（事後分布はGaussian）． winner-takes-all (WTA) loss 複数のDecoderの出力に対して，全ておいて再構成誤差をBack Propagationするのではなく， 最も再構成誤差が低い出力(winner)のみから再構成誤差をBack Propagationさせる．\n\\[ \\begin{aligned} L_{W T A}\\left(x_{i} | \\theta_{h}\\right) \u0026=E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{h}}\\left(x_{i} | z_{k}\\right)\\right] \\\\ \\text { s.t. } h \u0026=\\arg \\max _{j} E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{j}}\\left(x_{i} | z_{k}\\right)\\right] \\end{aligned} \\]\nDiscriminator WTA Lossでは再構成誤差をBack Propagationする出力以外については更新がされないことになってしまう． そのため，それ以外の出力についても入力の分布に近づけるようにDiscriminatorを用意する． realはもちろん入力画像で，fakeはVAEの出力（Bestとそれ以外）とランダムサンプリングされた$z$からDecoderを介して得られた出力である．\n\\[ \\begin{aligned} \\min _{D} \\max _{G} L_{D}(x, z)=\u0026\\min _{D} \\max _{G} \\underbrace{-\\log \\left(p_{D}\\left(x_{r e a l}\\right)\\right)}_{L_{real}} +L_{f a k e}(x, z) \\end{aligned} \\]\n\\[ \\begin{array}{l}{L_{\\text {fake }}(x, z)=\\log \\left(p_{D}\\left(\\hat{x}_{z \\sim \\mathcal{N}(0,1)}\\right)\\right)} {+\\log \\left(p_{D}\\left(\\hat{x}_{z \\sim \\mathcal{N}}\\left(\\mu_{\\left.z | x, \\Sigma_{z | x}\\right)}\\right)\\right)+\\log \\left(p_{D}\\left(\\hat{x}_{\\text {best-guess }}\\right)\\right)\\right.}\\end{array} \\]\nVAEのLoss関数は，\n\\[ \\min _{G} L_{G}=\\min _{G} L_{W T A}+K L\\left(q_{\\phi}(z | x) \\| \\mathcal{N}(0,1)\\right)-L_{D} \\]\n異常度の算出 WTA Lossを異常度とする． Sumしなければ，異常箇所のLocalizationに使えるのは従来のAutoencoder通り．\n4. どうやって有効だと検証した？ CIFAR10(1vs9)とMETAL ANOMALY（論文内にはリンクなし）で実験． CIFAR10でAUROC: 67.1． METAL ANOMALYでは異常度が大きいPixelの上位10%のSumを全体の異常度として算出．\n5. 議論はあるか？  Blurが解消されたのは，VAE-GAN構造にしたことによるところが大きいと思うが果たして． 高周波成分が再構成されることにより，今まで差分として出てこなかった部分もあると思う．  6. 次に読むべき論文はある？ ","date":1572534000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572534000,"objectID":"ff3a913e37d04845f459625da0d43b59","permalink":"https://salty-vanilla.github.io/portfolio/post/anomaly_detection_with_multiple-hypotheses_predictions/","publishdate":"2019-11-01T00:00:00+09:00","relpermalink":"/portfolio/post/anomaly_detection_with_multiple-hypotheses_predictions/","section":"post","summary":"1. どんなもの？ 異常検知の論文．Autoencoderの出力を複数にすることでAutoencoderの異常検知の問題を解決する．\n2. 先行研究と比べてどこがすごい？  Autoencoderの入出力による異常検知では，出力がぼやけてしまい高周波成分が再構成できず正常と異常のSN比が小さいという問題があった． 後述するMultiple-Hypothesesにより高周波成分の再構成に成功．  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ Multiple-Hypotheses VAEのDecoderから得られる出力を複数にする． 具体的には，$H$個のDeconv Layerを最終層に配置し，それぞれ独立のパラメータで出力させる（事後分布はGaussian）． winner-takes-all (WTA) loss 複数のDecoderの出力に対して，全ておいて再構成誤差をBack Propagationするのではなく， 最も再構成誤差が低い出力(winner)のみから再構成誤差をBack Propagationさせる．\n\\[ \\begin{aligned} L_{W T A}\\left(x_{i} | \\theta_{h}\\right) \u0026=E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{h}}\\left(x_{i} | z_{k}\\right)\\right] \\\\ \\text { s.t. } h \u0026=\\arg \\max _{j} E_{z_{k} \\sim q_{\\phi}(z | x)}\\left[\\log p_{\\theta_{j}}\\left(x_{i} | z_{k}\\right)\\right] \\end{aligned} \\]\nDiscriminator WTA Lossでは再構成誤差をBack Propagationする出力以外については更新がされないことになってしまう． そのため，それ以外の出力についても入力の分布に近づけるようにDiscriminatorを用意する． realはもちろん入力画像で，fakeはVAEの出力（Bestとそれ以外）とランダムサンプリングされた$z$からDecoderを介して得られた出力である．\n\\[ \\begin{aligned} \\min _{D} \\max _{G} L_{D}(x, z)=\u0026\\min _{D} \\max _{G} \\underbrace{-\\log \\left(p_{D}\\left(x_{r e a l}\\right)\\right)}_{L_{real}} +L_{f a k e}(x, z) \\end{aligned} \\]","tags":null,"title":"Anomaly Detection With Multiple-Hypotheses Predictions","type":"post"},{"authors":null,"categories":null,"content":"1. どんなもの？ 推論時に時間がかかってしまうAnoGANを高速化する枠組み．\n2. 先行研究と比べてどこがすごい？ AnoGANでは，推論時に$z$から$x$へのmappingを行うために学習済みGANのDiscriminatorの結果と再構成誤差からLossを算出し，勾配降下法によって$z$を探索していた． つまり，推論時にも”学習”のフェーズが存在し処理時間が長かった．\nf-AnoGANでは，推論時の勾配降下による探索を無くし，推論の高速化を行った．\n3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ $z$ から$x$を推論する枠組みを3つ提案．\nziz encoder 学習済みのGANのGeneratorを用いて，$z$をGeneratorに入力し，その出力をziz encoderに入力し得られた潜在ベクトルとの再構成誤差を最小化する．\n$n$は総画素数． $$ L(z) = \\frac{1}{n}|z - E(G(z))|^2 $$\nizi encoder 学習済みのGANのGeneratorを用いて，$x$をEncoderに入力し，その出力をizi encoderに入力し得られた画像との再構成誤差を最小化する． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 $$\nizif encoder izi encoderの派生形で，izi encoderのLossと同様の再構成誤差と，Discriminatorに$x$と$G(E(x))$を入力した際の中間層の出力の再構成誤差の和を最小化する． $f(\\cdot)$はDiscriminatorの中間層の出力で，$n_d$は$f(\\cdot)$の次元数で$k$は重みパラメータ．． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n異常度の算出 $$ A(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n4. どうやって有効だと検証した？ AnoGANと同様にretinal spectral-domain optical coherence tomography (SD-OCT)をデータセットとして実験． Autoencoder，AAE，ALI，WGANのDiscriminator，iterative(AnoGAN)と比較して精度も上回った．\n5. 議論はあるか？ 追加のEncoderをつけるという簡単な手法で高速化＆高精度化を果たした点がGood． 構成的にはGANomalyに近い感じがするが，精度比較のほどは果たして？\n6. 次に読むべき論文はある？  AnoGAN https://arxiv.org/abs/1703.05921 GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training https://arxiv.org/abs/1805.06725 Adversarially Learned Inference https://arxiv.org/abs/1606.00704  ","date":1570978800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570978800,"objectID":"dbf2807c36d84c7a0f8affaefadded0c","permalink":"https://salty-vanilla.github.io/portfolio/post/f-anogan/","publishdate":"2019-10-14T00:00:00+09:00","relpermalink":"/portfolio/post/f-anogan/","section":"post","summary":"1. どんなもの？ 推論時に時間がかかってしまうAnoGANを高速化する枠組み．\n2. 先行研究と比べてどこがすごい？ AnoGANでは，推論時に$z$から$x$へのmappingを行うために学習済みGANのDiscriminatorの結果と再構成誤差からLossを算出し，勾配降下法によって$z$を探索していた． つまり，推論時にも”学習”のフェーズが存在し処理時間が長かった．\nf-AnoGANでは，推論時の勾配降下による探索を無くし，推論の高速化を行った．\n3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ $z$ から$x$を推論する枠組みを3つ提案．\nziz encoder 学習済みのGANのGeneratorを用いて，$z$をGeneratorに入力し，その出力をziz encoderに入力し得られた潜在ベクトルとの再構成誤差を最小化する．\n$n$は総画素数． $$ L(z) = \\frac{1}{n}|z - E(G(z))|^2 $$\nizi encoder 学習済みのGANのGeneratorを用いて，$x$をEncoderに入力し，その出力をizi encoderに入力し得られた画像との再構成誤差を最小化する． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 $$\nizif encoder izi encoderの派生形で，izi encoderのLossと同様の再構成誤差と，Discriminatorに$x$と$G(E(x))$を入力した際の中間層の出力の再構成誤差の和を最小化する． $f(\\cdot)$はDiscriminatorの中間層の出力で，$n_d$は$f(\\cdot)$の次元数で$k$は重みパラメータ．． $$ L(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n異常度の算出 $$ A(x) = \\frac{1}{n}|x - G(E(x))|^2 + \\frac{k}{n_d}|f(x)-f(G(E(x)))|^2 $$\n4. どうやって有効だと検証した？ AnoGANと同様にretinal spectral-domain optical coherence tomography (SD-OCT)をデータセットとして実験． Autoencoder，AAE，ALI，WGANのDiscriminator，iterative(AnoGAN)と比較して精度も上回った．\n5. 議論はあるか？ 追加のEncoderをつけるという簡単な手法で高速化＆高精度化を果たした点がGood． 構成的にはGANomalyに近い感じがするが，精度比較のほどは果たして？","tags":null,"title":"f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks","type":"post"},{"authors":null,"categories":null,"content":"背景 手法 ","date":1556809200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556809200,"objectID":"816dc8a0372121d1b0260f07e0230f4d","permalink":"https://salty-vanilla.github.io/portfolio/project/wlid_life/","publishdate":"2019-05-03T00:00:00+09:00","relpermalink":"/portfolio/project/wlid_life/","section":"project","summary":"大量のカメラトラップ画像から野生動物が何頭いるかを自動判定","tags":null,"title":"Wild Life","type":"project"},{"authors":null,"categories":null,"content":"1. どんなもの？ Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を向上させる．\n2. 先行研究と比べてどこがすごい？  Saliency Mapを用いることで有効な領域の情報を重視し，無関係な情報を抑制する Local feature vector (CNNの中間層の出力)とGlobal feature vector (CNNの後段のFCの出力)を組み合わせる 適合度によって重要なLocal feature vectorだけを分類に活用する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 学習可能なAttention Estimatorを通常のCNNに付け加えるだけで，Attention Mapによる解釈性，精度の向上．\n  $S$個のAttention Moduleを↑のようにCNNに加える．$s$個目のAttention Moduleは，長さ$M$のベクトル$N$個からなる集合である．\n  $s$個目のlocal feature vectorは $$ \\mathbf{L^s} = { \\mathbf{l_1^s}, \\mathbf{l_2^s}, \u0026hellip;, \\mathbf{l_N^s} } $$ ここで，ベクトルの長さ$M$はFeature Mapのチャネル数に等しく，ベクトルの個数$N$はFeature Mapの画素数に等しい．\n  全結合層で各ベクトルの長さをglobal feature vector $\\mathbf{g}$の長さ$M'$に揃える $$ \\mathbf{\\hat{l^s_i}} = w\\cdot{\\mathbf{l_i^s}} $$\n  local feature vectorとglobal feature vectorから各画素のCompatibility scoresを求める $$ C^s(\\mathbf{\\hat{L_s}}, \\mathbf{g}) = {c_1^s, c_2^s, \u0026hellip;, c_n^s} $$ $$ c_i^s = \\mathbf{\\hat{l^s_i}} \\cdot{\\mathbf{g}} $$\n  Compatibility scoresに対して，softmaxを適用してAttention Mapを算出 $$ a_i^s = \\frac{exp(c_i^s)}{\\sum_j^N exp(c_j^s)} $$\n  各モジュールの出力はAttention MapとFeature Mapの内積 $$ \\mathbf{g^s} = \\sum_i^n a_i^s \\cdot{\\mathbf{l_i^s}} $$\n  最終的には，全Moduleの出力を連結することでModule全体の出力として，最後にFC層\n  $$ \\mathbf{g_a} = { \\mathbf{g_1}, \\mathbf{g_2}, \u0026hellip;, \\mathbf{g_S}} $$ $$ O = W \\cdot{\\mathbf{g_a}} $$\n4. どうやって有効だと検証した？ CIFAR10，CIFAR100，CUB200，SVHNで実験． BaselineであるVGG，VGG+GAP, VGG+PAN, ResNet164と比較して精度向上． 浅い層では局所的な情報を重視し，深い層では物体全体の情報を重視していることがわかる\n5. 議論はあるか？ Adversarial AttackやCross Domainな認識タスクに対しても有効であることが示されている．\n6. 次に読むべき論文はある？ ","date":1525532400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525532400,"objectID":"aa74104a1b07b41903f5c46506262534","permalink":"https://salty-vanilla.github.io/portfolio/post/learn_to_pay_attention/","publishdate":"2018-05-06T00:00:00+09:00","relpermalink":"/portfolio/post/learn_to_pay_attention/","section":"post","summary":"1. どんなもの？ Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を向上させる．\n2. 先行研究と比べてどこがすごい？  Saliency Mapを用いることで有効な領域の情報を重視し，無関係な情報を抑制する Local feature vector (CNNの中間層の出力)とGlobal feature vector (CNNの後段のFCの出力)を組み合わせる 適合度によって重要なLocal feature vectorだけを分類に活用する  3. 技術や手法の\u0026quot;キモ\u0026quot;はどこ？ 学習可能なAttention Estimatorを通常のCNNに付け加えるだけで，Attention Mapによる解釈性，精度の向上．\n  $S$個のAttention Moduleを↑のようにCNNに加える．$s$個目のAttention Moduleは，長さ$M$のベクトル$N$個からなる集合である．\n  $s$個目のlocal feature vectorは $$ \\mathbf{L^s} = { \\mathbf{l_1^s}, \\mathbf{l_2^s}, \u0026hellip;, \\mathbf{l_N^s} } $$ ここで，ベクトルの長さ$M$はFeature Mapのチャネル数に等しく，ベクトルの個数$N$はFeature Mapの画素数に等しい．\n  全結合層で各ベクトルの長さをglobal feature vector $\\mathbf{g}$の長さ$M'$に揃える $$ \\mathbf{\\hat{l^s_i}} = w\\cdot{\\mathbf{l_i^s}} $$\n  local feature vectorとglobal feature vectorから各画素のCompatibility scoresを求める $$ C^s(\\mathbf{\\hat{L_s}}, \\mathbf{g}) = {c_1^s, c_2^s, \u0026hellip;, c_n^s} $$ $$ c_i^s = \\mathbf{\\hat{l^s_i}} \\cdot{\\mathbf{g}} $$","tags":null,"title":"Learn to Pay Attention","type":"post"},{"authors":null,"categories":null,"content":"国内会議  中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;CNNによる回帰分析を用いた打痕判定に関する考察\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2016, pp.204-205(2016.12.9) 中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;回帰型CNNを用いた工業製品における外観検査手法の研究\u0026rdquo;, 第22回知能メカトロニクスワークショップ, 3A1-4(2017.8.28) 神本恭佑, 中塚俊介, 相澤宏旭, 加藤邦人, 小林裕幸, 坂野和見 : \u0026ldquo;Denoising Autoencoder Generative Adversarial Networks を用いた欠損検出の検討\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.54-55(2017.12.7) 中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.148-149(2017.12.8) 安藤正規，中塚俊介，相澤宏旭，中森さつき，池田敬，森部絢嗣，寺田和憲，加藤邦人: \u0026ldquo;機械学習による自動撮影カメラ画像からの獣種自動判別技術の開発\u0026rdquo;，日本哺乳類学会2018年度大会，S2-05，(2018.9)  国際会議  Shunsuke Nakatsuka, Kunihito Kato, Yosuke Nakanishi : \u0026ldquo;Study on Visual Inspection Method using CNN Regression\u0026rdquo;, Asia International Symposium on Mechatronics, D1-5(2017.9.15) Kyosuke Komoto, Shunsuke Nakatsuka Hiroaki, Aizawa, Kunihito Kato, Hiroyuki Kobayashi, Kazumi Banno : \u0026ldquo;A Performance Evaluation of Defect Detection by using Denoising AutoEncoder Generative Adversarial Networks\u0026rdquo;, International Workshop on Advanced Image Technology 2018, Session E2-4 (2018.1.9) Shunsuke Nakatsuka, Hiroaki Aizawa and Kunihito Kato : \u0026ldquo;A Method of Generation of Normal Model and Discrimination of Defects by Adversarial AutoEncoder under Small Number of Defective Samples\u0026rdquo;, Proceeding of 24rd International Workshop on Frontiers of Computer Vision, OS3-1,(2018.2.22)  論文誌  中塚俊介，相澤宏旭，加藤邦人：\u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と異常検出\u0026rdquo;，精密工学会誌，投稿中 安藤正規，中塚俊介，相澤宏旭，中森さつき，池田敬，森部絢嗣，寺田和憲，加藤邦人: \u0026ldquo;深層学習（Deep Learning）によるカメラトラップ画像の判別\u0026rdquo;，哺乳類科学, 投稿中  雑誌  中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, 映像情報インダストリアル, pp.57-68(2018.03)  特許  加藤邦人, 中塚俊介, 相澤宏旭 : \u0026ldquo;異常品判定方法\u0026rdquo; (特願2017-196758/2017.10.10出願)  受賞  Best Paper Award受賞 Shunsuke Nakatsuka, Kunihito Kato, Yosuke Nakanishi : \u0026ldquo;Study on Visual Inspection Method using CNN Regression\u0026rdquo;, Asia International Symposium on Mechatronics, D1-5(2017年9月15日受賞) ViEW2017 ビジョン技術の実利用ワークショップ 小田原賞（優秀論文賞）, 中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.148-149 (2017年12月8日 受賞)  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"40ea366a28f9524de71378c3212c5489","permalink":"https://salty-vanilla.github.io/portfolio/publication/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/portfolio/publication/","section":"","summary":"国内会議  中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;CNNによる回帰分析を用いた打痕判定に関する考察\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2016, pp.204-205(2016.12.9) 中塚俊介, 加藤邦人, 中西洋輔 : \u0026ldquo;回帰型CNNを用いた工業製品における外観検査手法の研究\u0026rdquo;, 第22回知能メカトロニクスワークショップ, 3A1-4(2017.8.28) 神本恭佑, 中塚俊介, 相澤宏旭, 加藤邦人, 小林裕幸, 坂野和見 : \u0026ldquo;Denoising Autoencoder Generative Adversarial Networks を用いた欠損検出の検討\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.54-55(2017.12.7) 中塚俊介, 相澤宏旭, 加藤邦人 : \u0026ldquo;少数不良品サンプル下におけるAdversarial AutoEncoderによる正常モデルの生成と不良判別\u0026rdquo;, ビジョン技術の実利用ワークショップ ViEW2017, pp.148-149(2017.12.8) 安藤正規，中塚俊介，相澤宏旭，中森さつき，池田敬，森部絢嗣，寺田和憲，加藤邦人: \u0026ldquo;機械学習による自動撮影カメラ画像からの獣種自動判別技術の開発\u0026rdquo;，日本哺乳類学会2018年度大会，S2-05，(2018.9)  国際会議  Shunsuke Nakatsuka, Kunihito Kato, Yosuke Nakanishi : \u0026ldquo;Study on Visual Inspection Method using CNN Regression\u0026rdquo;, Asia International Symposium on Mechatronics, D1-5(2017.9.15) Kyosuke Komoto, Shunsuke Nakatsuka Hiroaki, Aizawa, Kunihito Kato, Hiroyuki Kobayashi, Kazumi Banno : \u0026ldquo;A Performance Evaluation of Defect Detection by using Denoising AutoEncoder Generative Adversarial Networks\u0026rdquo;, International Workshop on Advanced Image Technology 2018, Session E2-4 (2018.","tags":null,"title":"Publications","type":"page"}]