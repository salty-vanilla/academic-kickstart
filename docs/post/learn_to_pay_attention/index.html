<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.2.5">
  <meta name="google-site-verification" content="Cc3qNeWjzkkGUiml6I-IY_Zs9QqvMsQIUFS07CCjlts" />
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Nakatsuka Shunsuke ">

  
  
  
    
  
  <meta name="description" content="1. どんなもの？ Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を向上させる．
2. 先行研究と比べてどこがすごい？  Saliency Mapを用いることで有効な領域の情報を重視し，無関係な情報を抑制する Local feature vector (CNNの中間層の出力)とGlobal feature vector (CNNの後段のFCの出力)を組み合わせる 適合度によって重要なLocal feature vectorだけを分類に活用する  3. 技術や手法の&quot;キモ&quot;はどこ？ 学習可能なAttention Estimatorを通常のCNNに付け加えるだけで，Attention Mapによる解釈性，精度の向上．
  $S$個のAttention Moduleを↑のようにCNNに加える．$s$個目のAttention Moduleは，長さ$M$のベクトル$N$個からなる集合である．
  $s$個目のlocal feature vectorは $$ \mathbf{L^s} = { \mathbf{l_1^s}, \mathbf{l_2^s}, &hellip;, \mathbf{l_N^s} } $$ ここで，ベクトルの長さ$M$はFeature Mapのチャネル数に等しく，ベクトルの個数$N$はFeature Mapの画素数に等しい．
  全結合層で各ベクトルの長さをglobal feature vector $\mathbf{g}$の長さ$M&#39;$に揃える $$ \mathbf{\hat{l^s_i}} = w\cdot{\mathbf{l_i^s}} $$
  local feature vectorとglobal feature vectorから各画素のCompatibility scoresを求める $$ C^s(\mathbf{\hat{L_s}}, \mathbf{g}) = {c_1^s, c_2^s, &hellip;, c_n^s} $$ $$ c_i^s = \mathbf{\hat{l^s_i}} \cdot{\mathbf{g}} $$">

  
  <link rel="alternate" hreflang="en-us" href="https://salty-vanilla.github.io/portfolio/post/learn_to_pay_attention/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#ef8354">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  
  
  
  <link rel="stylesheet" href="/portfolio/css/academic.min.293b82b2aaab66437e78347bec979f33.css">

  
    
    
    
    
      
    
    
    
    <link rel="stylesheet" href="/portfolio/css/academic.d3afa0f553c7cc00bac3afdaa697922d.css">
  

  
  
  

  

  <link rel="manifest" href="/portfolio/site.webmanifest">
  <link rel="icon" type="image/png" href="/portfolio/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/portfolio/img/icon-192.png">

  <link rel="canonical" href="https://salty-vanilla.github.io/portfolio/post/learn_to_pay_attention/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Nakatsuka Shunsuke">
  <meta property="og:url" content="https://salty-vanilla.github.io/portfolio/post/learn_to_pay_attention/">
  <meta property="og:title" content="Learn to Pay Attention | Nakatsuka Shunsuke">
  <meta property="og:description" content="1. どんなもの？ Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を向上させる．
2. 先行研究と比べてどこがすごい？  Saliency Mapを用いることで有効な領域の情報を重視し，無関係な情報を抑制する Local feature vector (CNNの中間層の出力)とGlobal feature vector (CNNの後段のFCの出力)を組み合わせる 適合度によって重要なLocal feature vectorだけを分類に活用する  3. 技術や手法の&quot;キモ&quot;はどこ？ 学習可能なAttention Estimatorを通常のCNNに付け加えるだけで，Attention Mapによる解釈性，精度の向上．
  $S$個のAttention Moduleを↑のようにCNNに加える．$s$個目のAttention Moduleは，長さ$M$のベクトル$N$個からなる集合である．
  $s$個目のlocal feature vectorは $$ \mathbf{L^s} = { \mathbf{l_1^s}, \mathbf{l_2^s}, &hellip;, \mathbf{l_N^s} } $$ ここで，ベクトルの長さ$M$はFeature Mapのチャネル数に等しく，ベクトルの個数$N$はFeature Mapの画素数に等しい．
  全結合層で各ベクトルの長さをglobal feature vector $\mathbf{g}$の長さ$M&#39;$に揃える $$ \mathbf{\hat{l^s_i}} = w\cdot{\mathbf{l_i^s}} $$
  local feature vectorとglobal feature vectorから各画素のCompatibility scoresを求める $$ C^s(\mathbf{\hat{L_s}}, \mathbf{g}) = {c_1^s, c_2^s, &hellip;, c_n^s} $$ $$ c_i^s = \mathbf{\hat{l^s_i}} \cdot{\mathbf{g}} $$"><meta property="og:image" content="https://salty-vanilla.github.io/portfolio/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-05-06T00:00:00&#43;09:00">
  
  <meta property="article:modified_time" content="2018-05-06T00:00:00&#43;09:00">
  

  

  

  <title>Learn to Pay Attention | Nakatsuka Shunsuke</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/portfolio/">Nakatsuka Shunsuke</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/portfolio/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/portfolio/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/portfolio/#projects">
            
            <span>Researches</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/portfolio/publication">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/portfolio/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Learn to Pay Attention</h1>

  

  
    



<meta content="2018-05-06 00:00:00 &#43;0900 JST" itemprop="datePublished">
<meta content="2018-05-06 00:00:00 &#43;0900 JST" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>May 6, 2018</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    1 min read
  </span>
  

  
  

  
  

  
    

  

</div>

    








  









  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      <h2 id="1-">1. どんなもの？</h2>
<p>Attention Mapを使ってCNNが分類を行うときに使う有効な視覚的情報の空間的なサポートを見つけ出し，利用することで一般物体認識の精度を向上させる．</p>
<h2 id="2-">2. 先行研究と比べてどこがすごい？</h2>
<ul>
<li>Saliency Mapを用いることで有効な領域の情報を重視し，無関係な情報を抑制する</li>
<li>Local feature vector (CNNの中間層の出力)とGlobal feature vector (CNNの後段のFCの出力)を組み合わせる</li>
<li>適合度によって重要なLocal feature vectorだけを分類に活用する</li>
</ul>
<h2 id="3-">3. 技術や手法の&quot;キモ&quot;はどこ？</h2>
<p>学習可能なAttention Estimatorを通常のCNNに付け加えるだけで，Attention Mapによる解釈性，精度の向上．</p>
<p><img src="img/architecture.png" alt=""></p>
<ol>
<li>
<p>$S$個のAttention Moduleを↑のようにCNNに加える．$s$個目のAttention Moduleは，長さ$M$のベクトル$N$個からなる集合である．</p>
</li>
<li>
<p>$s$個目のlocal feature vectorは
$$ \mathbf{L^s} = { \mathbf{l_1^s}, \mathbf{l_2^s}, &hellip;, \mathbf{l_N^s} } $$
ここで，ベクトルの長さ$M$はFeature Mapのチャネル数に等しく，ベクトルの個数$N$はFeature Mapの画素数に等しい．</p>
</li>
<li>
<p>全結合層で各ベクトルの長さをglobal feature vector $\mathbf{g}$の長さ$M'$に揃える
$$ \mathbf{\hat{l^s_i}} = w\cdot{\mathbf{l_i^s}} $$</p>
</li>
<li>
<p>local feature vectorとglobal feature vectorから各画素のCompatibility scoresを求める
$$ C^s(\mathbf{\hat{L_s}}, \mathbf{g}) = {c_1^s, c_2^s, &hellip;, c_n^s} $$
$$ c_i^s = \mathbf{\hat{l^s_i}} \cdot{\mathbf{g}} $$</p>
</li>
<li>
<p>Compatibility scoresに対して，softmaxを適用してAttention Mapを算出
$$ a_i^s = \frac{exp(c_i^s)}{\sum_j^N exp(c_j^s)} $$</p>
</li>
<li>
<p>各モジュールの出力はAttention MapとFeature Mapの内積
$$ \mathbf{g^s} = \sum_i^n a_i^s \cdot{\mathbf{l_i^s}} $$</p>
</li>
<li>
<p>最終的には，全Moduleの出力を連結することでModule全体の出力として，最後にFC層</p>
</li>
</ol>
<p>$$ \mathbf{g_a} = { \mathbf{g_1}, \mathbf{g_2}, &hellip;, \mathbf{g_S}} $$
$$ O = W \cdot{\mathbf{g_a}} $$</p>
<h2 id="4-">4. どうやって有効だと検証した？</h2>
<p>CIFAR10，CIFAR100，CUB200，SVHNで実験．
BaselineであるVGG，VGG+GAP, VGG+PAN, ResNet164と比較して精度向上．
浅い層では局所的な情報を重視し，深い層では物体全体の情報を重視していることがわかる</p>
<p><img src="img/res.png" alt=""></p>
<h2 id="5-">5. 議論はあるか？</h2>
<p>Adversarial AttackやCross Domainな認識タスクに対しても有効であることが示されている．</p>
<p><img src="img/adv_attack.png" alt="">
<img src="img/cross_domain.png" alt=""></p>
<h2 id="6-">6. 次に読むべき論文はある？</h2>

    </div>

    



    
      






  







<div class="media author-card" itemscope itemtype="http://schema.org/Person">
  
  
  <img class="portrait mr-3" src="/portfolio/author/admin/avatar_hued5d70cfe56e48dc137dc1e3bdf77641_127119_250x250_fill_lanczos_center_2.png" itemprop="image" alt="Avatar">
  

  <div class="media-body">
    <h5 class="card-title" itemprop="name"><a href="/portfolio/authors/admin">Nakatsuka Shunsuke </a></h5>
    <h6 class="card-subtitle">R&amp;D Engineer</h6>
    <p class="card-text" itemprop="description">My research interests include distributed robotics, mobile computing and programmable matter.</p>
    <ul class="network-icon" aria-hidden="true">
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="/portfolio/#contact" >
          <i class="fas fa-envelope"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://twitter.com/_Shu_Nak" target="_blank" rel="noopener">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://github.com/salty-vanilla" target="_blank" rel="noopener">
          <i class="fab fa-github"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://www.slideshare.net/ShunsukeNAKATSUKA1" target="_blank" rel="noopener">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
      
    </ul>
  </div>
</div>



      
      
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {delimiters: [
          {left: "$$", right: "$$", display: true},
          {left: "$", right: "$", display: false},
          {left: "\\[", right: "\\]", display: true},
          {left: "\\(", right: "\\)", dispaly: false},
          ]
        });
      });
    </script>

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/portfolio/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/portfolio/js/academic.min.ee93f50e7bcdd181a29c10939fba4467.js"></script>

  </body>
</html>

