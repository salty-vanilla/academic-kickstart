<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Representation Learning on Nakatsuka Shunsuke</title>
    <link>https://salty-vanilla.github.io/portfolio/categories/representation-learning/</link>
    <description>Recent content in Representation Learning on Nakatsuka Shunsuke</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 18 Jan 2020 00:00:00 +0900</lastBuildDate>
    
	<atom:link href="https://salty-vanilla.github.io/portfolio/categories/representation-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Laplacian Denoising Autoencoder</title>
      <link>https://salty-vanilla.github.io/portfolio/post/lapdae/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0900</pubDate>
      
      <guid>https://salty-vanilla.github.io/portfolio/post/lapdae/</guid>
      <description>1. どんなもの？  表現学習の枠組み Denoising Autoencoderをベースにより良い特徴表現を獲得 具体的には，入力データにノイズを付加するのではなくLaplacian Pyramidのrandom level目でノイズを付加する   2. 先行研究と比べてどこがすごい？  通常のDAEより優れた特徴表現の獲得 他の表現学習とは異なり，domain assumptionやpseudo labelを必要としない  3. 技術や手法の&amp;quot;キモ&amp;quot;はどこ？  入力データにノイズを付加するのではなく，Laplacian Pyramidのlevel $l$層目でノイズを付加する $l$層目のLaplacian Pyramid $x_l^L$ は，$l$層目のGaussian Pyramid $x_l^G$ を用いて下式 $$ x_l^L = x_l^G - upsample(x_{l+1}^G) $$ $x_0^G$ は元画像に等しい．上式の $l$ を 0 に向かって繰り返し計算すると元画像が求められる $$ x_l^G = x_l^L + upsample(x_{l+1}^G) $$ この繰り返しの途中でノイズを付加する   algorithmは以下  $c \in C$ はどんなノイズを付加するかのセットと要素 objectiveは通常のMSE     4. どうやって有効だと検証した？ MNIST  通常のDAEと比較して，input space, laplacian spaceどちらのnoiseに対しても正確に復元できていることがわかる 再構成Lossも低い   CIFAR10  再構成，画像検索共に通常のDAEより高精度   Imagenet  Supervised learningと同じようなconv filterが学習できている  conv層後の特徴を線形分類したときの精度比較．  LapDAEとAET-project[1]を組み合わせた LapDAE + Transが最高精度    Pascal VOCに転移学習しても最高精度   5.</description>
    </item>
    
  </channel>
</rss>