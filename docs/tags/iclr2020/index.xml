<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ICLR2020 on Nakatsuka Shunsuke</title>
    <link>https://salty-vanilla.github.io/portfolio/tags/iclr2020/</link>
    <description>Recent content in ICLR2020 on Nakatsuka Shunsuke</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://salty-vanilla.github.io/portfolio/tags/iclr2020/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DROCC: Deep Robust One-Class Classification</title>
      <link>https://salty-vanilla.github.io/portfolio/post/drocc/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://salty-vanilla.github.io/portfolio/post/drocc/</guid>
      <description>1. どんなもの？  One Class Learningの枠組み side-informationを必要とせず，representation collapseに対してrobust negative examples を用いたDROCC-LN(Limeted Negatives)も提案  2. 先行研究と比べてどこがすごい？  GEOM系は画像などのtransformに対して事前知識が必要（汎用性もない） DeepSVDDは全てが同じ特徴に落ちてしまうrepresentation collapseが問題  3. 技術や手法の&amp;quot;キモ&amp;quot;はどこ？ 仮定：
 The set of typical points $S$ lies on a low dimensional locally linear manifold that is well-sampled. In other words, outside a small radius around a training (typical) point, most points are anomalous.
  正常 $S$ は低次元な局所的線形多様体上に存在し，よくsamplingされている．言い換えるとtrainingデータの周りの小さな半径の外側が異常である．
 DROCC  入力データをNNで次元を落として正常ベクトル$f_\theta(x)$とその外側ベクトル$f_\theta(\tilde{x})$を生成 $f_\theta(\tilde{x})$を生成するのに敵対的枠組みを利用 $l$はcrossentropyとして正常1・外側0として分類タスクに持っていく  $$ \ell^{\mathrm{dr}}(\theta)=\lambda|\theta|^{2}+\sum_{i=1}^{n}\left[\ell\left(f_{\theta}\left(x_{i}\right), 1\right)+\mu \max _ {\tilde{x} _ {i} \in} \ell\left(f_{\theta}\left(\tilde{x}_{i}\right),-1\right)\right] $$</description>
    </item>
    
  </channel>
</rss>
